{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a18649de",
   "metadata": {},
   "source": [
    "# Complete pre-analysis cell labelling pipeline\n",
    "\n",
    "1. Alignment\n",
    "2. Segmentation\n",
    "3. Object localisation\n",
    "4. Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cca1b454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import enum\n",
    "import re\n",
    "import numpy as np\n",
    "import btrack\n",
    "from pystackreg import StackReg\n",
    "from skimage.io import imsave, imread\n",
    "from tqdm.auto import tqdm\n",
    "from octopuslite import DaskOctopusLiteLoader\n",
    "from skimage import transform as tf\n",
    "from stardist.models import StarDist2D \n",
    "from stardist.plot import render_label\n",
    "from csbdeep.utils import normalize\n",
    "from scipy import ndimage as nd\n",
    "from scipy.special import softmax\n",
    "from cellx import load_model\n",
    "from cellx.tools.image import InfinitePaddedImage\n",
    "from skimage.transform import resize\n",
    "\n",
    "seg_model = StarDist2D.from_pretrained('2D_versatile_fluo')\n",
    "\n",
    "def normalize_channels(x):\n",
    "\n",
    "    for dim in range(x.shape[-1]):\n",
    "        x[..., dim] = normalize(x[..., dim])\n",
    "        \n",
    "    return x\n",
    "\n",
    "def normalize(x):\n",
    "\n",
    "    xf = x.astype(np.float32)\n",
    "    mx = np.mean(xf)\n",
    "    sd = np.max([np.std(xf), 1./np.prod(x.shape)])\n",
    "\n",
    "    return (xf - mx) / sd\n",
    "\n",
    "def classify_objects(image,  gfp, rfp, objects, obj_type):\n",
    "    \n",
    "    # define stages of cell cycle to classify (dependent on model type)\n",
    "    LABELS = [\"interphase\", \"prometaphase\", \"metaphase\", \"anaphase\", \"apoptosis\"]\n",
    "    \n",
    "    # iterate over frames\n",
    "    for n in tqdm(range(image.shape[0])):\n",
    "        \n",
    "        # only select objects if in frame\n",
    "        _objects = [o for o in objects if o.t == n]\n",
    "        \n",
    "        # empty placeholder arrays\n",
    "        crops = []\n",
    "        to_update = []\n",
    "        \n",
    "        # select h2b channel to aid in classification\n",
    "        fp = gfp if obj_type == 1 else rfp\n",
    "        \n",
    "        # create stack by computing each frame of dask array input\n",
    "        frame = np.stack(\n",
    "            [image[n, ...].compute(), fp[n, ...].compute()], \n",
    "            axis=-1,) \n",
    "        \n",
    "        # create padded image for network\n",
    "        vol = InfinitePaddedImage(frame, mode = 'reflect')\n",
    "        \n",
    "        # iterate over objects \n",
    "        for obj in _objects:\n",
    "            \n",
    "            # create coords for image slice\n",
    "            xs = slice(int(obj.x-40), int(obj.x+40), 1)\n",
    "            ys = slice(int(obj.y-40), int(obj.y+40), 1)\n",
    "            \n",
    "            # crop image\n",
    "            crop = vol[ys, xs, :]\n",
    "            crop = resize(crop, (64, 64), preserve_range=True).astype(np.float32)\n",
    "            \n",
    "            # normalise image\n",
    "            if crop.shape == (64 ,64, 2):\n",
    "                crops.append(normalize_channels(crop))\n",
    "                to_update.append(obj)\n",
    "            else:\n",
    "                print(crop.shape)\n",
    "                \n",
    "        if not crops:\n",
    "            continue\n",
    "            \n",
    "        # use classifcation model to predict\n",
    "        pred = model.predict(np.stack(crops, axis=0))\n",
    "        \n",
    "        # check correct number of predictions\n",
    "        assert pred.shape[0] == len(_objects)\n",
    "        \n",
    "        # assign labels to objects\n",
    "        for idx in range(pred.shape[0]):\n",
    "            obj = _objects[idx]\n",
    "            \n",
    "            # assigning details of prediction\n",
    "            pred_label = np.argmax(pred[idx, ...])\n",
    "            pred_softmax = softmax(pred[idx, ...])\n",
    "            logits = {f\"prob_{k}\": pred_softmax[ki] for ki, k in enumerate(LABELS)}\n",
    "            \n",
    "            # write out\n",
    "            obj.label = pred_label\n",
    "            obj.properties = logits\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2625540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0022a0b46ce24fe1bbc0999d59c170de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79437e36c091468e81cda42589b5ccd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting alignment for ND0013/Pos0\n",
      "Using cropping: (500, 500)\n",
      "Registering alignment for Pos0 ND0013\n",
      "Alignment complete for ND0013 Pos0\n",
      "Starting segmentation for ND0013 Pos0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb7bdfa5b9b4d8c82c3ac81b92354bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2785 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root_dir = '/home/nathan/data/kraken/ras'\n",
    "expt_list = sorted([expt for expt in os.listdir(root_dir) \n",
    "                    if 'ND' in expt and os.path.isdir(os.path.join(root_dir, expt))], \n",
    "                    key = lambda x: [int(y) for y in re.findall(r'\\d+', x)])\n",
    "\n",
    "for expt in tqdm(expt_list):\n",
    "    pos_list = sorted([pos for pos in os.listdir(f'{root_dir}/{expt}') \n",
    "                        if 'Pos' in pos \n",
    "                        and os.path.isdir(f'{root_dir}/{expt}/{pos}')],\n",
    "                        key = lambda x: [int(y) for y in re.findall(r'\\d+', x)])\n",
    "    \n",
    "    for pos in tqdm(pos_list):\n",
    "\n",
    "        print(f'Starting alignment for {expt}/{pos}')\n",
    "\n",
    "        ### create new subdir of for raw files and move them all there\n",
    "        image_path = f'{root_dir}/{expt}/{pos}/{pos}_images'\n",
    "        if not os.path.exists(image_path):\n",
    "            os.mkdir(image_path)\n",
    "            files = sorted(glob.glob(f'{root_dir}/{expt}/{pos}/*.tif'))\n",
    "            for file in files:\n",
    "                os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_images'))\n",
    "\n",
    "        # check if blanks dir exists and make if not and move\n",
    "        if not os.path.exists(f'{root_dir}/{expt}/{pos}/{pos}_blanks'):\n",
    "            os.mkdir(f'{root_dir}/{expt}/{pos}/{pos}_blanks')\n",
    "            ### pre load files from raw file dir \n",
    "            images = DaskOctopusLiteLoader(image_path, remove_background= False)\n",
    "\n",
    "            ### measure mean pixel value arrays and use to find under/over-exposed frames\n",
    "            # set empty dict arrays for mean values \n",
    "            mean_arrays = {}\n",
    "            # set for dodgy frames (only unique entries)\n",
    "            dodgy_frame_list = set([])\n",
    "            #iterate over channels\n",
    "            for channel in tqdm(images.channels, desc = f'Finding mean values of image channels'):\n",
    "                if 'MASK' in channel.name:\n",
    "                    continue\n",
    "                # find mean value of each frame in each channel\n",
    "                mean_arrays[channel.name] = [np.mean(img) for img in image_generator(images.files(channel.name))]\n",
    "                # iterate over frames\n",
    "                for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "                    # check to see if mean frame pixel value meets criteria\n",
    "                    if max_pixel < mean_value or mean_value < min_pixel:\n",
    "                        # if so add to delete list\n",
    "                        dodgy_frame_list.add(frame)\n",
    "            # format delete list to only include single values\n",
    "            dodgy_frame_list = list(dodgy_frame_list)\n",
    "            print('Number of under/over-exposed frames:', len(dodgy_frame_list))\n",
    "\n",
    "            # move blank images into this directory\n",
    "            for channel in images.channels:\n",
    "                for f in images.files(channel.name):\n",
    "                    for i in dodgy_frame_list:\n",
    "                        if str(i).zfill(9) in f:\n",
    "                            os.rename(f, f.replace('_images', '_blanks'))\n",
    "\n",
    "        # crop central window out of reference image with blanks removed\n",
    "        reference_image = DaskOctopusLiteLoader(image_path, \n",
    "                                                crop = (500, 500)\n",
    "                                               )['gfp'].compute() \n",
    "\n",
    "\n",
    "        ### Register alignment\n",
    "        print('Registering alignment for', pos, expt)\n",
    "        # create operator using transformation type (translation)\n",
    "        sr = StackReg(StackReg.TRANSLATION) \n",
    "        # register each frame to the previous as transformation matrices/tensor\n",
    "        transform_tensor = sr.register_stack(reference_image, reference = 'previous', )\n",
    "\n",
    "        ### clip transformation tensor to eliminate any rare jumps, (1688-1600)/2=44\n",
    "        transform_tensor = np.clip(transform_tensor, a_max= 44, a_min = -44)\n",
    "\n",
    "        # save out transform tensor\n",
    "        np.save(f'{root_dir}/{expt}/{pos}/transform_tensor.npy', transform_tensor)\n",
    "\n",
    "        print('Alignment complete for', expt, pos)\n",
    "\n",
    "\n",
    "\n",
    "        print('Starting segmentation for', expt, pos)\n",
    "        # load images\n",
    "        images = DaskOctopusLiteLoader(image_path, \n",
    "                                       remove_background = True)\n",
    "\n",
    "        # iterate over images filenames \n",
    "        for frame, fn in tqdm(enumerate(images.files('gfp')),total = len(images.files('gfp'))):\n",
    "            # load two seperate images\n",
    "            gfp = imread(fn)\n",
    "            # predict labels using 2 instances of the model with different params\n",
    "            labels, details = seg_model.predict_instances(normalize(gfp), prob_thresh=0.75)\n",
    "            # format 2channel mask image \n",
    "            mask = np.zeros(labels.shape)\n",
    "\n",
    "            for i in range(1, np.amax(labels)):\n",
    "                #needs erosion step to stop merging of labels\n",
    "                segment = nd.binary_erosion(labels==i)\n",
    "                mask[segment] = 1 ## for gfp\n",
    "                # set background to zero\n",
    "                mask[labels == 0] = 0\n",
    "\n",
    "            # now do the same for the rfp channel\n",
    "            rfp = imread(fn.replace('channel001', 'channel002'))   \n",
    "            # predict labels using 2 instances of the model with different params\n",
    "            labels, details = seg_model.predict_instances(normalize(rfp), prob_thresh=0.2)\n",
    "\n",
    "            for i in range(1, np.amax(labels)):\n",
    "                #needs erosion step to stop merging of labels\n",
    "                segment = nd.binary_erosion(labels==i)\n",
    "                mask[segment] = 2 ## for rfp\n",
    "\n",
    "            # set filename as mask format (channel099)\n",
    "            fn = ((images.files('gfp')[frame])).replace('channel001', 'channel099')\n",
    "            # save out labelled image\n",
    "            imsave(fn, mask.astype(np.uint8), check_contrast=False)\n",
    "\n",
    "        print('Segmentation complete for', expt, pos)\n",
    "\n",
    "        print('Starting object localisation for', expt, pos)\n",
    "\n",
    "        transform_path = f'{root_dir}/{expt}/{pos}/transform_tensor.npy'\n",
    "        images = DaskOctopusLiteLoader(image_path, \n",
    "                                      # transforms=transform_path,\n",
    "                                       crop=(1200,1600), \n",
    "                                       remove_background=True)\n",
    "\n",
    "        objects = btrack.utils.segmentation_to_objects(\n",
    "            images['mask'],\n",
    "            images['gfp'],\n",
    "            properties = ('area', 'eccentricity', 'mean_intensity'),\n",
    "            assign_class_ID = True,\n",
    "        )\n",
    "\n",
    "        objects_gfp = [obj for obj in objects if obj.properties['class id'] == 1]\n",
    "        objects_rfp = [obj for obj in objects if obj.properties['class id'] == 2]\n",
    "\n",
    "        model = load_model('../models/cellx_classifier_stardist.h5')\n",
    "\n",
    "        bf = images['brightfield']\n",
    "        gfp = images['gfp']\n",
    "        rfp = images['rfp']\n",
    "        \n",
    "        print('Classifying objects in', expt, pos)\n",
    "        objects_gfp = classify_objects(bf, gfp, rfp, objects_gfp, obj_type = 1)\n",
    "        objects_rfp = classify_objects(bf, gfp, rfp, objects_rfp, obj_type = 2)\n",
    "\n",
    "        with btrack.dataio.HDF5FileHandler(\n",
    "            f'{root_dir}/{expt}/{pos}/objects_type_1.h5', 'w', obj_type='obj_type_1',\n",
    "        ) as hdf:\n",
    "            #hdf.write_segmentation(masks['mask'])\n",
    "            hdf.write_objects(objects_gfp)\n",
    "\n",
    "        with btrack.dataio.HDF5FileHandler(\n",
    "            f'{root_dir}/{expt}/{pos}/objects_type_2.h5', 'w', obj_type='obj_type_2',\n",
    "        ) as hdf:\n",
    "            #hdf.write_segmentation(masks['mask'])\n",
    "            hdf.write_objects(objects_rfp)\n",
    "\n",
    "        with btrack.dataio.HDF5FileHandler(\n",
    "            f'{root_dir}/{expt}/{pos}/objects.h5', 'w', obj_type='obj_type_1',\n",
    "        ) as hdf:\n",
    "            #hdf.write_segmentation(masks['mask'])\n",
    "            hdf.write_objects(objects_gfp)\n",
    "\n",
    "        with btrack.dataio.HDF5FileHandler(\n",
    "            f'{root_dir}/{expt}/{pos}/objects.h5', 'a', obj_type='obj_type_2',\n",
    "        ) as hdf:\n",
    "            #hdf.write_segmentation(masks['mask'])\n",
    "            hdf.write_objects(objects_rfp)\n",
    "\n",
    "        print('Object localisation complete for', expt, pos)\n",
    "\n",
    "        print('Starting tracking for', expt, pos)\n",
    "\n",
    "        # initialise a tracker session using a context manager\n",
    "        with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "            # configure the tracker using a config file\n",
    "            tracker.configure_from_file(\n",
    "                '../models/MDCK_config_wildtype.json'\n",
    "            )\n",
    "            tracker.max_search_radius = 40\n",
    "\n",
    "            # append the objects to be tracked\n",
    "            tracker.append(objects_gfp)\n",
    "\n",
    "            # set the volume\n",
    "            tracker.volume=((0, 1600), (0, 1200), (-1e5, 1e5))\n",
    "\n",
    "            # track them (in interactive mode)\n",
    "            tracker.track_interactive(step_size=100)\n",
    "\n",
    "            # generate hypotheses and run the global optimizer\n",
    "            tracker.optimize()\n",
    "\n",
    "            tracker.export(f'{root_dir}/{expt}/{pos}/tracks.h5', obj_type='obj_type_1')\n",
    "\n",
    "            # get the tracks in a format for napari visualization (optional)\n",
    "            visaulise_tracks, properties, graph = tracker.to_napari(ndim=2)\n",
    "\n",
    "            gfp_tracks = tracker.tracks\n",
    "\n",
    "        # initialise a tracker session using a context manager\n",
    "        with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "            # configure the tracker using a config file\n",
    "            tracker.configure_from_file(\n",
    "                '../models/MDCK_config_scribble_sparse.json'\n",
    "            )\n",
    "            tracker.max_search_radius = 40\n",
    "\n",
    "            # append the objects to be tracked\n",
    "            tracker.append(objects_rfp)\n",
    "\n",
    "            # set the volume\n",
    "            tracker.volume=((0, 1600), (0, 1200), (-1e5, 1e5))\n",
    "\n",
    "            # track them (in interactive mode)\n",
    "            tracker.track_interactive(step_size=100)\n",
    "\n",
    "            # generate hypotheses and run the global optimizer\n",
    "            tracker.optimize()\n",
    "\n",
    "            tracker.export(f'{root_dir}/{expt}/{pos}/tracks.h5', obj_type='obj_type_2')\n",
    "\n",
    "            # get the tracks in a format for napari visualization (optional)\n",
    "            visaulise_tracks, properties, graph = tracker.to_napari(ndim=2)\n",
    "\n",
    "            rfp_tracks = tracker.tracks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
