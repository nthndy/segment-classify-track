{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a18649de",
   "metadata": {},
   "source": [
    "# Complete pre-analysis cell labelling pipeline\n",
    "\n",
    "1. Alignment\n",
    "2. Segmentation\n",
    "3. Object localisation\n",
    "4. Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca1b454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import enum\n",
    "import re\n",
    "import numpy as np\n",
    "import btrack\n",
    "import pandas as pd\n",
    "from pystackreg import StackReg\n",
    "from skimage.io import imsave, imread\n",
    "from tqdm.auto import tqdm\n",
    "from octopuslite import DaskOctopusLiteLoader\n",
    "from skimage import transform as tf\n",
    "from skimage.transform import resize ### tidy up these dependencies\n",
    "from stardist.models import StarDist2D \n",
    "from stardist.plot import render_label\n",
    "from csbdeep.utils import normalize\n",
    "from scipy import ndimage as nd\n",
    "from scipy.special import softmax\n",
    "from cellx import load_model\n",
    "from cellx.tools.image import InfinitePaddedImage\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import binary_erosion, remove_small_objects\n",
    "from natsort import natsorted\n",
    "\n",
    "seg_model = StarDist2D.from_pretrained('2D_versatile_fluo')\n",
    "\n",
    "def image_generator(files, crop = None):\n",
    "    \n",
    "    if crop is None:\n",
    "        for filename in files:\n",
    "            img = imread(filename)\n",
    "            yield img\n",
    "    else:\n",
    "        for filename in files:\n",
    "            img = imread(filename)\n",
    "            img = crop_image(img, crop)\n",
    "            yield img\n",
    "\n",
    "def normalize_channels(x):\n",
    "\n",
    "    for dim in range(x.shape[-1]):\n",
    "        x[..., dim] = normalize(x[..., dim])\n",
    "        \n",
    "    return x\n",
    "\n",
    "def normalize(x):\n",
    "\n",
    "    xf = x.astype(np.float32)\n",
    "    mx = np.mean(xf)\n",
    "    sd = np.max([np.std(xf), 1./np.prod(x.shape)])\n",
    "\n",
    "    return (xf - mx) / sd\n",
    "\n",
    "def classify_objects(image,  gfp, rfp, objects, obj_type):\n",
    "    \n",
    "    # define stages of cell cycle to classify (dependent on model type)\n",
    "    LABELS = [\"interphase\", \"prometaphase\", \"metaphase\", \"anaphase\", \"apoptosis\"]\n",
    "    \n",
    "    # iterate over frames\n",
    "    for n in tqdm(range(image.shape[0])):\n",
    "        \n",
    "        # only select objects if in frame\n",
    "        _objects = [o for o in objects if o.t == n]\n",
    "        \n",
    "        # empty placeholder arrays\n",
    "        crops = []\n",
    "        to_update = []\n",
    "        \n",
    "        # select h2b channel to aid in classification\n",
    "        fp = gfp if obj_type == 1 else rfp\n",
    "        \n",
    "        # create stack by computing each frame of dask array input\n",
    "        frame = np.stack(\n",
    "            [image[n, ...].compute(), fp[n, ...].compute()], \n",
    "            axis=-1,) \n",
    "        \n",
    "        # create padded image for network\n",
    "        vol = InfinitePaddedImage(frame, mode = 'reflect')\n",
    "        \n",
    "        # iterate over objects \n",
    "        for obj in _objects:\n",
    "            \n",
    "            # create coords for image slice\n",
    "            xs = slice(int(obj.x-40), int(obj.x+40), 1)\n",
    "            ys = slice(int(obj.y-40), int(obj.y+40), 1)\n",
    "            \n",
    "            # crop image\n",
    "            crop = vol[ys, xs, :]\n",
    "            crop = resize(crop, (64, 64), preserve_range=True).astype(np.float32)\n",
    "            \n",
    "            # normalise image\n",
    "            if crop.shape == (64 ,64, 2):\n",
    "                crops.append(normalize_channels(crop))\n",
    "                to_update.append(obj)\n",
    "            else:\n",
    "                print(crop.shape)\n",
    "                \n",
    "        if not crops:\n",
    "            continue\n",
    "            \n",
    "        # use classifcation model to predict\n",
    "        pred = model.predict(np.stack(crops, axis=0))\n",
    "        \n",
    "        # check correct number of predictions\n",
    "        assert pred.shape[0] == len(_objects)\n",
    "        \n",
    "        # assign labels to objects\n",
    "        for idx in range(pred.shape[0]):\n",
    "            obj = _objects[idx]\n",
    "            \n",
    "            # assigning details of prediction\n",
    "            pred_label = np.argmax(pred[idx, ...])\n",
    "            pred_softmax = softmax(pred[idx, ...])\n",
    "            logits = {f\"prob_{k}\": pred_softmax[ki] for ki, k in enumerate(LABELS)}\n",
    "            \n",
    "            # write out\n",
    "            obj.label = pred_label\n",
    "            obj.properties = logits\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c293c3cb",
   "metadata": {},
   "source": [
    "# Experiment info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa7aedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_info = pd.read_csv('/home/nathan/data/kraken/ras/experiment_info_april22.csv')\n",
    "del expt_info['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d2775b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiments</th>\n",
       "      <th>Positions</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Position notes</th>\n",
       "      <th>Experiment Notes</th>\n",
       "      <th>Usable?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ND0000</td>\n",
       "      <td>Pos0</td>\n",
       "      <td>MDCK Rasv12 -</td>\n",
       "      <td>uninduced</td>\n",
       "      <td>stopped due to focus issue</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ND0000</td>\n",
       "      <td>Pos1</td>\n",
       "      <td>50:50 wt:ras+</td>\n",
       "      <td>induced</td>\n",
       "      <td>stopped due to focus issue</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ND0000</td>\n",
       "      <td>Pos2</td>\n",
       "      <td>MDCK Rasv12 +</td>\n",
       "      <td>induced</td>\n",
       "      <td>stopped due to focus issue</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ND0000</td>\n",
       "      <td>Pos3</td>\n",
       "      <td>50:50 wt:ras+</td>\n",
       "      <td>induced</td>\n",
       "      <td>stopped due to focus issue</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ND0000</td>\n",
       "      <td>Pos4</td>\n",
       "      <td>50:50 wt:ras-</td>\n",
       "      <td>uninduced</td>\n",
       "      <td>stopped due to focus issue</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>ND0025</td>\n",
       "      <td>Pos9</td>\n",
       "      <td>97.5:2.5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>ND0025</td>\n",
       "      <td>Pos10</td>\n",
       "      <td>97.5:2.5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>ND0025</td>\n",
       "      <td>Pos11</td>\n",
       "      <td>97.5:2.5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>ND0025</td>\n",
       "      <td>Pos12</td>\n",
       "      <td>97.5:2.5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>ND0025</td>\n",
       "      <td>Pos13</td>\n",
       "      <td>97.5:2.5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Experiments Positions         Condition        Position notes  \\\n",
       "0        ND0000      Pos0     MDCK Rasv12 -             uninduced   \n",
       "1        ND0000      Pos1     50:50 wt:ras+               induced   \n",
       "2        ND0000      Pos2     MDCK Rasv12 +               induced   \n",
       "3        ND0000      Pos3     50:50 wt:ras+               induced   \n",
       "4        ND0000      Pos4     50:50 wt:ras-             uninduced   \n",
       "..          ...       ...               ...                   ...   \n",
       "336      ND0025      Pos9  97.5:2.5 wt:ras+  induced 3x seed dens   \n",
       "337      ND0025     Pos10  97.5:2.5 wt:ras+  induced 3x seed dens   \n",
       "338      ND0025     Pos11  97.5:2.5 wt:ras+  induced 3x seed dens   \n",
       "339      ND0025     Pos12  97.5:2.5 wt:ras+  induced 3x seed dens   \n",
       "340      ND0025     Pos13  97.5:2.5 wt:ras+  induced 3x seed dens   \n",
       "\n",
       "               Experiment Notes Usable?  \n",
       "0    stopped due to focus issue   False  \n",
       "1    stopped due to focus issue   False  \n",
       "2    stopped due to focus issue   False  \n",
       "3    stopped due to focus issue   False  \n",
       "4    stopped due to focus issue   False  \n",
       "..                          ...     ...  \n",
       "336                         NaN    True  \n",
       "337                         NaN    True  \n",
       "338                         NaN    True  \n",
       "339                         NaN    True  \n",
       "340                           .    True  \n",
       "\n",
       "[341 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expt_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf62abb2",
   "metadata": {},
   "source": [
    "##### Just 99:1 expts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45800183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiments</th>\n",
       "      <th>Positions</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Position notes</th>\n",
       "      <th>Experiment Notes</th>\n",
       "      <th>Usable?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>ND0014</td>\n",
       "      <td>Pos5</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>ND0014</td>\n",
       "      <td>Pos6</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 2x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>ND0014</td>\n",
       "      <td>Pos7</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 2x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>ND0014</td>\n",
       "      <td>Pos8</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 2x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>ND0014</td>\n",
       "      <td>Pos9</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 2x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>ND0017</td>\n",
       "      <td>Pos3</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>ND0017</td>\n",
       "      <td>Pos4</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>ND0017</td>\n",
       "      <td>Pos5</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>ND0017</td>\n",
       "      <td>Pos6</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>ND0017</td>\n",
       "      <td>Pos7</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>ND0021</td>\n",
       "      <td>Pos3</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>ND0021</td>\n",
       "      <td>Pos4</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>ND0021</td>\n",
       "      <td>Pos5</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>ND0021</td>\n",
       "      <td>Pos6</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>ND0021</td>\n",
       "      <td>Pos7</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>ND0022</td>\n",
       "      <td>Pos3</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>ND0022</td>\n",
       "      <td>Pos4</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>ND0022</td>\n",
       "      <td>Pos5</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>ND0022</td>\n",
       "      <td>Pos6</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>ND0022</td>\n",
       "      <td>Pos7</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>ND0024</td>\n",
       "      <td>Pos3</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>ND0024</td>\n",
       "      <td>Pos4</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>ND0024</td>\n",
       "      <td>Pos5</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>ND0024</td>\n",
       "      <td>Pos6</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>ND0024</td>\n",
       "      <td>Pos7</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>ND0025</td>\n",
       "      <td>Pos3</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>ND0025</td>\n",
       "      <td>Pos4</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>ND0025</td>\n",
       "      <td>Pos5</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>ND0025</td>\n",
       "      <td>Pos6</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>ND0025</td>\n",
       "      <td>Pos7</td>\n",
       "      <td>99:1 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Experiments Positions     Condition        Position notes  \\\n",
       "178      ND0014      Pos5  99:1 wt:ras+               induced   \n",
       "179      ND0014      Pos6  99:1 wt:ras+  induced 2x seed dens   \n",
       "180      ND0014      Pos7  99:1 wt:ras+  induced 2x seed dens   \n",
       "181      ND0014      Pos8  99:1 wt:ras+  induced 2x seed dens   \n",
       "182      ND0014      Pos9  99:1 wt:ras+  induced 2x seed dens   \n",
       "218      ND0017      Pos3  99:1 wt:ras+  induced 3x seed dens   \n",
       "219      ND0017      Pos4  99:1 wt:ras+  induced 3x seed dens   \n",
       "220      ND0017      Pos5  99:1 wt:ras+  induced 3x seed dens   \n",
       "221      ND0017      Pos6  99:1 wt:ras+  induced 3x seed dens   \n",
       "222      ND0017      Pos7  99:1 wt:ras+  induced 3x seed dens   \n",
       "274      ND0021      Pos3  99:1 wt:ras+  induced 3x seed dens   \n",
       "275      ND0021      Pos4  99:1 wt:ras+  induced 3x seed dens   \n",
       "276      ND0021      Pos5  99:1 wt:ras+  induced 3x seed dens   \n",
       "277      ND0021      Pos6  99:1 wt:ras+  induced 3x seed dens   \n",
       "278      ND0021      Pos7  99:1 wt:ras+  induced 3x seed dens   \n",
       "288      ND0022      Pos3  99:1 wt:ras+  induced 3x seed dens   \n",
       "289      ND0022      Pos4  99:1 wt:ras+  induced 3x seed dens   \n",
       "290      ND0022      Pos5  99:1 wt:ras+  induced 3x seed dens   \n",
       "291      ND0022      Pos6  99:1 wt:ras+  induced 3x seed dens   \n",
       "292      ND0022      Pos7  99:1 wt:ras+  induced 3x seed dens   \n",
       "316      ND0024      Pos3  99:1 wt:ras+  induced 3x seed dens   \n",
       "317      ND0024      Pos4  99:1 wt:ras+  induced 3x seed dens   \n",
       "318      ND0024      Pos5  99:1 wt:ras+  induced 3x seed dens   \n",
       "319      ND0024      Pos6  99:1 wt:ras+  induced 3x seed dens   \n",
       "320      ND0024      Pos7  99:1 wt:ras+  induced 3x seed dens   \n",
       "330      ND0025      Pos3  99:1 wt:ras+  induced 3x seed dens   \n",
       "331      ND0025      Pos4  99:1 wt:ras+  induced 3x seed dens   \n",
       "332      ND0025      Pos5  99:1 wt:ras+  induced 3x seed dens   \n",
       "333      ND0025      Pos6  99:1 wt:ras+  induced 3x seed dens   \n",
       "334      ND0025      Pos7  99:1 wt:ras+  induced 3x seed dens   \n",
       "\n",
       "    Experiment Notes Usable?  \n",
       "178              NaN    True  \n",
       "179              NaN    True  \n",
       "180              NaN    True  \n",
       "181              NaN    True  \n",
       "182              NaN    True  \n",
       "218              NaN    True  \n",
       "219              NaN    True  \n",
       "220              NaN    True  \n",
       "221              NaN    True  \n",
       "222              NaN    True  \n",
       "274              NaN    True  \n",
       "275              NaN    True  \n",
       "276              NaN    True  \n",
       "277              NaN    True  \n",
       "278              NaN    True  \n",
       "288              NaN    True  \n",
       "289              NaN    True  \n",
       "290              NaN    True  \n",
       "291              NaN    True  \n",
       "292              NaN    True  \n",
       "316              NaN    True  \n",
       "317              NaN    True  \n",
       "318              NaN    True  \n",
       "319              NaN    True  \n",
       "320              NaN    True  \n",
       "330              NaN    True  \n",
       "331              NaN    True  \n",
       "332              NaN    True  \n",
       "333              NaN    True  \n",
       "334              NaN    True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expt_pos_list = expt_info.loc[(expt_info['Usable?'] == True) & \n",
    "                              (expt_info['Condition'] == \"99:1 wt:ras+\" ) &\n",
    "                              (expt_info['Experiments'] != \"ND0023\" ) &\n",
    "                              (expt_info['Experiments'] != \"ND0016\" ) &\n",
    "                              (expt_info['Experiments'] != \"ND0018\" ) &\n",
    "                              (expt_info['Experiments'] != \"ND0019\" ) ]\n",
    "expt_pos_list\n",
    "# expt_pos_list = expt_info.loc[(expt_info['Useable (in radial analysis)'] == True) & \n",
    "#                               (expt_info['CELL TYPE'] == \"99:1 wt:ras+\" ) &\n",
    "#                               (expt_info['EXP n˚'] != \"ND0023\" ) ][['EXP n˚','POSITION', 'CELL TYPE', 'FRAMES n˚']]\n",
    "# expt_pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "429be9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### sort by fewer frames first, sorting as string has the unintended habit of putting <1000 to the back which i want for now\n",
    "# expt_pos_list['FRAMES n˚'] = expt_pos_list['FRAMES n˚'].astype(int) ## convert to int\n",
    "# expt_pos_list = expt_pos_list.sort_values(by=['FRAMES n˚'], ascending = True)\n",
    "# expt_pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2625540",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d996a77de2e4ca5baadb5392184f40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress of experiment annotation:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting alignment for ND0014/Pos5\n",
      "Starting segmentation for ND0014 Pos5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304f265acd224675bfd46993d6c3291b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1425 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0014 Pos5\n",
      "Starting object localisation for ND0014 Pos5\n",
      "Starting tracking for ND0014 Pos5\n",
      "Starting alignment for ND0014/Pos6\n",
      "Starting segmentation for ND0014 Pos6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c14b1410237466c8f8beab8bb6522e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0014 Pos6\n",
      "Starting object localisation for ND0014 Pos6\n",
      "Starting tracking for ND0014 Pos6\n",
      "Starting alignment for ND0014/Pos7\n",
      "Starting segmentation for ND0014 Pos7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f46c510c222481c9d938ac5c1454c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0014 Pos7\n",
      "Starting object localisation for ND0014 Pos7\n",
      "Starting tracking for ND0014 Pos7\n",
      "Starting alignment for ND0014/Pos8\n",
      "Starting segmentation for ND0014 Pos8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc06757a7bce48599b6571a603376ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0014 Pos8\n",
      "Starting object localisation for ND0014 Pos8\n",
      "Starting tracking for ND0014 Pos8\n",
      "Starting alignment for ND0014/Pos9\n",
      "Starting segmentation for ND0014 Pos9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6002ceea791d458cb6fc04f1728298c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1429 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0014 Pos9\n",
      "Starting object localisation for ND0014 Pos9\n",
      "Starting tracking for ND0014 Pos9\n",
      "Starting alignment for ND0017/Pos3\n",
      "Starting segmentation for ND0017 Pos3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c94fbbb712436c94f59ba9674e343c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0017 Pos3\n",
      "Starting object localisation for ND0017 Pos3\n",
      "Starting tracking for ND0017 Pos3\n",
      "Starting alignment for ND0017/Pos4\n",
      "Starting segmentation for ND0017 Pos4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621d5e2ebab14228a6b67ab77b4d969b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0017 Pos4\n",
      "Starting object localisation for ND0017 Pos4\n",
      "Starting tracking for ND0017 Pos4\n",
      "Starting alignment for ND0017/Pos5\n",
      "Starting segmentation for ND0017 Pos5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d390bb8c05d434a86050dccee199bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0017 Pos5\n",
      "Starting object localisation for ND0017 Pos5\n",
      "Starting tracking for ND0017 Pos5\n",
      "Starting alignment for ND0017/Pos6\n",
      "Starting segmentation for ND0017 Pos6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ba786b523f47acbc73537a794401c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0017 Pos6\n",
      "Starting object localisation for ND0017 Pos6\n",
      "Starting tracking for ND0017 Pos6\n",
      "Starting alignment for ND0017/Pos7\n",
      "Starting segmentation for ND0017 Pos7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c026fc4e92464d10bcbeadcc5ab00fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0017 Pos7\n",
      "Starting object localisation for ND0017 Pos7\n",
      "Starting tracking for ND0017 Pos7\n",
      "Starting alignment for ND0021/Pos3\n",
      "Starting segmentation for ND0021 Pos3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954d7368559846c8abbe63d23dbeb75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2067 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0021 Pos3\n",
      "Starting object localisation for ND0021 Pos3\n",
      "Starting tracking for ND0021 Pos3\n",
      "Starting alignment for ND0021/Pos4\n",
      "Starting segmentation for ND0021 Pos4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604f7f3d7b8048cfba0d2eccc5458a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0021 Pos4\n",
      "Starting object localisation for ND0021 Pos4\n",
      "Using cropping: (1200, 1600)\n",
      "Classifying objects in ND0021 Pos4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3377184f49ce4d1bb7208ba0b3452493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3a55a9b36f4d97a924e04e4ffca670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object localisation complete for ND0021 Pos4\n",
      "Starting tracking for ND0021 Pos4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/05/19 04:10:42 PM] btrack (v0.4.3) library imported\n",
      "[INFO][2022/05/19 04:10:42 PM] Setting max XYZ search radius to: 100\n",
      "[INFO][2022/05/19 04:10:42 PM] Starting BayesianTracker session\n",
      "[INFO][2022/05/19 04:10:42 PM] Loading motion model: MDCK_motion\n",
      "[INFO][2022/05/19 04:10:42 PM] Setting max XYZ search radius to: 40\n",
      "[INFO][2022/05/19 04:10:43 PM] Set volume to ((0, 1600), (0, 1200), (-100000.0, 100000.0))\n",
      "[INFO][2022/05/19 04:10:43 PM] Starting tracking... \n",
      "[INFO][2022/05/19 04:10:44 PM] Tracking objects in frames 0 to 99 (of 2071)...\n",
      "[INFO][2022/05/19 04:10:45 PM] Tracking objects in frames 100 to 199 (of 2071)...\n",
      "[INFO][2022/05/19 04:10:46 PM] Tracking objects in frames 200 to 299 (of 2071)...\n",
      "[INFO][2022/05/19 04:10:47 PM] Tracking objects in frames 300 to 399 (of 2071)...\n",
      "[INFO][2022/05/19 04:10:48 PM] Tracking objects in frames 400 to 499 (of 2071)...\n",
      "[INFO][2022/05/19 04:10:50 PM] Tracking objects in frames 500 to 599 (of 2071)...\n",
      "[INFO][2022/05/19 04:10:53 PM] Tracking objects in frames 600 to 699 (of 2071)...\n",
      "[INFO][2022/05/19 04:10:59 PM] Tracking objects in frames 700 to 799 (of 2071)...\n",
      "[INFO][2022/05/19 04:11:07 PM] Tracking objects in frames 800 to 899 (of 2071)...\n",
      "[INFO][2022/05/19 04:11:20 PM] Tracking objects in frames 900 to 999 (of 2071)...\n",
      "[INFO][2022/05/19 04:11:42 PM] Tracking objects in frames 1000 to 1099 (of 2071)...\n",
      "[INFO][2022/05/19 04:12:13 PM] Tracking objects in frames 1100 to 1199 (of 2071)...\n",
      "[INFO][2022/05/19 04:12:58 PM] Tracking objects in frames 1200 to 1299 (of 2071)...\n",
      "[INFO][2022/05/19 04:13:53 PM] Tracking objects in frames 1300 to 1399 (of 2071)...\n",
      "[INFO][2022/05/19 04:15:00 PM] Tracking objects in frames 1400 to 1499 (of 2071)...\n",
      "[INFO][2022/05/19 04:16:13 PM] Tracking objects in frames 1500 to 1599 (of 2071)...\n",
      "[INFO][2022/05/19 04:17:32 PM] Tracking objects in frames 1600 to 1699 (of 2071)...\n",
      "[INFO][2022/05/19 04:20:03 PM] Tracking objects in frames 1700 to 1799 (of 2071)...\n",
      "[INFO][2022/05/19 04:21:21 PM] Tracking objects in frames 1800 to 1899 (of 2071)...\n",
      "[INFO][2022/05/19 04:22:35 PM] Tracking objects in frames 1900 to 1999 (of 2071)...\n",
      "[INFO][2022/05/19 04:23:51 PM] Tracking objects in frames 2000 to 2071 (of 2071)...\n",
      "[INFO][2022/05/19 04:24:45 PM] SUCCESS.\n",
      "[INFO][2022/05/19 04:24:45 PM]  - Found 22374 tracks in 2071 frames (in 0.0s)\n",
      "[INFO][2022/05/19 04:24:45 PM]  - Inserted 20948 dummy objects to fill tracking gaps\n",
      "[INFO][2022/05/19 04:24:45 PM] Loading hypothesis model: MDCK_hypothesis_wildtype\n",
      "[INFO][2022/05/19 04:24:45 PM] Calculating hypotheses (relax: True)...\n",
      "[INFO][2022/05/19 04:27:20 PM]  - Fates.FALSE_POSITIVE: 5636 (of 22374)\n",
      "[INFO][2022/05/19 04:27:20 PM]  - Fates.LINK: 8301 (of 19840)\n",
      "[INFO][2022/05/19 04:27:20 PM]  - Fates.DIVIDE: 1606 (of 11383)\n",
      "[INFO][2022/05/19 04:27:20 PM]  - Fates.APOPTOSIS: 925 (of 1280)\n",
      "[INFO][2022/05/19 04:27:20 PM]  - Fates.INITIALIZE_BORDER: 1982 (of 3193)\n",
      "[INFO][2022/05/19 04:27:20 PM]  - Fates.INITIALIZE_FRONT: 186 (of 200)\n",
      "[INFO][2022/05/19 04:27:20 PM]  - Fates.INITIALIZE_LAZY: 3057 (of 18981)\n",
      "[INFO][2022/05/19 04:27:20 PM]  - Fates.TERMINATE_BORDER: 1878 (of 3100)\n",
      "[INFO][2022/05/19 04:27:20 PM]  - Fates.TERMINATE_BACK: 1103 (of 1239)\n",
      "[INFO][2022/05/19 04:27:20 PM]  - Fates.TERMINATE_LAZY: 2925 (of 18035)\n",
      "[INFO][2022/05/19 04:27:20 PM]  - TOTAL: 99625 hypotheses\n",
      "[INFO][2022/05/19 04:27:22 PM] Completed optimization with 14073 tracks\n",
      "[INFO][2022/05/19 04:28:03 PM] Ending BayesianTracker session\n",
      "[INFO][2022/05/19 04:28:05 PM] btrack (v0.4.3) library imported\n",
      "[INFO][2022/05/19 04:28:05 PM] Setting max XYZ search radius to: 100\n",
      "[INFO][2022/05/19 04:28:05 PM] Starting BayesianTracker session\n",
      "[INFO][2022/05/19 04:28:06 PM] Loading motion model: MDCK_motion\n",
      "[INFO][2022/05/19 04:28:06 PM] Setting max XYZ search radius to: 40\n",
      "[INFO][2022/05/19 04:28:06 PM] Set volume to ((0, 1600), (0, 1200), (-100000.0, 100000.0))\n",
      "[INFO][2022/05/19 04:28:06 PM] Starting tracking... \n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 0 to 99 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 100 to 199 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 200 to 299 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 300 to 399 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 400 to 499 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 500 to 599 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 600 to 699 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 700 to 799 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 800 to 899 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 900 to 999 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 1000 to 1099 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 1100 to 1199 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 1200 to 1299 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 1300 to 1399 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 1400 to 1499 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 1500 to 1599 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 1600 to 1699 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:06 PM] Tracking objects in frames 1700 to 1799 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:07 PM] Tracking objects in frames 1800 to 1899 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:07 PM] Tracking objects in frames 1900 to 1999 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:07 PM] Tracking objects in frames 2000 to 2071 (of 2071)...\n",
      "[INFO][2022/05/19 04:28:08 PM] SUCCESS.\n",
      "[INFO][2022/05/19 04:28:08 PM]  - Found 10488 tracks in 2071 frames (in 0.0s)\n",
      "[INFO][2022/05/19 04:28:08 PM]  - Inserted 3657 dummy objects to fill tracking gaps\n",
      "[INFO][2022/05/19 04:28:08 PM] Loading hypothesis model: MDCK_hypothesis_scribble_sparse\n",
      "[INFO][2022/05/19 04:28:08 PM] Calculating hypotheses (relax: True)...\n",
      "[INFO][2022/05/19 04:28:18 PM]  - Fates.FALSE_POSITIVE: 7217 (of 10488)\n",
      "[INFO][2022/05/19 04:28:18 PM]  - Fates.LINK: 1356 (of 2866)\n",
      "[INFO][2022/05/19 04:28:18 PM]  - Fates.DIVIDE: 140 (of 823)\n",
      "[INFO][2022/05/19 04:28:18 PM]  - Fates.APOPTOSIS: 1157 (of 1622)\n",
      "[INFO][2022/05/19 04:28:18 PM]  - Fates.INITIALIZE_BORDER: 176 (of 524)\n",
      "[INFO][2022/05/19 04:28:18 PM]  - Fates.INITIALIZE_FRONT: 4 (of 4)\n",
      "[INFO][2022/05/19 04:28:18 PM]  - Fates.INITIALIZE_LAZY: 1455 (of 9960)\n",
      "[INFO][2022/05/19 04:28:18 PM]  - Fates.TERMINATE_BORDER: 131 (of 513)\n",
      "[INFO][2022/05/19 04:28:18 PM]  - Fates.TERMINATE_BACK: 80 (of 156)\n",
      "[INFO][2022/05/19 04:28:18 PM]  - Fates.TERMINATE_LAZY: 407 (of 9819)\n",
      "[INFO][2022/05/19 04:28:18 PM]  - TOTAL: 36775 hypotheses\n",
      "[INFO][2022/05/19 04:28:18 PM] Completed optimization with 9132 tracks\n",
      "[INFO][2022/05/19 04:28:20 PM] Ending BayesianTracker session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting alignment for ND0021/Pos5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1d3acc31a8468a81da01b066754434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding mean values of image channels:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 25\n",
      "Using cropping: (500, 500)\n",
      "Registering alignment for Pos5 ND0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pystackreg.py (379): Detected axis 1 as the possible time axis for the stack due to its low variability, but axis 0 was supplied for registration. Are you sure you supplied the correct axis?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment complete for ND0021 Pos5\n",
      "Starting segmentation for ND0021 Pos5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f068c0b0870f4feabba08f510a75cadb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root_dir = '/home/nathan/data/kraken/ras'\n",
    "\n",
    "for i, expt_pos in tqdm(expt_pos_list.iterrows(), desc = 'Progress of experiment annotation', total = len(expt_pos_list)):    \n",
    "    expt = expt_pos['Experiments']\n",
    "    pos = expt_pos['Positions']\n",
    "\n",
    "    print(f'Starting alignment for {expt}/{pos}')\n",
    "\n",
    "    ### create new subdir of for raw files and move them all there\n",
    "    image_path = f'{root_dir}/{expt}/{pos}/{pos}_images'\n",
    "    if not os.path.exists(image_path):\n",
    "        os.mkdir(image_path)\n",
    "        files = sorted(glob.glob(f'{root_dir}/{expt}/{pos}/*.tif'))\n",
    "        for file in files:\n",
    "            os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_images'))\n",
    "\n",
    "    # check if blanks dir exists and make if not and move\n",
    "    if not os.path.exists(f'{root_dir}/{expt}/{pos}/{pos}_blanks'):\n",
    "        os.mkdir(f'{root_dir}/{expt}/{pos}/{pos}_blanks')\n",
    "        ### pre load files from raw file dir \n",
    "        images = DaskOctopusLiteLoader(image_path, remove_background= False)\n",
    "\n",
    "        ### measure mean pixel value arrays and use to find under/over-exposed frames\n",
    "        max_pixel = 200\n",
    "        min_pixel = 2\n",
    "        # set empty dict arrays for mean values \n",
    "        mean_arrays = {}\n",
    "        # set for dodgy frames (only unique entries)\n",
    "        dodgy_frame_list = set([])\n",
    "        #iterate over channels\n",
    "        for channel in tqdm(images.channels, desc = f'Finding mean values of image channels'):\n",
    "            if 'MASK' in channel.name:\n",
    "                continue\n",
    "            # find mean value of each frame in each channel\n",
    "            mean_arrays[channel.name] = [np.mean(img) for img in image_generator(images.files(channel.name))]\n",
    "            # iterate over frames\n",
    "            for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "                # check to see if mean frame pixel value meets criteria\n",
    "                if max_pixel < mean_value or mean_value < min_pixel:\n",
    "                    # if so add to delete list\n",
    "                    dodgy_frame_list.add(frame)\n",
    "        # format delete list to only include single values\n",
    "        dodgy_frame_list = list(dodgy_frame_list)\n",
    "        print('Number of under/over-exposed frames:', len(dodgy_frame_list))\n",
    "\n",
    "        # move blank images into this directory\n",
    "        for channel in images.channels:\n",
    "            for f in images.files(channel.name):\n",
    "                for i in dodgy_frame_list:\n",
    "                    if str(i).zfill(9) in f:\n",
    "                        os.rename(f, f.replace('_images', '_blanks'))\n",
    "\n",
    "    if not os.path.exists(f'{root_dir}/{expt}/{pos}/transform_tensor.npy'):\n",
    "        # crop central window out of reference image with blanks removed\n",
    "        reference_image = DaskOctopusLiteLoader(image_path, \n",
    "                                                crop = (500, 500)\n",
    "                                               )['gfp'].compute() \n",
    "\n",
    "\n",
    "        ### Register alignment\n",
    "        print('Registering alignment for', pos, expt)\n",
    "        # create operator using transformation type (translation)\n",
    "        sr = StackReg(StackReg.TRANSLATION) \n",
    "        # register each frame to the previous as transformation matrices/tensor\n",
    "        transform_tensor = sr.register_stack(reference_image, reference = 'previous', )\n",
    "\n",
    "        ### clip transformation tensor to eliminate any rare jumps, (1688-1600)/2=44\n",
    "        transform_tensor = np.clip(transform_tensor, a_max= 44, a_min = -44)\n",
    "\n",
    "        # save out transform tensor\n",
    "        np.save(f'{root_dir}/{expt}/{pos}/transform_tensor.npy', transform_tensor)\n",
    "\n",
    "        print('Alignment complete for', expt, pos)\n",
    "\n",
    "\n",
    "\n",
    "    print('Starting segmentation for', expt, pos)\n",
    "    # load images\n",
    "    images = DaskOctopusLiteLoader(image_path, \n",
    "                                   remove_background = True)\n",
    "    \n",
    "    \n",
    "    # iterate over images filenames \n",
    "    for frame, fn in tqdm(enumerate(images.files('gfp')),total = len(images.files('gfp'))):\n",
    "        # load two seperate images\n",
    "        if os.path.exists(fn.replace('channel001', 'channel099')):\n",
    "            continue\n",
    "        gfp = imread(fn)\n",
    "        # predict gfp labels with a higher threshold as the fl. signal is strong\n",
    "        labels, details = seg_model.predict_instances(normalize(gfp), prob_thresh=0.75)\n",
    "        # create empty mask image\n",
    "        mask = np.zeros(labels.shape, dtype = np.uint8)\n",
    "        # remove any small, unrealistically nuclear objects from seg output\n",
    "        labels = remove_small_objects(labels, min_size = 200)\n",
    "        ### image post processing, start at 1 to skip background label\n",
    "        for i in range(1, np.amax(labels)):\n",
    "            #needs erosion step to stop merging of labels\n",
    "            segment = labels == i\n",
    "            seg_props = regionprops(label(segment), cache = False)\n",
    "            ### if segment exists, subject to exclusion criteria\n",
    "            if seg_props:\n",
    "                ### if segment area is large and elliptical it is probably a missclassified ras cyto (keeping for future use)\n",
    "                if 3000 <= seg_props[0].area or seg_props[0].eccentricity > 0.95: \n",
    "                    ## below condition has been applied on some post processing but cannot be applied here as gpf mask will not have rfp hole in yet, should not matter though as most large gfp masks will be caught by size alone\n",
    "                    # or seg_props.area < (0.9*seg_props.filled_area):\n",
    "                    ### dont bother eroding the large ras cyto masks as will add time\n",
    "                    #segment = binary_erosion(segment)\n",
    "                    mask[segment] = 3\n",
    "                else:\n",
    "                    segment = binary_erosion(segment)\n",
    "                    mask[segment] = 1\n",
    "\n",
    "        # now do the same for the rfp channel\n",
    "        rfp = imread(fn.replace('channel001', 'channel002'))   \n",
    "        # predict labels a much lower threshold as rfp signal is dim\n",
    "        labels, details = seg_model.predict_instances(normalize(rfp), prob_thresh=0.2)\n",
    "\n",
    "        ### remove small objects (low thresh picks up hot pixels) also reduce number of iterations needed for individual binary erosion\n",
    "        labels = remove_small_objects(labels, min_size = 200)\n",
    "\n",
    "        ### iterate over individual segments, eroding and reassigning label to not merge\n",
    "        for i in range(1, np.amax(labels)):\n",
    "            #needs erosion step to stop merging of labels\n",
    "            segment = labels == i\n",
    "            segment = binary_erosion(segment)\n",
    "            ## add to main mask\n",
    "            mask[segment] = 2\n",
    "\n",
    "        # set filename as mask format (channel099)\n",
    "        fn = ((images.files('gfp')[frame])).replace('channel001', 'channel099')\n",
    "        #save out labelled image\n",
    "        imsave(fn, mask.astype(np.uint8), check_contrast=False)\n",
    "        \n",
    "    print('Segmentation complete for', expt, pos)\n",
    "\n",
    "    \n",
    "    print('Starting object localisation for', expt, pos)\n",
    "    \n",
    "    if not os.path.exists(f'{root_dir}/{expt}/{pos}/objects.h5'):\n",
    "        transform_path = f'{root_dir}/{expt}/{pos}/transform_tensor.npy'\n",
    "        images = DaskOctopusLiteLoader(image_path, \n",
    "                                       transforms=transform_path,\n",
    "                                       crop=(1200,1600), \n",
    "                                       remove_background=True)\n",
    "\n",
    "        ## loading seperate instances of objects so that fl. intensities can be measured\n",
    "        objects_gfp = btrack.utils.segmentation_to_objects(\n",
    "            images['mask']==1,\n",
    "            images['gfp'],\n",
    "            properties = ('area', 'eccentricity', 'mean_intensity'),\n",
    "            assign_class_ID = True,\n",
    "        )\n",
    "        objects_rfp = btrack.utils.segmentation_to_objects(\n",
    "            (images['mask']==2)*2,\n",
    "            images['rfp'],\n",
    "            properties = ('area', 'eccentricity', 'mean_intensity'),\n",
    "            assign_class_ID = True,\n",
    "        )\n",
    "        ### filter for size\n",
    "        ### probably redundant two lines but just keeping as insurance\n",
    "    #         objects_gfp = [o for o in objects_gfp if 4000.>o.properties['area']>100.]\n",
    "    #         objects_rfp = [o for o in objects_rfp if 4000.>o.properties['area']>100.]\n",
    "    #         objects_gfp = [obj for obj in objects_gfp if obj.properties['class id'] == 1]\n",
    "    #         objects_rfp = [obj for obj in objects_rfp if obj.properties['class id'] == 2]\n",
    "\n",
    "        model = load_model('../models/cellx_classifier_stardist.h5')\n",
    "\n",
    "        bf = images['brightfield']\n",
    "        gfp = images['gfp']\n",
    "        rfp = images['rfp']\n",
    "\n",
    "        print('Classifying objects in', expt, pos)\n",
    "        objects_gfp = classify_objects(bf, gfp, rfp, objects_gfp, obj_type = 1)\n",
    "        objects_rfp = classify_objects(bf, gfp, rfp, objects_rfp, obj_type = 2)\n",
    "\n",
    "        with btrack.dataio.HDF5FileHandler(\n",
    "            f'{root_dir}/{expt}/{pos}/objects_type_1.h5', 'w', obj_type='obj_type_1',\n",
    "        ) as hdf:\n",
    "            #hdf.write_segmentation(masks['mask'])\n",
    "            hdf.write_objects(objects_gfp)    \n",
    "\n",
    "        with btrack.dataio.HDF5FileHandler(\n",
    "            f'{root_dir}/{expt}/{pos}/objects_type_2.h5', 'w', obj_type='obj_type_2',\n",
    "        ) as hdf:\n",
    "            #hdf.write_segmentation(masks['mask'])\n",
    "            hdf.write_objects(objects_rfp)\n",
    "\n",
    "        with btrack.dataio.HDF5FileHandler(\n",
    "            f'{root_dir}/{expt}/{pos}/objects.h5', 'w', obj_type='obj_type_1',\n",
    "        ) as hdf:\n",
    "            #hdf.write_segmentation(masks['mask'])\n",
    "            hdf.write_objects(objects_gfp)\n",
    "\n",
    "        with btrack.dataio.HDF5FileHandler(\n",
    "            f'{root_dir}/{expt}/{pos}/objects.h5', 'a', obj_type='obj_type_2',\n",
    "        ) as hdf:\n",
    "            #hdf.write_segmentation(masks['mask'])\n",
    "            hdf.write_objects(objects_rfp)\n",
    "\n",
    "        print('Object localisation complete for', expt, pos)\n",
    "\n",
    "    print('Starting tracking for', expt, pos)\n",
    "\n",
    "    if not os.path.exists(f'{root_dir}/{expt}/{pos}/tracks.h5'):\n",
    "        # initialise a tracker session using a context manager\n",
    "        with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "            # configure the tracker using a config file\n",
    "            tracker.configure_from_file(\n",
    "                '../models/MDCK_config_wildtype.json'\n",
    "            )\n",
    "            tracker.max_search_radius = 40\n",
    "\n",
    "            # append the objects to be tracked\n",
    "            tracker.append(objects_gfp)\n",
    "\n",
    "            # set the volume\n",
    "            tracker.volume=((0, 1600), (0, 1200), (-1e5, 1e5))\n",
    "\n",
    "            # track them (in interactive mode)\n",
    "            tracker.track_interactive(step_size=100)\n",
    "\n",
    "            # generate hypotheses and run the global optimizer\n",
    "            tracker.optimize()\n",
    "\n",
    "            tracker.export(f'{root_dir}/{expt}/{pos}/tracks.h5', obj_type='obj_type_1')\n",
    "\n",
    "            # get the tracks in a format for napari visualization (optional)\n",
    "    #         visaulise_tracks, properties, graph = tracker.to_napari(ndim=2)\n",
    "\n",
    "    #         gfp_tracks = tracker.tracks\n",
    "\n",
    "        # initialise a tracker session using a context manager\n",
    "        with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "            # configure the tracker using a config file\n",
    "            tracker.configure_from_file(\n",
    "                '../models/MDCK_config_scribble_sparse.json'\n",
    "            )\n",
    "            tracker.max_search_radius = 40\n",
    "\n",
    "            # append the objects to be tracked\n",
    "            tracker.append(objects_rfp)\n",
    "\n",
    "            # set the volume\n",
    "            tracker.volume=((0, 1600), (0, 1200), (-1e5, 1e5))\n",
    "\n",
    "            # track them (in interactive mode)\n",
    "            tracker.track_interactive(step_size=100)\n",
    "\n",
    "            # generate hypotheses and run the global optimizer\n",
    "            tracker.optimize()\n",
    "\n",
    "            tracker.export(f'{root_dir}/{expt}/{pos}/tracks.h5', obj_type='obj_type_2')\n",
    "\n",
    "    #         # get the tracks in a format for napari visualization (optional)\n",
    "    #         visaulise_tracks, properties, graph = tracker.to_napari(ndim=2)\n",
    "\n",
    "    #         rfp_tracks = tracker.tracks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
