{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a18649de",
   "metadata": {},
   "source": [
    "# Complete pre-analysis cell labelling pipeline\n",
    "\n",
    "1. Alignment\n",
    "2. Segmentation\n",
    "3. Object localisation\n",
    "4. Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca1b454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import enum\n",
    "import re\n",
    "import numpy as np\n",
    "import btrack\n",
    "import pandas as pd\n",
    "from pystackreg import StackReg\n",
    "from skimage.io import imsave, imread\n",
    "from tqdm.auto import tqdm\n",
    "from octopuslite import DaskOctopusLiteLoader\n",
    "from skimage import transform as tf\n",
    "from skimage.transform import resize ### tidy up these dependencies\n",
    "from stardist.models import StarDist2D \n",
    "from stardist.plot import render_label\n",
    "from csbdeep.utils import normalize\n",
    "from scipy import ndimage as nd\n",
    "from scipy.special import softmax\n",
    "from cellx import load_model\n",
    "from cellx.tools.image import InfinitePaddedImage\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import binary_erosion, remove_small_objects\n",
    "from natsort import natsorted\n",
    "\n",
    "seg_model = StarDist2D.from_pretrained('2D_versatile_fluo')\n",
    "\n",
    "def image_generator(files, crop = None):\n",
    "    \n",
    "    if crop is None:\n",
    "        for filename in files:\n",
    "            img = imread(filename)\n",
    "            yield img\n",
    "    else:\n",
    "        for filename in files:\n",
    "            img = imread(filename)\n",
    "            img = crop_image(img, crop)\n",
    "            yield img\n",
    "\n",
    "def normalize_channels(x):\n",
    "\n",
    "    for dim in range(x.shape[-1]):\n",
    "        x[..., dim] = normalize(x[..., dim])\n",
    "        \n",
    "    return x\n",
    "\n",
    "def normalize(x):\n",
    "\n",
    "    xf = x.astype(np.float32)\n",
    "    mx = np.mean(xf)\n",
    "    sd = np.max([np.std(xf), 1./np.prod(x.shape)])\n",
    "\n",
    "    return (xf - mx) / sd\n",
    "\n",
    "def classify_objects(image,  gfp, rfp, objects, obj_type):\n",
    "    \n",
    "    # define stages of cell cycle to classify (dependent on model type)\n",
    "    LABELS = [\"interphase\", \"prometaphase\", \"metaphase\", \"anaphase\", \"apoptosis\"]\n",
    "    \n",
    "    # iterate over frames\n",
    "    for n in tqdm(range(image.shape[0])):\n",
    "        \n",
    "        # only select objects if in frame\n",
    "        _objects = [o for o in objects if o.t == n]\n",
    "        \n",
    "        # empty placeholder arrays\n",
    "        crops = []\n",
    "        to_update = []\n",
    "        \n",
    "        # select h2b channel to aid in classification\n",
    "        fp = gfp if obj_type == 1 else rfp\n",
    "        \n",
    "        # create stack by computing each frame of dask array input\n",
    "        frame = np.stack(\n",
    "            [image[n, ...].compute(), fp[n, ...].compute()], \n",
    "            axis=-1,) \n",
    "        \n",
    "        # create padded image for network\n",
    "        vol = InfinitePaddedImage(frame, mode = 'reflect')\n",
    "        \n",
    "        # iterate over objects \n",
    "        for obj in _objects:\n",
    "            \n",
    "            # create coords for image slice\n",
    "            xs = slice(int(obj.x-40), int(obj.x+40), 1)\n",
    "            ys = slice(int(obj.y-40), int(obj.y+40), 1)\n",
    "            \n",
    "            # crop image\n",
    "            crop = vol[ys, xs, :]\n",
    "            crop = resize(crop, (64, 64), preserve_range=True).astype(np.float32)\n",
    "            \n",
    "            # normalise image\n",
    "            if crop.shape == (64 ,64, 2):\n",
    "                crops.append(normalize_channels(crop))\n",
    "                to_update.append(obj)\n",
    "            else:\n",
    "                print(crop.shape)\n",
    "                \n",
    "        if not crops:\n",
    "            continue\n",
    "            \n",
    "        # use classifcation model to predict\n",
    "        pred = model.predict(np.stack(crops, axis=0))\n",
    "        \n",
    "        # check correct number of predictions\n",
    "        assert pred.shape[0] == len(_objects)\n",
    "        \n",
    "        # assign labels to objects\n",
    "        for idx in range(pred.shape[0]):\n",
    "            obj = _objects[idx]\n",
    "            \n",
    "            # assigning details of prediction\n",
    "            pred_label = np.argmax(pred[idx, ...])\n",
    "            pred_softmax = softmax(pred[idx, ...])\n",
    "            logits = {f\"prob_{k}\": pred_softmax[ki] for ki, k in enumerate(LABELS)}\n",
    "            \n",
    "            # write out\n",
    "            obj.label = pred_label\n",
    "            obj.properties = logits\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c293c3cb",
   "metadata": {},
   "source": [
    "# Experiment info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa7aedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_info = pd.read_csv('/home/nathan/data/kraken/ras/experiment_info_april22.csv')\n",
    "del expt_info['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "130cde9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiments</th>\n",
       "      <th>Positions</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Position notes</th>\n",
       "      <th>Experiment Notes</th>\n",
       "      <th>Usable?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>ND0017</td>\n",
       "      <td>Pos9</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>ND0017</td>\n",
       "      <td>Pos10</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>ND0017</td>\n",
       "      <td>Pos11</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>ND0017</td>\n",
       "      <td>Pos12</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>ND0017</td>\n",
       "      <td>Pos13</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>ND0018</td>\n",
       "      <td>Pos9</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>micromanager error hence ending at 400 frames</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>ND0018</td>\n",
       "      <td>Pos10</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>micromanager error hence ending at 400 frames</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>ND0018</td>\n",
       "      <td>Pos11</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>micromanager error hence ending at 400 frames</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>ND0018</td>\n",
       "      <td>Pos12</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>micromanager error hence ending at 400 frames</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>ND0018</td>\n",
       "      <td>Pos13</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>micromanager error hence ending at 400 frames</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>ND0019</td>\n",
       "      <td>Pos9</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>micromanager error hence ending at 743frames, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>ND0019</td>\n",
       "      <td>Pos10</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>micromanager error hence ending at 743frames, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>ND0019</td>\n",
       "      <td>Pos11</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>micromanager error hence ending at 743frames, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>ND0019</td>\n",
       "      <td>Pos12</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>micromanager error hence ending at 743frames, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>ND0019</td>\n",
       "      <td>Pos13</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>micromanager error hence ending at 743frames, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>ND0021</td>\n",
       "      <td>Pos9</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>ND0021</td>\n",
       "      <td>Pos10</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>ND0021</td>\n",
       "      <td>Pos11</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>ND0021</td>\n",
       "      <td>Pos12</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>ND0021</td>\n",
       "      <td>Pos13</td>\n",
       "      <td>95:5 wt:ras+</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Experiments Positions     Condition        Position notes  \\\n",
       "224      ND0017      Pos9  95:5 wt:ras+  induced 3x seed dens   \n",
       "225      ND0017     Pos10  95:5 wt:ras+  induced 3x seed dens   \n",
       "226      ND0017     Pos11  95:5 wt:ras+  induced 3x seed dens   \n",
       "227      ND0017     Pos12  95:5 wt:ras+  induced 3x seed dens   \n",
       "228      ND0017     Pos13  95:5 wt:ras+  induced 3x seed dens   \n",
       "238      ND0018      Pos9  95:5 wt:ras+  induced 3x seed dens   \n",
       "239      ND0018     Pos10  95:5 wt:ras+  induced 3x seed dens   \n",
       "240      ND0018     Pos11  95:5 wt:ras+  induced 3x seed dens   \n",
       "241      ND0018     Pos12  95:5 wt:ras+  induced 3x seed dens   \n",
       "242      ND0018     Pos13  95:5 wt:ras+  induced 3x seed dens   \n",
       "252      ND0019      Pos9  95:5 wt:ras+  induced 3x seed dens   \n",
       "253      ND0019     Pos10  95:5 wt:ras+  induced 3x seed dens   \n",
       "254      ND0019     Pos11  95:5 wt:ras+  induced 3x seed dens   \n",
       "255      ND0019     Pos12  95:5 wt:ras+  induced 3x seed dens   \n",
       "256      ND0019     Pos13  95:5 wt:ras+  induced 3x seed dens   \n",
       "280      ND0021      Pos9  95:5 wt:ras+  induced 3x seed dens   \n",
       "281      ND0021     Pos10  95:5 wt:ras+  induced 3x seed dens   \n",
       "282      ND0021     Pos11  95:5 wt:ras+  induced 3x seed dens   \n",
       "283      ND0021     Pos12  95:5 wt:ras+  induced 3x seed dens   \n",
       "284      ND0021     Pos13  95:5 wt:ras+  induced 3x seed dens   \n",
       "\n",
       "                                      Experiment Notes Usable?  \n",
       "224                                                NaN    True  \n",
       "225                                                NaN    True  \n",
       "226                                                NaN    True  \n",
       "227                                                NaN    True  \n",
       "228                                                NaN    True  \n",
       "238      micromanager error hence ending at 400 frames    True  \n",
       "239      micromanager error hence ending at 400 frames    True  \n",
       "240      micromanager error hence ending at 400 frames    True  \n",
       "241      micromanager error hence ending at 400 frames    True  \n",
       "242      micromanager error hence ending at 400 frames    True  \n",
       "252  micromanager error hence ending at 743frames, ...    True  \n",
       "253  micromanager error hence ending at 743frames, ...    True  \n",
       "254  micromanager error hence ending at 743frames, ...    True  \n",
       "255  micromanager error hence ending at 743frames, ...    True  \n",
       "256  micromanager error hence ending at 743frames, ...    True  \n",
       "280                                                NaN    True  \n",
       "281                                                NaN    True  \n",
       "282                                                NaN    True  \n",
       "283                                                NaN    True  \n",
       "284                                                NaN    True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expt_pos_list = expt_info.loc[(expt_info['Usable?'] == True) & \n",
    "                              (expt_info['Condition'] == \"95:5 wt:ras+\" ) &\n",
    "                              (expt_info['Experiments'] != \"ND0023\" ) ]\n",
    "expt_pos_list\n",
    "# expt_pos_list = expt_info.loc[(expt_info['Useable (in radial analysis)'] == True) & \n",
    "#                               (expt_info['CELL TYPE'] == \"95:5 wt:ras+\" )][['EXP n˚','POSITION', 'CELL TYPE', 'FRAMES n˚']]\n",
    "# expt_pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ab9701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### sort by fewer frames first\n",
    "# expt_pos_list['FRAMES n˚'] = expt_pos_list['FRAMES n˚'].astype(int) ## convert to int\n",
    "# expt_pos_list = expt_pos_list.sort_values(by=['FRAMES n˚'])\n",
    "# expt_pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e968a639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0180dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2625540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36a71e74b9545f79c08e44c78cc6ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress of experiment annotation:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting alignment for ND0017/Pos9\n",
      "Starting segmentation for ND0017 Pos9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192f05c95204497e95f6a83380465040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0017 Pos9\n",
      "Starting object localisation for ND0017 Pos9\n",
      "Starting tracking for ND0017 Pos9\n",
      "Starting alignment for ND0017/Pos10\n",
      "Starting segmentation for ND0017 Pos10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43b4ee5798840dc8d6db0bcfd0f200e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0017 Pos10\n",
      "Starting object localisation for ND0017 Pos10\n",
      "Starting tracking for ND0017 Pos10\n",
      "Starting alignment for ND0017/Pos11\n",
      "Starting segmentation for ND0017 Pos11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a912ee628d934e3d83111fdb42a81e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0017 Pos11\n",
      "Starting object localisation for ND0017 Pos11\n",
      "Starting tracking for ND0017 Pos11\n",
      "Starting alignment for ND0017/Pos12\n",
      "Starting segmentation for ND0017 Pos12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a1c8540f064b0d8a9b37b6048c9248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0017 Pos12\n",
      "Starting object localisation for ND0017 Pos12\n",
      "Starting tracking for ND0017 Pos12\n",
      "Starting alignment for ND0017/Pos13\n",
      "Starting segmentation for ND0017 Pos13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc89dccc2a34772b88c35eab31dc28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0017 Pos13\n",
      "Starting object localisation for ND0017 Pos13\n",
      "Starting tracking for ND0017 Pos13\n",
      "Starting alignment for ND0018/Pos9\n",
      "Starting segmentation for ND0018 Pos9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa75452dd99347f0828ce5f96c71d125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0018 Pos9\n",
      "Starting object localisation for ND0018 Pos9\n",
      "Starting tracking for ND0018 Pos9\n",
      "Starting alignment for ND0018/Pos10\n",
      "Starting segmentation for ND0018 Pos10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5485059bc43c4d749fdab2b21cf657e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0018 Pos10\n",
      "Starting object localisation for ND0018 Pos10\n",
      "Starting tracking for ND0018 Pos10\n",
      "Starting alignment for ND0018/Pos11\n",
      "Starting segmentation for ND0018 Pos11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c848a55d3d44a8942a8717a76646c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/394 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0018 Pos11\n",
      "Starting object localisation for ND0018 Pos11\n",
      "Starting tracking for ND0018 Pos11\n",
      "Starting alignment for ND0018/Pos12\n",
      "Starting segmentation for ND0018 Pos12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6bf4aba5a7415088ab116368f0c420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/399 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0018 Pos12\n",
      "Starting object localisation for ND0018 Pos12\n",
      "Starting tracking for ND0018 Pos12\n",
      "Starting alignment for ND0018/Pos13\n",
      "Starting segmentation for ND0018 Pos13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69649b3fdf8544b797af98db243f6047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/396 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0018 Pos13\n",
      "Starting object localisation for ND0018 Pos13\n",
      "Starting tracking for ND0018 Pos13\n",
      "Starting alignment for ND0019/Pos9\n",
      "Starting segmentation for ND0019 Pos9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbabfe6acf34d269070561e7b0d57d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/729 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0019 Pos9\n",
      "Starting object localisation for ND0019 Pos9\n",
      "Starting tracking for ND0019 Pos9\n",
      "Starting alignment for ND0019/Pos10\n",
      "Starting segmentation for ND0019 Pos10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e6f429344e4bb0aff03fa162dfead3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/735 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0019 Pos10\n",
      "Starting object localisation for ND0019 Pos10\n",
      "Starting tracking for ND0019 Pos10\n",
      "Starting alignment for ND0019/Pos11\n",
      "Starting segmentation for ND0019 Pos11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6165ec8232c14381bf7c34551256bc77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/735 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0019 Pos11\n",
      "Starting object localisation for ND0019 Pos11\n",
      "Starting tracking for ND0019 Pos11\n",
      "Starting alignment for ND0019/Pos12\n",
      "Starting segmentation for ND0019 Pos12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710792fac81240498eca6f2395477047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0019 Pos12\n",
      "Starting object localisation for ND0019 Pos12\n",
      "Starting tracking for ND0019 Pos12\n",
      "Starting alignment for ND0019/Pos13\n",
      "Starting segmentation for ND0019 Pos13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d3cf9049f74ca4a53e4cdce5e16345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/734 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0019 Pos13\n",
      "Starting object localisation for ND0019 Pos13\n",
      "Starting tracking for ND0019 Pos13\n",
      "Starting alignment for ND0021/Pos9\n",
      "Starting segmentation for ND0021 Pos9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf04e29b0f94652af42d6a687164d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2097 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0021 Pos9\n",
      "Starting object localisation for ND0021 Pos9\n",
      "Starting tracking for ND0021 Pos9\n",
      "Starting alignment for ND0021/Pos10\n",
      "Starting segmentation for ND0021 Pos10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ef97cf05f84688bb01152ffc8ea156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2079 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0021 Pos10\n",
      "Starting object localisation for ND0021 Pos10\n",
      "Starting tracking for ND0021 Pos10\n",
      "Starting alignment for ND0021/Pos11\n",
      "Starting segmentation for ND0021 Pos11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20f91a8f87f43e9bc1dc922a2a43235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0021 Pos11\n",
      "Starting object localisation for ND0021 Pos11\n",
      "Starting tracking for ND0021 Pos11\n",
      "Starting alignment for ND0021/Pos12\n",
      "Starting segmentation for ND0021 Pos12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5bb5cf03379483794d7b53c1236a4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2070 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0021 Pos12\n",
      "Starting object localisation for ND0021 Pos12\n",
      "Starting tracking for ND0021 Pos12\n",
      "Starting alignment for ND0021/Pos13\n",
      "Starting segmentation for ND0021 Pos13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfc87a9a031469eb1a28a9786c322fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0021 Pos13\n",
      "Starting object localisation for ND0021 Pos13\n",
      "Using cropping: (1200, 1600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/04/20 02:12:00 AM] Localizing objects from segmentation...\n",
      "[INFO][2022/04/20 02:12:00 AM] Found intensity_image data\n",
      "[INFO][2022/04/20 02:12:00 AM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2022/04/20 02:36:38 AM] Objects are of type: <class 'dict'>\n",
      "[INFO][2022/04/20 02:36:45 AM] ...Found 929188 objects in 2071 frames.\n",
      "[INFO][2022/04/20 02:36:45 AM] Localizing objects from segmentation...\n",
      "[INFO][2022/04/20 02:36:45 AM] Found intensity_image data\n",
      "[INFO][2022/04/20 02:36:45 AM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2022/04/20 02:57:21 AM] Objects are of type: <class 'dict'>\n",
      "[INFO][2022/04/20 02:57:22 AM] ...Found 85669 objects in 2071 frames.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying objects in ND0021 Pos13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cc6586334e4b2ba4f0d556840f5967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ea7b8a8ed34b7a845a39899e0df630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/04/20 04:52:17 AM] Opening HDF file: /home/nathan/data/kraken/ras/ND0021/Pos13/objects_type_1.h5...\n",
      "[INFO][2022/04/20 04:52:25 AM] Writing objects/obj_type_1\n",
      "[INFO][2022/04/20 04:52:25 AM] Writing labels/obj_type_1\n",
      "[INFO][2022/04/20 04:52:25 AM] Loading objects/obj_type_1 (929188, 5) (929188 filtered: None)\n",
      "[INFO][2022/04/20 04:52:36 AM] Writing properties/obj_type_1/area (929188,)\n",
      "[INFO][2022/04/20 04:52:36 AM] Writing properties/obj_type_1/eccentricity (929188,)\n",
      "[INFO][2022/04/20 04:52:36 AM] Writing properties/obj_type_1/mean_intensity (929188,)\n",
      "[INFO][2022/04/20 04:52:36 AM] Writing properties/obj_type_1/class id (929188,)\n",
      "[INFO][2022/04/20 04:52:36 AM] Writing properties/obj_type_1/prob_interphase (929188,)\n",
      "[INFO][2022/04/20 04:52:37 AM] Writing properties/obj_type_1/prob_prometaphase (929188,)\n",
      "[INFO][2022/04/20 04:52:37 AM] Writing properties/obj_type_1/prob_metaphase (929188,)\n",
      "[INFO][2022/04/20 04:52:37 AM] Writing properties/obj_type_1/prob_anaphase (929188,)\n",
      "[INFO][2022/04/20 04:52:37 AM] Writing properties/obj_type_1/prob_apoptosis (929188,)\n",
      "[INFO][2022/04/20 04:52:37 AM] Closing HDF file: /home/nathan/data/kraken/ras/ND0021/Pos13/objects_type_1.h5\n",
      "[INFO][2022/04/20 04:52:37 AM] Opening HDF file: /home/nathan/data/kraken/ras/ND0021/Pos13/objects_type_2.h5...\n",
      "[INFO][2022/04/20 04:52:38 AM] Writing objects/obj_type_2\n",
      "[INFO][2022/04/20 04:52:38 AM] Writing labels/obj_type_2\n",
      "[INFO][2022/04/20 04:52:38 AM] Loading objects/obj_type_2 (85669, 5) (85669 filtered: None)\n",
      "[INFO][2022/04/20 04:52:39 AM] Writing properties/obj_type_2/area (85669,)\n",
      "[INFO][2022/04/20 04:52:39 AM] Writing properties/obj_type_2/eccentricity (85669,)\n",
      "[INFO][2022/04/20 04:52:39 AM] Writing properties/obj_type_2/mean_intensity (85669,)\n",
      "[INFO][2022/04/20 04:52:39 AM] Writing properties/obj_type_2/class id (85669,)\n",
      "[INFO][2022/04/20 04:52:39 AM] Writing properties/obj_type_2/prob_interphase (85669,)\n",
      "[INFO][2022/04/20 04:52:39 AM] Writing properties/obj_type_2/prob_prometaphase (85669,)\n",
      "[INFO][2022/04/20 04:52:39 AM] Writing properties/obj_type_2/prob_metaphase (85669,)\n",
      "[INFO][2022/04/20 04:52:39 AM] Writing properties/obj_type_2/prob_anaphase (85669,)\n",
      "[INFO][2022/04/20 04:52:39 AM] Writing properties/obj_type_2/prob_apoptosis (85669,)\n",
      "[INFO][2022/04/20 04:52:39 AM] Closing HDF file: /home/nathan/data/kraken/ras/ND0021/Pos13/objects_type_2.h5\n",
      "[INFO][2022/04/20 04:52:39 AM] Opening HDF file: /home/nathan/data/kraken/ras/ND0021/Pos13/objects.h5...\n",
      "[INFO][2022/04/20 04:52:46 AM] Writing objects/obj_type_1\n",
      "[INFO][2022/04/20 04:52:46 AM] Writing labels/obj_type_1\n",
      "[INFO][2022/04/20 04:52:46 AM] Loading objects/obj_type_1 (929188, 5) (929188 filtered: None)\n",
      "[INFO][2022/04/20 04:52:56 AM] Writing properties/obj_type_1/area (929188,)\n",
      "[INFO][2022/04/20 04:52:56 AM] Writing properties/obj_type_1/eccentricity (929188,)\n",
      "[INFO][2022/04/20 04:52:57 AM] Writing properties/obj_type_1/mean_intensity (929188,)\n",
      "[INFO][2022/04/20 04:52:57 AM] Writing properties/obj_type_1/class id (929188,)\n",
      "[INFO][2022/04/20 04:52:57 AM] Writing properties/obj_type_1/prob_interphase (929188,)\n",
      "[INFO][2022/04/20 04:52:57 AM] Writing properties/obj_type_1/prob_prometaphase (929188,)\n",
      "[INFO][2022/04/20 04:52:57 AM] Writing properties/obj_type_1/prob_metaphase (929188,)\n",
      "[INFO][2022/04/20 04:52:57 AM] Writing properties/obj_type_1/prob_anaphase (929188,)\n",
      "[INFO][2022/04/20 04:52:57 AM] Writing properties/obj_type_1/prob_apoptosis (929188,)\n",
      "[INFO][2022/04/20 04:52:57 AM] Closing HDF file: /home/nathan/data/kraken/ras/ND0021/Pos13/objects.h5\n",
      "[INFO][2022/04/20 04:52:57 AM] Opening HDF file: /home/nathan/data/kraken/ras/ND0021/Pos13/objects.h5...\n",
      "[INFO][2022/04/20 04:52:58 AM] Writing objects/obj_type_2\n",
      "[INFO][2022/04/20 04:52:58 AM] Writing labels/obj_type_2\n",
      "[INFO][2022/04/20 04:52:58 AM] Loading objects/obj_type_2 (85669, 5) (85669 filtered: None)\n",
      "[INFO][2022/04/20 04:52:59 AM] Writing properties/obj_type_2/area (85669,)\n",
      "[INFO][2022/04/20 04:52:59 AM] Writing properties/obj_type_2/eccentricity (85669,)\n",
      "[INFO][2022/04/20 04:52:59 AM] Writing properties/obj_type_2/mean_intensity (85669,)\n",
      "[INFO][2022/04/20 04:52:59 AM] Writing properties/obj_type_2/class id (85669,)\n",
      "[INFO][2022/04/20 04:52:59 AM] Writing properties/obj_type_2/prob_interphase (85669,)\n",
      "[INFO][2022/04/20 04:52:59 AM] Writing properties/obj_type_2/prob_prometaphase (85669,)\n",
      "[INFO][2022/04/20 04:52:59 AM] Writing properties/obj_type_2/prob_metaphase (85669,)\n",
      "[INFO][2022/04/20 04:52:59 AM] Writing properties/obj_type_2/prob_anaphase (85669,)\n",
      "[INFO][2022/04/20 04:52:59 AM] Writing properties/obj_type_2/prob_apoptosis (85669,)\n",
      "[INFO][2022/04/20 04:52:59 AM] Closing HDF file: /home/nathan/data/kraken/ras/ND0021/Pos13/objects.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object localisation complete for ND0021 Pos13\n",
      "Starting tracking for ND0021 Pos13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/04/20 04:53:01 AM] Loaded btrack: /home/nathan/analysis/BayesianTracker/btrack/libs/libtracker.so\n",
      "[INFO][2022/04/20 04:53:01 AM] btrack (v0.4.3) library imported\n",
      "[INFO][2022/04/20 04:53:01 AM] Setting max XYZ search radius to: 100\n",
      "[INFO][2022/04/20 04:53:01 AM] Starting BayesianTracker session\n",
      "[INFO][2022/04/20 04:53:01 AM] Loading configuration file: ../models/MDCK_config_wildtype.json\n",
      "[INFO][2022/04/20 04:53:01 AM] Loading motion model: MDCK_motion\n",
      "[INFO][2022/04/20 04:53:01 AM] Setting max XYZ search radius to: 40\n",
      "[INFO][2022/04/20 04:53:01 AM] Objects are of type: <class 'list'>\n",
      "[INFO][2022/04/20 04:53:02 AM] Set volume to ((0, 1600), (0, 1200), (-100000.0, 100000.0))\n",
      "[INFO][2022/04/20 04:53:02 AM] Starting tracking... \n",
      "[INFO][2022/04/20 04:53:02 AM] Tracking objects in frames 0 to 99 (of 2071)...\n",
      "[INFO][2022/04/20 04:53:03 AM]  - Timing (Bayesian updates: 7.59ms, Linking: 0.60ms)\n",
      "[INFO][2022/04/20 04:53:03 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:53:03 AM]  - Stats (Active: 203, Lost: 2213, Conflicts resolved: 549)\n",
      "[INFO][2022/04/20 04:53:03 AM] Tracking objects in frames 100 to 199 (of 2071)...\n",
      "[INFO][2022/04/20 04:53:04 AM]  - Timing (Bayesian updates: 8.83ms, Linking: 0.73ms)\n",
      "[INFO][2022/04/20 04:53:04 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:53:04 AM]  - Stats (Active: 222, Lost: 4652, Conflicts resolved: 1139)\n",
      "[INFO][2022/04/20 04:53:04 AM] Tracking objects in frames 200 to 299 (of 2071)...\n",
      "[INFO][2022/04/20 04:53:05 AM]  - Timing (Bayesian updates: 8.33ms, Linking: 0.65ms)\n",
      "[INFO][2022/04/20 04:53:05 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:53:05 AM]  - Stats (Active: 202, Lost: 6994, Conflicts resolved: 1607)\n",
      "[INFO][2022/04/20 04:53:05 AM] Tracking objects in frames 300 to 399 (of 2071)...\n",
      "[INFO][2022/04/20 04:53:06 AM]  - Timing (Bayesian updates: 13.10ms, Linking: 0.82ms)\n",
      "[INFO][2022/04/20 04:53:06 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:53:06 AM]  - Stats (Active: 259, Lost: 9692, Conflicts resolved: 2187)\n",
      "[INFO][2022/04/20 04:53:06 AM] Tracking objects in frames 400 to 499 (of 2071)...\n",
      "[INFO][2022/04/20 04:53:08 AM]  - Timing (Bayesian updates: 21.46ms, Linking: 1.10ms)\n",
      "[INFO][2022/04/20 04:53:08 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:53:08 AM]  - Stats (Active: 318, Lost: 13301, Conflicts resolved: 2960)\n",
      "[INFO][2022/04/20 04:53:08 AM] Tracking objects in frames 500 to 599 (of 2071)...\n",
      "[INFO][2022/04/20 04:53:10 AM]  - Timing (Bayesian updates: 29.77ms, Linking: 1.33ms)\n",
      "[INFO][2022/04/20 04:53:10 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:53:10 AM]  - Stats (Active: 351, Lost: 16600, Conflicts resolved: 3741)\n",
      "[INFO][2022/04/20 04:53:10 AM] Tracking objects in frames 600 to 699 (of 2071)...\n",
      "[INFO][2022/04/20 04:53:14 AM]  - Timing (Bayesian updates: 45.94ms, Linking: 1.70ms)\n",
      "[INFO][2022/04/20 04:53:14 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:53:14 AM]  - Stats (Active: 419, Lost: 20622, Conflicts resolved: 4741)\n",
      "[INFO][2022/04/20 04:53:14 AM] Tracking objects in frames 700 to 799 (of 2071)...\n",
      "[INFO][2022/04/20 04:53:20 AM]  - Timing (Bayesian updates: 65.31ms, Linking: 2.11ms)\n",
      "[INFO][2022/04/20 04:53:20 AM]  - Probabilities (Link: 0.99999, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:53:20 AM]  - Stats (Active: 481, Lost: 25821, Conflicts resolved: 6208)\n",
      "[INFO][2022/04/20 04:53:20 AM] Tracking objects in frames 800 to 899 (of 2071)...\n",
      "[INFO][2022/04/20 04:53:29 AM]  - Timing (Bayesian updates: 81.75ms, Linking: 2.36ms)\n",
      "[INFO][2022/04/20 04:53:29 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:53:29 AM]  - Stats (Active: 529, Lost: 31814, Conflicts resolved: 8020)\n",
      "[INFO][2022/04/20 04:53:29 AM] Tracking objects in frames 900 to 999 (of 2071)...\n",
      "[INFO][2022/04/20 04:53:38 AM]  - Timing (Bayesian updates: 102.07ms, Linking: 2.54ms)\n",
      "[INFO][2022/04/20 04:53:38 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:53:38 AM]  - Stats (Active: 562, Lost: 37110, Conflicts resolved: 9734)\n",
      "[INFO][2022/04/20 04:53:38 AM] Tracking objects in frames 1000 to 1099 (of 2071)...\n",
      "[INFO][2022/04/20 04:53:51 AM]  - Timing (Bayesian updates: 120.97ms, Linking: 2.85ms)\n",
      "[INFO][2022/04/20 04:53:51 AM]  - Probabilities (Link: 1.00000, Lost: 0.99998)\n",
      "[INFO][2022/04/20 04:53:51 AM]  - Stats (Active: 605, Lost: 41965, Conflicts resolved: 11133)\n",
      "[INFO][2022/04/20 04:53:51 AM] Tracking objects in frames 1100 to 1199 (of 2071)...\n",
      "[INFO][2022/04/20 04:54:04 AM]  - Timing (Bayesian updates: 138.53ms, Linking: 2.97ms)\n",
      "[INFO][2022/04/20 04:54:04 AM]  - Probabilities (Link: 1.00000, Lost: 0.99962)\n",
      "[INFO][2022/04/20 04:54:04 AM]  - Stats (Active: 630, Lost: 47743, Conflicts resolved: 13686)\n",
      "[INFO][2022/04/20 04:54:04 AM] Tracking objects in frames 1200 to 1299 (of 2071)...\n",
      "[INFO][2022/04/20 04:54:21 AM]  - Timing (Bayesian updates: 259.05ms, Linking: 5.47ms)\n",
      "[INFO][2022/04/20 04:54:21 AM]  - Probabilities (Link: 1.00000, Lost: 0.99186)\n",
      "[INFO][2022/04/20 04:54:21 AM]  - Stats (Active: 689, Lost: 53641, Conflicts resolved: 16106)\n",
      "[INFO][2022/04/20 04:54:21 AM] Tracking objects in frames 1300 to 1399 (of 2071)...\n",
      "[INFO][2022/04/20 04:54:40 AM]  - Timing (Bayesian updates: 329.11ms, Linking: 4.93ms)\n",
      "[INFO][2022/04/20 04:54:40 AM]  - Probabilities (Link: 0.99946, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:54:40 AM]  - Stats (Active: 1203, Lost: 60781, Conflicts resolved: 19627)\n",
      "[INFO][2022/04/20 04:54:40 AM] Tracking objects in frames 1400 to 1499 (of 2071)...\n",
      "[INFO][2022/04/20 04:55:00 AM]  - Timing (Bayesian updates: 190.91ms, Linking: 3.53ms)\n",
      "[INFO][2022/04/20 04:55:00 AM]  - Probabilities (Link: 1.00000, Lost: 0.91505)\n",
      "[INFO][2022/04/20 04:55:00 AM]  - Stats (Active: 714, Lost: 66606, Conflicts resolved: 22049)\n",
      "[INFO][2022/04/20 04:55:00 AM] Tracking objects in frames 1500 to 1599 (of 2071)...\n",
      "[INFO][2022/04/20 04:55:20 AM]  - Timing (Bayesian updates: 174.87ms, Linking: 3.47ms)\n",
      "[INFO][2022/04/20 04:55:20 AM]  - Probabilities (Link: 0.99988, Lost: 0.99278)\n",
      "[INFO][2022/04/20 04:55:20 AM]  - Stats (Active: 704, Lost: 72433, Conflicts resolved: 24343)\n",
      "[INFO][2022/04/20 04:55:20 AM] Tracking objects in frames 1600 to 1699 (of 2071)...\n",
      "[INFO][2022/04/20 04:55:37 AM]  - Timing (Bayesian updates: 185.69ms, Linking: 3.64ms)\n",
      "[INFO][2022/04/20 04:55:37 AM]  - Probabilities (Link: 1.00000, Lost: 0.88513)\n",
      "[INFO][2022/04/20 04:55:37 AM]  - Stats (Active: 776, Lost: 79627, Conflicts resolved: 28067)\n",
      "[INFO][2022/04/20 04:55:37 AM] Tracking objects in frames 1700 to 1799 (of 2071)...\n",
      "[INFO][2022/04/20 04:55:55 AM]  - Timing (Bayesian updates: 144.97ms, Linking: 3.01ms)\n",
      "[INFO][2022/04/20 04:55:55 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:55:55 AM]  - Stats (Active: 653, Lost: 87756, Conflicts resolved: 32182)\n",
      "[INFO][2022/04/20 04:55:55 AM] Tracking objects in frames 1800 to 1899 (of 2071)...\n",
      "[INFO][2022/04/20 04:56:10 AM]  - Timing (Bayesian updates: 139.89ms, Linking: 3.00ms)\n",
      "[INFO][2022/04/20 04:56:10 AM]  - Probabilities (Link: 0.99997, Lost: 0.91807)\n",
      "[INFO][2022/04/20 04:56:10 AM]  - Stats (Active: 648, Lost: 94726, Conflicts resolved: 35260)\n",
      "[INFO][2022/04/20 04:56:10 AM] Tracking objects in frames 1900 to 1999 (of 2071)...\n",
      "[INFO][2022/04/20 04:56:25 AM]  - Timing (Bayesian updates: 119.55ms, Linking: 2.80ms)\n",
      "[INFO][2022/04/20 04:56:25 AM]  - Probabilities (Link: 0.99999, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:56:25 AM]  - Stats (Active: 620, Lost: 102437, Conflicts resolved: 38476)\n",
      "[INFO][2022/04/20 04:56:25 AM] Tracking objects in frames 2000 to 2071 (of 2071)...\n",
      "[INFO][2022/04/20 04:56:34 AM]  - Timing (Bayesian updates: 114.24ms, Linking: 2.85ms)\n",
      "[INFO][2022/04/20 04:56:34 AM]  - Probabilities (Link: 0.99953, Lost: 0.99993)\n",
      "[INFO][2022/04/20 04:56:34 AM] SUCCESS.\n",
      "[INFO][2022/04/20 04:56:34 AM]  - Found 22934 tracks in 2071 frames (in 0.0s)\n",
      "[INFO][2022/04/20 04:56:34 AM]  - Inserted 24228 dummy objects to fill tracking gaps\n",
      "[INFO][2022/04/20 04:56:34 AM] Loading hypothesis model: MDCK_hypothesis_wildtype\n",
      "[INFO][2022/04/20 04:56:34 AM] Calculating hypotheses (relax: True)...\n",
      "[INFO][2022/04/20 04:56:35 AM] Setting up constraints matrix for global optimisation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/04/20 04:56:35 AM] Optimizing...\n",
      "[INFO][2022/04/20 04:56:35 AM] Optimization complete. (Solution: optimal)\n",
      "[INFO][2022/04/20 04:56:35 AM]  - Fates.FALSE_POSITIVE: 22934 (of 22934)\n",
      "[INFO][2022/04/20 04:56:35 AM]  - TOTAL: 22934 hypotheses\n",
      "[INFO][2022/04/20 04:56:35 AM] Completed optimization with 22934 tracks\n",
      "[INFO][2022/04/20 04:56:35 AM] Opening HDF file: /home/nathan/data/kraken/ras/ND0021/Pos13/tracks.h5...\n",
      "[INFO][2022/04/20 04:56:43 AM] Writing objects/obj_type_1\n",
      "[INFO][2022/04/20 04:56:43 AM] Writing labels/obj_type_1\n",
      "[INFO][2022/04/20 04:56:43 AM] Loading objects/obj_type_1 (929188, 5) (929188 filtered: None)\n",
      "[INFO][2022/04/20 04:56:53 AM] Writing properties/obj_type_1/area (929188,)\n",
      "[INFO][2022/04/20 04:56:53 AM] Writing properties/obj_type_1/eccentricity (929188,)\n",
      "[INFO][2022/04/20 04:56:54 AM] Writing properties/obj_type_1/mean_intensity (929188,)\n",
      "[INFO][2022/04/20 04:56:54 AM] Writing properties/obj_type_1/class id (929188,)\n",
      "[INFO][2022/04/20 04:56:54 AM] Writing properties/obj_type_1/prob_interphase (929188,)\n",
      "[INFO][2022/04/20 04:56:54 AM] Writing properties/obj_type_1/prob_prometaphase (929188,)\n",
      "[INFO][2022/04/20 04:56:54 AM] Writing properties/obj_type_1/prob_metaphase (929188,)\n",
      "[INFO][2022/04/20 04:56:54 AM] Writing properties/obj_type_1/prob_anaphase (929188,)\n",
      "[INFO][2022/04/20 04:56:54 AM] Writing properties/obj_type_1/prob_apoptosis (929188,)\n",
      "[INFO][2022/04/20 04:56:57 AM] Writing tracks/obj_type_1\n",
      "[INFO][2022/04/20 04:56:57 AM] Writing dummies/obj_type_1\n",
      "[INFO][2022/04/20 04:56:57 AM] Writing LBEP/obj_type_1\n",
      "[INFO][2022/04/20 04:56:57 AM] Writing fates/obj_type_1\n",
      "[INFO][2022/04/20 04:56:58 AM] Closing HDF file: /home/nathan/data/kraken/ras/ND0021/Pos13/tracks.h5\n",
      "[INFO][2022/04/20 04:56:58 AM] Ending BayesianTracker session\n",
      "[INFO][2022/04/20 04:56:59 AM] Loaded btrack: /home/nathan/analysis/BayesianTracker/btrack/libs/libtracker.so\n",
      "[INFO][2022/04/20 04:56:59 AM] btrack (v0.4.3) library imported\n",
      "[INFO][2022/04/20 04:56:59 AM] Setting max XYZ search radius to: 100\n",
      "[INFO][2022/04/20 04:56:59 AM] Starting BayesianTracker session\n",
      "[INFO][2022/04/20 04:56:59 AM] Loading configuration file: ../models/MDCK_config_scribble_sparse.json\n",
      "[INFO][2022/04/20 04:56:59 AM] Loading motion model: MDCK_motion\n",
      "[INFO][2022/04/20 04:56:59 AM] Setting max XYZ search radius to: 40\n",
      "[INFO][2022/04/20 04:56:59 AM] Objects are of type: <class 'list'>\n",
      "[INFO][2022/04/20 04:56:59 AM] Set volume to ((0, 1600), (0, 1200), (-100000.0, 100000.0))\n",
      "[INFO][2022/04/20 04:56:59 AM] Starting tracking... \n",
      "[INFO][2022/04/20 04:56:59 AM] Tracking objects in frames 0 to 99 (of 2071)...\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Timing (Bayesian updates: 0.03ms, Linking: 0.03ms)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Probabilities (Link: 1.00000, Lost: 0.99920)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Stats (Active: 11, Lost: 249, Conflicts resolved: 35)\n",
      "[INFO][2022/04/20 04:56:59 AM] Tracking objects in frames 100 to 199 (of 2071)...\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Timing (Bayesian updates: 0.02ms, Linking: 0.03ms)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Probabilities (Link: 0.99994, Lost: 0.98121)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Stats (Active: 14, Lost: 575, Conflicts resolved: 54)\n",
      "[INFO][2022/04/20 04:56:59 AM] Tracking objects in frames 200 to 299 (of 2071)...\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Timing (Bayesian updates: 0.01ms, Linking: 0.02ms)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Probabilities (Link: 1.00000, Lost: 0.98214)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Stats (Active: 9, Lost: 849, Conflicts resolved: 57)\n",
      "[INFO][2022/04/20 04:56:59 AM] Tracking objects in frames 300 to 399 (of 2071)...\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Timing (Bayesian updates: 0.03ms, Linking: 0.03ms)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Probabilities (Link: 0.99999, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Stats (Active: 12, Lost: 1142, Conflicts resolved: 66)\n",
      "[INFO][2022/04/20 04:56:59 AM] Tracking objects in frames 400 to 499 (of 2071)...\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Timing (Bayesian updates: 0.04ms, Linking: 0.04ms)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Stats (Active: 16, Lost: 1483, Conflicts resolved: 78)\n",
      "[INFO][2022/04/20 04:56:59 AM] Tracking objects in frames 500 to 599 (of 2071)...\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Timing (Bayesian updates: 0.06ms, Linking: 0.05ms)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Probabilities (Link: 0.99995, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Stats (Active: 23, Lost: 1963, Conflicts resolved: 111)\n",
      "[INFO][2022/04/20 04:56:59 AM] Tracking objects in frames 600 to 699 (of 2071)...\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Timing (Bayesian updates: 0.11ms, Linking: 0.10ms)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Probabilities (Link: 1.00000, Lost: 0.99876)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Stats (Active: 30, Lost: 2709, Conflicts resolved: 185)\n",
      "[INFO][2022/04/20 04:56:59 AM] Tracking objects in frames 700 to 799 (of 2071)...\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Timing (Bayesian updates: 0.11ms, Linking: 0.06ms)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Probabilities (Link: 0.99874, Lost: 0.87162)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Stats (Active: 31, Lost: 3507, Conflicts resolved: 274)\n",
      "[INFO][2022/04/20 04:56:59 AM] Tracking objects in frames 800 to 899 (of 2071)...\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Timing (Bayesian updates: 0.22ms, Linking: 0.09ms)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Probabilities (Link: 1.00000, Lost: 0.84101)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Stats (Active: 41, Lost: 4452, Conflicts resolved: 403)\n",
      "[INFO][2022/04/20 04:56:59 AM] Tracking objects in frames 900 to 999 (of 2071)...\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Timing (Bayesian updates: 0.21ms, Linking: 0.09ms)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Probabilities (Link: 0.99999, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Stats (Active: 41, Lost: 5692, Conflicts resolved: 537)\n",
      "[INFO][2022/04/20 04:56:59 AM] Tracking objects in frames 1000 to 1099 (of 2071)...\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Timing (Bayesian updates: 0.26ms, Linking: 0.09ms)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Probabilities (Link: 0.99966, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Stats (Active: 42, Lost: 6543, Conflicts resolved: 626)\n",
      "[INFO][2022/04/20 04:56:59 AM] Tracking objects in frames 1100 to 1199 (of 2071)...\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Timing (Bayesian updates: 0.37ms, Linking: 0.12ms)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Probabilities (Link: 1.00000, Lost: 0.87538)\n",
      "[INFO][2022/04/20 04:56:59 AM]  - Stats (Active: 53, Lost: 7341, Conflicts resolved: 731)\n",
      "[INFO][2022/04/20 04:56:59 AM] Tracking objects in frames 1200 to 1299 (of 2071)...\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Timing (Bayesian updates: 0.61ms, Linking: 0.16ms)\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Probabilities (Link: 1.00000, Lost: 0.99663)\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Stats (Active: 68, Lost: 8437, Conflicts resolved: 848)\n",
      "[INFO][2022/04/20 04:57:00 AM] Tracking objects in frames 1300 to 1399 (of 2071)...\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Timing (Bayesian updates: 1.04ms, Linking: 0.23ms)\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Probabilities (Link: 0.99981, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Stats (Active: 106, Lost: 10060, Conflicts resolved: 1035)\n",
      "[INFO][2022/04/20 04:57:00 AM] Tracking objects in frames 1400 to 1499 (of 2071)...\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Timing (Bayesian updates: 1.05ms, Linking: 0.22ms)\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Probabilities (Link: 0.99998, Lost: 0.98147)\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Stats (Active: 89, Lost: 11598, Conflicts resolved: 1184)\n",
      "[INFO][2022/04/20 04:57:00 AM] Tracking objects in frames 1500 to 1599 (of 2071)...\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Timing (Bayesian updates: 0.94ms, Linking: 0.20ms)\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Probabilities (Link: 0.99984, Lost: 0.47772)\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Stats (Active: 83, Lost: 13633, Conflicts resolved: 1397)\n",
      "[INFO][2022/04/20 04:57:00 AM] Tracking objects in frames 1600 to 1699 (of 2071)...\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Timing (Bayesian updates: 1.40ms, Linking: 0.25ms)\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Probabilities (Link: 0.99903, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Stats (Active: 105, Lost: 16092, Conflicts resolved: 1648)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/04/20 04:57:00 AM] Tracking objects in frames 1700 to 1799 (of 2071)...\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Timing (Bayesian updates: 1.47ms, Linking: 0.25ms)\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Probabilities (Link: 0.99997, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Stats (Active: 108, Lost: 18765, Conflicts resolved: 1895)\n",
      "[INFO][2022/04/20 04:57:00 AM] Tracking objects in frames 1800 to 1899 (of 2071)...\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Timing (Bayesian updates: 1.59ms, Linking: 0.27ms)\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Probabilities (Link: 0.99975, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:57:00 AM]  - Stats (Active: 117, Lost: 21995, Conflicts resolved: 2222)\n",
      "[INFO][2022/04/20 04:57:00 AM] Tracking objects in frames 1900 to 1999 (of 2071)...\n",
      "[INFO][2022/04/20 04:57:01 AM]  - Timing (Bayesian updates: 1.63ms, Linking: 0.27ms)\n",
      "[INFO][2022/04/20 04:57:01 AM]  - Probabilities (Link: 0.99999, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:57:01 AM]  - Stats (Active: 107, Lost: 25284, Conflicts resolved: 2519)\n",
      "[INFO][2022/04/20 04:57:01 AM] Tracking objects in frames 2000 to 2071 (of 2071)...\n",
      "[INFO][2022/04/20 04:57:01 AM]  - Timing (Bayesian updates: 2.09ms, Linking: 0.34ms)\n",
      "[INFO][2022/04/20 04:57:01 AM]  - Probabilities (Link: 0.99999, Lost: 1.00000)\n",
      "[INFO][2022/04/20 04:57:01 AM] SUCCESS.\n",
      "[INFO][2022/04/20 04:57:01 AM]  - Found 4962 tracks in 2071 frames (in 0.0s)\n",
      "[INFO][2022/04/20 04:57:01 AM]  - Inserted 1990 dummy objects to fill tracking gaps\n",
      "[INFO][2022/04/20 04:57:01 AM] Loading hypothesis model: MDCK_hypothesis_scribble_sparse\n",
      "[INFO][2022/04/20 04:57:01 AM] Calculating hypotheses (relax: True)...\n",
      "[INFO][2022/04/20 04:57:01 AM] Setting up constraints matrix for global optimisation...\n",
      "[INFO][2022/04/20 04:57:01 AM] Optimizing...\n",
      "[INFO][2022/04/20 04:57:01 AM] Optimization complete. (Solution: optimal)\n",
      "[INFO][2022/04/20 04:57:01 AM]  - Fates.FALSE_POSITIVE: 4962 (of 4962)\n",
      "[INFO][2022/04/20 04:57:01 AM]  - TOTAL: 4962 hypotheses\n",
      "[INFO][2022/04/20 04:57:01 AM] Completed optimization with 4962 tracks\n",
      "[INFO][2022/04/20 04:57:01 AM] Opening HDF file: /home/nathan/data/kraken/ras/ND0021/Pos13/tracks.h5...\n",
      "[INFO][2022/04/20 04:57:02 AM] Writing objects/obj_type_2\n",
      "[INFO][2022/04/20 04:57:02 AM] Writing labels/obj_type_2\n",
      "[INFO][2022/04/20 04:57:02 AM] Loading objects/obj_type_2 (85669, 5) (85669 filtered: None)\n",
      "[INFO][2022/04/20 04:57:02 AM] Writing properties/obj_type_2/area (85669,)\n",
      "[INFO][2022/04/20 04:57:02 AM] Writing properties/obj_type_2/eccentricity (85669,)\n",
      "[INFO][2022/04/20 04:57:02 AM] Writing properties/obj_type_2/mean_intensity (85669,)\n",
      "[INFO][2022/04/20 04:57:03 AM] Writing properties/obj_type_2/class id (85669,)\n",
      "[INFO][2022/04/20 04:57:03 AM] Writing properties/obj_type_2/prob_interphase (85669,)\n",
      "[INFO][2022/04/20 04:57:03 AM] Writing properties/obj_type_2/prob_prometaphase (85669,)\n",
      "[INFO][2022/04/20 04:57:03 AM] Writing properties/obj_type_2/prob_metaphase (85669,)\n",
      "[INFO][2022/04/20 04:57:03 AM] Writing properties/obj_type_2/prob_anaphase (85669,)\n",
      "[INFO][2022/04/20 04:57:03 AM] Writing properties/obj_type_2/prob_apoptosis (85669,)\n",
      "[INFO][2022/04/20 04:57:03 AM] Writing tracks/obj_type_2\n",
      "[INFO][2022/04/20 04:57:03 AM] Writing dummies/obj_type_2\n",
      "[INFO][2022/04/20 04:57:03 AM] Writing LBEP/obj_type_2\n",
      "[INFO][2022/04/20 04:57:03 AM] Writing fates/obj_type_2\n",
      "[INFO][2022/04/20 04:57:03 AM] Closing HDF file: /home/nathan/data/kraken/ras/ND0021/Pos13/tracks.h5\n",
      "[INFO][2022/04/20 04:57:03 AM] Ending BayesianTracker session\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/home/nathan/data/kraken/ras'\n",
    "\n",
    "for i, expt_pos in tqdm(expt_pos_list.iterrows(), desc = 'Progress of experiment annotation', total = len(expt_pos_list)):    \n",
    "    expt = expt_pos['Experiments']\n",
    "    pos = expt_pos['Positions']\n",
    "\n",
    "    print(f'Starting alignment for {expt}/{pos}')\n",
    "\n",
    "    ### create new subdir of for raw files and move them all there\n",
    "    image_path = f'{root_dir}/{expt}/{pos}/{pos}_images'\n",
    "    if not os.path.exists(image_path):\n",
    "        os.mkdir(image_path)\n",
    "        files = sorted(glob.glob(f'{root_dir}/{expt}/{pos}/*.tif'))\n",
    "        for file in files:\n",
    "            os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_images'))\n",
    "\n",
    "    # check if blanks dir exists and make if not and move\n",
    "    if not os.path.exists(f'{root_dir}/{expt}/{pos}/{pos}_blanks'):\n",
    "        os.mkdir(f'{root_dir}/{expt}/{pos}/{pos}_blanks')\n",
    "        ### pre load files from raw file dir \n",
    "        images = DaskOctopusLiteLoader(image_path, remove_background= False)\n",
    "\n",
    "        ### measure mean pixel value arrays and use to find under/over-exposed frames\n",
    "        max_pixel = 200\n",
    "        min_pixel = 2\n",
    "        # set empty dict arrays for mean values \n",
    "        mean_arrays = {}\n",
    "        # set for dodgy frames (only unique entries)\n",
    "        dodgy_frame_list = set([])\n",
    "        #iterate over channels\n",
    "        for channel in tqdm(images.channels, desc = f'Finding mean values of image channels'):\n",
    "            if 'MASK' in channel.name:\n",
    "                continue\n",
    "            # find mean value of each frame in each channel\n",
    "            mean_arrays[channel.name] = [np.mean(img) for img in image_generator(images.files(channel.name))]\n",
    "            # iterate over frames\n",
    "            for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "                # check to see if mean frame pixel value meets criteria\n",
    "                if max_pixel < mean_value or mean_value < min_pixel:\n",
    "                    # if so add to delete list\n",
    "                    dodgy_frame_list.add(frame)\n",
    "        # format delete list to only include single values\n",
    "        dodgy_frame_list = list(dodgy_frame_list)\n",
    "        print('Number of under/over-exposed frames:', len(dodgy_frame_list))\n",
    "\n",
    "        # move blank images into this directory\n",
    "        for channel in images.channels:\n",
    "            for f in images.files(channel.name):\n",
    "                for i in dodgy_frame_list:\n",
    "                    if str(i).zfill(9) in f:\n",
    "                        os.rename(f, f.replace('_images', '_blanks'))\n",
    "\n",
    "    if not os.path.exists(f'{root_dir}/{expt}/{pos}/transform_tensor.npy'):\n",
    "        # crop central window out of reference image with blanks removed\n",
    "        reference_image = DaskOctopusLiteLoader(image_path, \n",
    "                                                crop = (500, 500)\n",
    "                                               )['gfp'].compute() \n",
    "\n",
    "\n",
    "        ### Register alignment\n",
    "        print('Registering alignment for', pos, expt)\n",
    "        # create operator using transformation type (translation)\n",
    "        sr = StackReg(StackReg.TRANSLATION) \n",
    "        # register each frame to the previous as transformation matrices/tensor\n",
    "        transform_tensor = sr.register_stack(reference_image, reference = 'previous', )\n",
    "\n",
    "        ### clip transformation tensor to eliminate any rare jumps, (1688-1600)/2=44\n",
    "        transform_tensor = np.clip(transform_tensor, a_max= 44, a_min = -44)\n",
    "\n",
    "        # save out transform tensor\n",
    "        np.save(f'{root_dir}/{expt}/{pos}/transform_tensor.npy', transform_tensor)\n",
    "\n",
    "        print('Alignment complete for', expt, pos)\n",
    "\n",
    "\n",
    "\n",
    "    print('Starting segmentation for', expt, pos)\n",
    "    # load images\n",
    "    images = DaskOctopusLiteLoader(image_path, \n",
    "                                   remove_background = True)\n",
    "    \n",
    "    \n",
    "    # iterate over images filenames \n",
    "    for frame, fn in tqdm(enumerate(images.files('gfp')),total = len(images.files('gfp'))):\n",
    "        # load two seperate images\n",
    "        if os.path.exists(fn.replace('channel001', 'channel099')):\n",
    "            continue\n",
    "        gfp = imread(fn)\n",
    "        # predict gfp labels with a higher threshold as the fl. signal is strong\n",
    "        labels, details = seg_model.predict_instances(normalize(gfp), prob_thresh=0.75)\n",
    "        # create empty mask image\n",
    "        mask = np.zeros(labels.shape, dtype = np.uint8)\n",
    "        # remove any small, unrealistically nuclear objects from seg output\n",
    "        labels = remove_small_objects(labels, min_size = 200)\n",
    "        ### image post processing, start at 1 to skip background label\n",
    "        for i in range(1, np.amax(labels)):\n",
    "            #needs erosion step to stop merging of labels\n",
    "            segment = labels == i\n",
    "            seg_props = regionprops(label(segment), cache = False)\n",
    "            ### if segment exists, subject to exclusion criteria\n",
    "            if seg_props:\n",
    "                ### if segment area is large and elliptical it is probably a missclassified ras cyto (keeping for future use)\n",
    "                if 3000 <= seg_props[0].area or seg_props[0].eccentricity > 0.95: \n",
    "                    ## below condition has been applied on some post processing but cannot be applied here as gpf mask will not have rfp hole in yet, should not matter though as most large gfp masks will be caught by size alone\n",
    "                    # or seg_props.area < (0.9*seg_props.filled_area):\n",
    "                    ### dont bother eroding the large ras cyto masks as will add time\n",
    "                    #segment = binary_erosion(segment)\n",
    "                    mask[segment] = 3\n",
    "                else:\n",
    "                    segment = binary_erosion(segment)\n",
    "                    mask[segment] = 1\n",
    "\n",
    "        # now do the same for the rfp channel\n",
    "        rfp = imread(fn.replace('channel001', 'channel002'))   \n",
    "        # predict labels a much lower threshold as rfp signal is dim\n",
    "        labels, details = seg_model.predict_instances(normalize(rfp), prob_thresh=0.2)\n",
    "\n",
    "        ### remove small objects (low thresh picks up hot pixels) also reduce number of iterations needed for individual binary erosion\n",
    "        labels = remove_small_objects(labels, min_size = 200)\n",
    "\n",
    "        ### iterate over individual segments, eroding and reassigning label to not merge\n",
    "        for i in range(1, np.amax(labels)):\n",
    "            #needs erosion step to stop merging of labels\n",
    "            segment = labels == i\n",
    "            segment = binary_erosion(segment)\n",
    "            ## add to main mask\n",
    "            mask[segment] = 2\n",
    "\n",
    "        # set filename as mask format (channel099)\n",
    "        fn = ((images.files('gfp')[frame])).replace('channel001', 'channel099')\n",
    "        #save out labelled image\n",
    "        imsave(fn, mask.astype(np.uint8), check_contrast=False)\n",
    "        \n",
    "    print('Segmentation complete for', expt, pos)\n",
    "\n",
    "    \n",
    "    print('Starting object localisation for', expt, pos)\n",
    "    \n",
    "    if not os.path.exists(f'{root_dir}/{expt}/{pos}/objects.h5'):\n",
    "        transform_path = f'{root_dir}/{expt}/{pos}/transform_tensor.npy'\n",
    "        images = DaskOctopusLiteLoader(image_path, \n",
    "                                       transforms=transform_path,\n",
    "                                       crop=(1200,1600), \n",
    "                                       remove_background=True)\n",
    "\n",
    "        ## loading seperate instances of objects so that fl. intensities can be measured\n",
    "        objects_gfp = btrack.utils.segmentation_to_objects(\n",
    "            images['mask']==1,\n",
    "            images['gfp'],\n",
    "            properties = ('area', 'eccentricity', 'mean_intensity'),\n",
    "            assign_class_ID = True,\n",
    "        )\n",
    "        objects_rfp = btrack.utils.segmentation_to_objects(\n",
    "            (images['mask']==2)*2,\n",
    "            images['rfp'],\n",
    "            properties = ('area', 'eccentricity', 'mean_intensity'),\n",
    "            assign_class_ID = True,\n",
    "        )\n",
    "        ### filter for size\n",
    "        ### probably redundant two lines but just keeping as insurance\n",
    "    #         objects_gfp = [o for o in objects_gfp if 4000.>o.properties['area']>100.]\n",
    "    #         objects_rfp = [o for o in objects_rfp if 4000.>o.properties['area']>100.]\n",
    "    #         objects_gfp = [obj for obj in objects_gfp if obj.properties['class id'] == 1]\n",
    "    #         objects_rfp = [obj for obj in objects_rfp if obj.properties['class id'] == 2]\n",
    "\n",
    "        model = load_model('../models/cellx_classifier_stardist.h5')\n",
    "\n",
    "        bf = images['brightfield']\n",
    "        gfp = images['gfp']\n",
    "        rfp = images['rfp']\n",
    "\n",
    "        print('Classifying objects in', expt, pos)\n",
    "        objects_gfp = classify_objects(bf, gfp, rfp, objects_gfp, obj_type = 1)\n",
    "        objects_rfp = classify_objects(bf, gfp, rfp, objects_rfp, obj_type = 2)\n",
    "\n",
    "        with btrack.dataio.HDF5FileHandler(\n",
    "            f'{root_dir}/{expt}/{pos}/objects_type_1.h5', 'w', obj_type='obj_type_1',\n",
    "        ) as hdf:\n",
    "            #hdf.write_segmentation(masks['mask'])\n",
    "            hdf.write_objects(objects_gfp)    \n",
    "\n",
    "        with btrack.dataio.HDF5FileHandler(\n",
    "            f'{root_dir}/{expt}/{pos}/objects_type_2.h5', 'w', obj_type='obj_type_2',\n",
    "        ) as hdf:\n",
    "            #hdf.write_segmentation(masks['mask'])\n",
    "            hdf.write_objects(objects_rfp)\n",
    "\n",
    "        with btrack.dataio.HDF5FileHandler(\n",
    "            f'{root_dir}/{expt}/{pos}/objects.h5', 'w', obj_type='obj_type_1',\n",
    "        ) as hdf:\n",
    "            #hdf.write_segmentation(masks['mask'])\n",
    "            hdf.write_objects(objects_gfp)\n",
    "\n",
    "        with btrack.dataio.HDF5FileHandler(\n",
    "            f'{root_dir}/{expt}/{pos}/objects.h5', 'a', obj_type='obj_type_2',\n",
    "        ) as hdf:\n",
    "            #hdf.write_segmentation(masks['mask'])\n",
    "            hdf.write_objects(objects_rfp)\n",
    "\n",
    "        print('Object localisation complete for', expt, pos)\n",
    "\n",
    "    print('Starting tracking for', expt, pos)\n",
    "\n",
    "    if not os.path.exists(f'{root_dir}/{expt}/{pos}/tracks.h5'):\n",
    "        # initialise a tracker session using a context manager\n",
    "        with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "            # configure the tracker using a config file\n",
    "            tracker.configure_from_file(\n",
    "                '../models/MDCK_config_wildtype.json'\n",
    "            )\n",
    "            tracker.max_search_radius = 40\n",
    "\n",
    "            # append the objects to be tracked\n",
    "            tracker.append(objects_gfp)\n",
    "\n",
    "            # set the volume\n",
    "            tracker.volume=((0, 1600), (0, 1200), (-1e5, 1e5))\n",
    "\n",
    "            # track them (in interactive mode)\n",
    "            tracker.track_interactive(step_size=100)\n",
    "\n",
    "            # generate hypotheses and run the global optimizer\n",
    "            tracker.optimize()\n",
    "\n",
    "            tracker.export(f'{root_dir}/{expt}/{pos}/tracks.h5', obj_type='obj_type_1')\n",
    "\n",
    "            # get the tracks in a format for napari visualization (optional)\n",
    "    #         visaulise_tracks, properties, graph = tracker.to_napari(ndim=2)\n",
    "\n",
    "    #         gfp_tracks = tracker.tracks\n",
    "\n",
    "        # initialise a tracker session using a context manager\n",
    "        with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "            # configure the tracker using a config file\n",
    "            tracker.configure_from_file(\n",
    "                '../models/MDCK_config_scribble_sparse.json'\n",
    "            )\n",
    "            tracker.max_search_radius = 40\n",
    "\n",
    "            # append the objects to be tracked\n",
    "            tracker.append(objects_rfp)\n",
    "\n",
    "            # set the volume\n",
    "            tracker.volume=((0, 1600), (0, 1200), (-1e5, 1e5))\n",
    "\n",
    "            # track them (in interactive mode)\n",
    "            tracker.track_interactive(step_size=100)\n",
    "\n",
    "            # generate hypotheses and run the global optimizer\n",
    "            tracker.optimize()\n",
    "\n",
    "            tracker.export(f'{root_dir}/{expt}/{pos}/tracks.h5', obj_type='obj_type_2')\n",
    "\n",
    "    #         # get the tracks in a format for napari visualization (optional)\n",
    "    #         visaulise_tracks, properties, graph = tracker.to_napari(ndim=2)\n",
    "\n",
    "    #         rfp_tracks = tracker.tracks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
