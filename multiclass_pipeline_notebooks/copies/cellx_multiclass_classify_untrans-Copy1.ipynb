{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cada0f4",
   "metadata": {},
   "source": [
    "# Phenotype classifcation using CellX \n",
    "\n",
    "This notebook shows how to take segmented time lapse microscopy images and use h2b fluorescence markers to classfiy mitotic state of the cell cycle. \n",
    "\n",
    "The sections of this notebook are as follows:\n",
    "\n",
    "1. Load images\n",
    "2. Localise the objects\n",
    "3. Classify the objects\n",
    "4. Batch process\n",
    "\n",
    "The data used in this notebook is timelapse microscopy data with h2b-gfp/rfp markers that show the spatial extent of the nucleus and it's mitotic state. \n",
    "\n",
    "This notebook uses the dask octopuslite image loader from the CellX/Lowe lab project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c311e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from octopuslite import DaskOctopusLiteLoader\n",
    "import btrack\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imshow\n",
    "from cellx import load_model\n",
    "from cellx.tools.image import InfinitePaddedImage\n",
    "from skimage.transform import resize\n",
    "import glob\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [18,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5906f",
   "metadata": {},
   "source": [
    "## 1. Load segmentation images\n",
    "\n",
    "#### *Important:* from this point on you will need to be consistent with the use of cropping and alignment. \n",
    "Using a previously generated alignment transformation will aid greatly in the tracking notebook, which depends on the object localisation performed in this notebook. Cropping your images will ensure that no border effects from the translational shift are seen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ee9d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: (1200, 1600)\n"
     ]
    }
   ],
   "source": [
    "# load images\n",
    "expt = 'ND0012'\n",
    "pos = 'Pos5'\n",
    "root_dir = '/home/nathan/data/kraken/ras'\n",
    "image_path = f'{root_dir}/{expt}/{pos}/{pos}_images'\n",
    "transform_path = f'{root_dir}/{expt}/{pos}/gfp_transform_tensor.npy'\n",
    "images = DaskOctopusLiteLoader(image_path, \n",
    "                               transforms=transform_path,\n",
    "                               crop=(1200,1600), \n",
    "                               remove_background=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfccac2e",
   "metadata": {},
   "source": [
    "## 2. Localise the objects\n",
    "We need to also measure the mean intensity regionprops parameter in order to differentiate object class, for which we need to provide an image to measure. This means we need to provide the segmentation images twice: once to find the centroid and once to measure the pixel intensity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f3d937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/02/04 10:18:09 AM] Localizing objects from segmentation...\n",
      "[INFO][2022/02/04 10:18:09 AM] Found intensity_image data\n",
      "[INFO][2022/02/04 10:18:09 AM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2022/02/04 10:28:10 AM] Objects are of type: <class 'dict'>\n",
      "[INFO][2022/02/04 10:28:10 AM] ...Found 9566 objects in 1738 frames.\n"
     ]
    }
   ],
   "source": [
    "objects = btrack.utils.segmentation_to_objects(\n",
    "    images['mask'], images['mask'],\n",
    "    properties = ('area', 'max_intensity', ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa49b7b",
   "metadata": {},
   "source": [
    "#### Can also assign measured values from raw image to each segment using `skimage.measure.regionprops` parameters\n",
    "But also need to load the raw images to be measured first. Cannot currently save out `intensity_image` parameter to object file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4548905",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_objects = btrack.utils.segmentation_to_objects(\n",
    "    images['mask'], \n",
    "    images['gfp'],\n",
    "    properties = ('area', 'mean_intensity', 'intensity_image'), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e2efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_objects[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63775a4c",
   "metadata": {},
   "source": [
    "Example image showing PCNA-iRFP morphology "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d3a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(detailed_objects[0].properties['intensity_image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08114355",
   "metadata": {},
   "source": [
    "## 2b. Differentiate the objects based on class ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583c2fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_gfp = [obj for obj in objects if obj.properties['max_intensity'] == 1]\n",
    "objects_rfp = [obj for obj in objects if obj.properties['max_intensity'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc05b98",
   "metadata": {},
   "source": [
    "## 3. Classify the objects "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1725583",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10cd85e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../models/cellx_classifier_stardist.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bce619f",
   "metadata": {},
   "source": [
    "Define normalisation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92d135ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_channels(x):\n",
    "\n",
    "    for dim in range(x.shape[-1]):\n",
    "        x[..., dim] = normalize(x[..., dim])\n",
    "        \n",
    "    return x\n",
    "\n",
    "def normalize(x):\n",
    "\n",
    "    xf = x.astype(np.float32)\n",
    "    mx = np.mean(xf)\n",
    "    sd = np.max([np.std(xf), 1./np.prod(x.shape)])\n",
    "\n",
    "    return (xf - mx) / sd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8428f",
   "metadata": {},
   "source": [
    "Define classifier function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41184a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_objects(image,  gfp, rfp, objects, obj_type):\n",
    "    \n",
    "    # define stages of cell cycle to classify (dependent on model type)\n",
    "    LABELS = [\"interphase\", \"prometaphase\", \"metaphase\", \"anaphase\", \"apoptosis\"]\n",
    "    \n",
    "    # iterate over frames\n",
    "    for n in tqdm(range(image.shape[0])):\n",
    "        \n",
    "        # only select objects if in frame\n",
    "        _objects = [o for o in objects if o.t == n]\n",
    "        \n",
    "        # empty placeholder arrays\n",
    "        crops = []\n",
    "        to_update = []\n",
    "        \n",
    "        # select h2b channel to aid in classification\n",
    "        fp = gfp if obj_type == 1 else rfp\n",
    "        \n",
    "        # create stack by computing each frame of dask array input\n",
    "        frame = np.stack(\n",
    "            [image[n, ...].compute(), fp[n, ...].compute()], \n",
    "            axis=-1,) \n",
    "        \n",
    "        # create padded image for network\n",
    "        vol = InfinitePaddedImage(frame, mode = 'reflect')\n",
    "        \n",
    "        # iterate over objects \n",
    "        for obj in _objects:\n",
    "            \n",
    "            # create coords for image slice\n",
    "            xs = slice(int(obj.x-40), int(obj.x+40), 1)\n",
    "            ys = slice(int(obj.y-40), int(obj.y+40), 1)\n",
    "            \n",
    "            # crop image\n",
    "            crop = vol[ys, xs, :]\n",
    "            crop = resize(crop, (64, 64), preserve_range=True).astype(np.float32)\n",
    "            \n",
    "            # normalise image\n",
    "            if crop.shape == (64 ,64, 2):\n",
    "                crops.append(normalize_channels(crop))\n",
    "                to_update.append(obj)\n",
    "            else:\n",
    "                print(crop.shape)\n",
    "                \n",
    "        if not crops:\n",
    "            continue\n",
    "            \n",
    "        # use classifcation model to predict\n",
    "        pred = model.predict(np.stack(crops, axis=0))\n",
    "        \n",
    "        # check correct number of predictions\n",
    "        assert pred.shape[0] == len(_objects)\n",
    "        \n",
    "        # assign labels to objects\n",
    "        for idx in range(pred.shape[0]):\n",
    "            obj = _objects[idx]\n",
    "            \n",
    "            # assigning details of prediction\n",
    "            pred_label = np.argmax(pred[idx, ...])\n",
    "            pred_softmax = softmax(pred[idx, ...])\n",
    "            logits = {f\"prob_{k}\": pred_softmax[ki] for ki, k in enumerate(LABELS)}\n",
    "            \n",
    "            # write out\n",
    "            obj.label = pred_label\n",
    "            obj.properties = logits\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8781b4",
   "metadata": {},
   "source": [
    "#### Load raw images for classifier, a colour channel dependent on `obj_type` needed too (i.e. GFP is `obj_type = 1`, RFP is `obj_type = 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657771d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = images['brightfield']\n",
    "gfp = images['gfp']\n",
    "rfp = images['rfp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30835a86",
   "metadata": {},
   "source": [
    "#### Classify objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e84c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_gfp = classify_objects(bf, objects_gfp, obj_type = 1)\n",
    "objects_rfp = classify_objects(bf, objects_rfp, obj_type = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70646be",
   "metadata": {},
   "source": [
    "#### Inspect an example object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_gfp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5c716",
   "metadata": {},
   "source": [
    "#### Save out classified GFP objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796afd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with btrack.dataio.HDF5FileHandler(\n",
    "    f'{root_dir}/{expt}/{pos}/objects_type_1.h5', 'w', obj_type='obj_type_1',\n",
    ") as hdf:\n",
    "    #hdf.write_segmentation(masks['mask'])\n",
    "    hdf.write_objects(objects_gfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdb0274",
   "metadata": {},
   "source": [
    "#### Save out classified RFP objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de0f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with btrack.dataio.HDF5FileHandler(\n",
    "    f'{root_dir}/{expt}/{pos}/objects_type_2.h5', 'w', obj_type='obj_type_2',\n",
    ") as hdf:\n",
    "    #hdf.write_segmentation(masks['mask'])\n",
    "    hdf.write_objects(objects_rfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e10e7",
   "metadata": {},
   "source": [
    "# 4. Batch process\n",
    "Iterate over many experiments and positions (need to ensure you define normalisation and classification functions above first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1792133",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa18a0633e844909da3ddc065d86a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257c2dd32ef644ceb6c1d48c935976cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/nathan/data/kraken/ras/ND0012/Pos0/untrans_no_bg_objects_type_2.h5', '/home/nathan/data/kraken/ras/ND0012/Pos0/untrans_no_bg_objects_type_1.h5'] file found, skipping ND0012/Pos0\n",
      "['/home/nathan/data/kraken/ras/ND0012/Pos1/untrans_no_bg_objects_type_2.h5', '/home/nathan/data/kraken/ras/ND0012/Pos1/untrans_no_bg_objects_type_1.h5'] file found, skipping ND0012/Pos1\n",
      "ND0012 Pos2 enough masks\n",
      "Starting ND0012/Pos2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/02/23 12:22:18 PM] Localizing objects from segmentation...\n",
      "[INFO][2022/02/23 12:26:20 PM] Objects are of type: <class 'dict'>\n",
      "[INFO][2022/02/23 12:26:23 PM] ...Found 478183 objects in 1738 frames.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying objects\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a99e48510664898a332c50173bd96bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1738 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%timeit\n",
    "root_dir = '/home/nathan/data/kraken/ras'\n",
    "expt_list = [#'ND0010', 'ND0011', \n",
    "    'ND0012', \n",
    "    #'ND0013'\n",
    "]\n",
    "#expt_list = [expt for expt in os.listdir(root_dir) if len(expt) == 6]\n",
    "\n",
    "pos_list = 'all'\n",
    "overwrite = False\n",
    "\n",
    "for expt in tqdm(expt_list):\n",
    "    try:\n",
    "        # Find all positions in that experiment, if pos_list is all then it finds all positions\n",
    "        if pos_list == 'all':\n",
    "            pos_list = [pos for pos in os.listdir(f'{root_dir}/{expt}') \n",
    "                    if 'Pos' in pos \n",
    "                    and os.path.isdir(f'{root_dir}/{expt}/{pos}')]  \n",
    "\n",
    "        ### Iterate over all positions in that experiment\n",
    "        for pos in tqdm(natsorted(pos_list)):\n",
    "\n",
    "            ### check if overwrite param is false check if raw directory already created and if type of transform file already exists and decide whether to skip pos\n",
    "            if not overwrite and glob.glob(f'{root_dir}/{expt}/{pos}/*untrans_no_bg_objects_type*.h5'):\n",
    "                print(glob.glob(f'{root_dir}/{expt}/{pos}/**untrans_no_bg_objects_type*.h5'), f'file found, skipping {expt}/{pos}')\n",
    "                continue\n",
    "\n",
    "            #check seg is complete\n",
    "            mask_path = f'{root_dir}/{expt}/{pos}/{pos}_images/*channel099*'\n",
    "            if glob.glob(mask_path) and len(glob.glob(mask_path)) == len(glob.glob(f'{root_dir}/{expt}/{pos}/{pos}_images/*channel001*')):\n",
    "                print(expt, pos, 'enough masks')\n",
    "\n",
    "                print(f'Starting {expt}/{pos}')\n",
    "                # load segmentation images and apply necessary transforms and crops\n",
    "                image_path = f'{root_dir}/{expt}/{pos}/{pos}_images'\n",
    "                #transform_path = f'{root_dir}/{expt}/{pos}/gfp_transform_tensor.npy'\n",
    "                images = DaskOctopusLiteLoader(image_path, \n",
    "                                   #transforms=transform_path,\n",
    "                                   #crop=(1200,1600), \n",
    "                                   remove_background=False)\n",
    "\n",
    "                # ID the objects in each segmentation image and assign option properties to them\n",
    "                objects = btrack.utils.segmentation_to_objects(\n",
    "                    images['mask'], \n",
    "                    properties = ('area',),\n",
    "                    assign_class_ID = True\n",
    "                )\n",
    "\n",
    "                # differentiate the objects based on class ID\n",
    "                objects_gfp = [obj for obj in objects if obj.properties['class id'] == 1]\n",
    "                objects_rfp = [obj for obj in objects if obj.properties['class id'] == 2]\n",
    "\n",
    "                # load classifcation model and define labels\n",
    "                model = load_model('../models/cellx_classifier_stardist.h5')\n",
    "                LABELS = [\"interphase\", \"prometaphase\", \"metaphase\", \"anaphase\", \"apoptosis\"]\n",
    "\n",
    "                # load images for classifcation\n",
    "                bf = images['brightfield']\n",
    "                gfp = images['gfp']\n",
    "                rfp = images['rfp']\n",
    "\n",
    "                # classify objects\n",
    "                print(\"Classifying objects\")\n",
    "                objects_gfp = classify_objects(bf, gfp, rfp, objects_gfp, obj_type = 1)\n",
    "                objects_rfp = classify_objects(bf, gfp, rfp, objects_rfp, obj_type = 2)\n",
    "\n",
    "                # save out classified objects as segmentation h5 file\n",
    "                with btrack.dataio.HDF5FileHandler(\n",
    "                    f'{root_dir}/{expt}/{pos}/untrans_objects_type_1.h5', 'w', obj_type='obj_type_1',\n",
    "                ) as hdf:\n",
    "                    #hdf.write_segmentation(masks['mask'])\n",
    "                    hdf.write_objects(objects_gfp)\n",
    "                with btrack.dataio.HDF5FileHandler(\n",
    "                    f'{root_dir}/{expt}/{pos}/untrans_objects_type_2.h5', 'w', obj_type='obj_type_2',\n",
    "                ) as hdf:\n",
    "                    #hdf.write_segmentation(masks['mask'])\n",
    "                    hdf.write_objects(objects_rfp)  \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        #print(pos, expt, 'failed probably due to zero cell count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f6f166",
   "metadata": {},
   "source": [
    "# ND11 and ND12 processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe13ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "root_dir = '/home/nathan/data/kraken/ras'\n",
    "expt_list = [#'ND0010', 'ND0011', \n",
    "    'ND0011', \n",
    "    #'ND0013'\n",
    "]\n",
    "#expt_list = [expt for expt in os.listdir(root_dir) if len(expt) == 6]\n",
    "\n",
    "pos_list = 'all'\n",
    "overwrite = False\n",
    "\n",
    "for expt in tqdm(expt_list):\n",
    "    try:\n",
    "        # Find all positions in that experiment, if pos_list is all then it finds all positions\n",
    "        if pos_list == 'all':\n",
    "            pos_list = [pos for pos in os.listdir(f'{root_dir}/{expt}') \n",
    "                    if 'Pos' in pos \n",
    "                    and os.path.isdir(f'{root_dir}/{expt}/{pos}')]  \n",
    "\n",
    "        ### Iterate over all positions in that experiment\n",
    "        for pos in tqdm(natsorted(pos_list)):\n",
    "\n",
    "            ### check if overwrite param is false check if raw directory already created and if type of transform file already exists and decide whether to skip pos\n",
    "            if not overwrite and glob.glob(f'{root_dir}/{expt}/{pos}/*untrans_no_bg_objects_type*.h5'):\n",
    "                print(glob.glob(f'{root_dir}/{expt}/{pos}/**untrans_no_bg_objects_type*.h5'), f'file found, skipping {expt}/{pos}')\n",
    "                continue\n",
    "\n",
    "            #check seg is complete\n",
    "            mask_path = f'{root_dir}/{expt}/{pos}/{pos}_images/*channel099*'\n",
    "            if glob.glob(mask_path) and len(glob.glob(mask_path)) == len(glob.glob(f'{root_dir}/{expt}/{pos}/{pos}_images/*channel001*')):\n",
    "                print(expt, pos, 'enough masks')\n",
    "\n",
    "                print(f'Starting {expt}/{pos}')\n",
    "                # load segmentation images and apply necessary transforms and crops\n",
    "                image_path = f'{root_dir}/{expt}/{pos}/{pos}_images'\n",
    "                #transform_path = f'{root_dir}/{expt}/{pos}/gfp_transform_tensor.npy'\n",
    "                images = DaskOctopusLiteLoader(image_path, \n",
    "                                   #transforms=transform_path,\n",
    "                                   #crop=(1200,1600), \n",
    "                                   remove_background=False)\n",
    "\n",
    "                # ID the objects in each segmentation image and assign option properties to them\n",
    "                objects = btrack.utils.segmentation_to_objects(\n",
    "                    images['mask'], \n",
    "                    properties = ('area',),\n",
    "                    assign_class_ID = True\n",
    "                )\n",
    "\n",
    "                # differentiate the objects based on class ID\n",
    "                objects_gfp = [obj for obj in objects if obj.properties['class id'] == 1]\n",
    "                objects_rfp = [obj for obj in objects if obj.properties['class id'] == 2]\n",
    "\n",
    "                # load classifcation model and define labels\n",
    "                model = load_model('../models/cellx_classifier_stardist.h5')\n",
    "                LABELS = [\"interphase\", \"prometaphase\", \"metaphase\", \"anaphase\", \"apoptosis\"]\n",
    "\n",
    "                # load images for classifcation\n",
    "                bf = images['brightfield']\n",
    "                gfp = images['gfp']\n",
    "                rfp = images['rfp']\n",
    "\n",
    "                # classify objects\n",
    "                print(\"Classifying objects\")\n",
    "                objects_gfp = classify_objects(bf, gfp, rfp, objects_gfp, obj_type = 1)\n",
    "                objects_rfp = classify_objects(bf, gfp, rfp, objects_rfp, obj_type = 2)\n",
    "\n",
    "                # save out classified objects as segmentation h5 file\n",
    "                with btrack.dataio.HDF5FileHandler(\n",
    "                    f'{root_dir}/{expt}/{pos}/untrans_objects_type_1.h5', 'w', obj_type='obj_type_1',\n",
    "                ) as hdf:\n",
    "                    #hdf.write_segmentation(masks['mask'])\n",
    "                    hdf.write_objects(objects_gfp)\n",
    "                with btrack.dataio.HDF5FileHandler(\n",
    "                    f'{root_dir}/{expt}/{pos}/untrans_objects_type_2.h5', 'w', obj_type='obj_type_2',\n",
    "                ) as hdf:\n",
    "                    #hdf.write_segmentation(masks['mask'])\n",
    "                    hdf.write_objects(objects_rfp)  \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        #print(pos, expt, 'failed probably due to zero cell count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df611d71",
   "metadata": {},
   "source": [
    "# copying all h5 files to temp directory to transfer home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcdd9062",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/nathan/data/kraken/ras'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fc59a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob( f'{root_dir}/*/*/untrans_no_bg_objects_type_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31c1e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0160de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nathan/data/kraken/ras/ND0010/Pos0/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0010/Pos1/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0010/Pos2/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0010/Pos3/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0010/Pos4/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0010/Pos5/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0010/Pos6/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0010/Pos7/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0010/Pos8/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0010/Pos9/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0010/Pos10/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0010/Pos11/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0012/Pos0/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0012/Pos1/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0012/Pos2/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0012/Pos3/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0012/Pos5/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0012/Pos8/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0012/Pos10/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0012/Pos11/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0013/Pos0/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0013/Pos1/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0013/Pos2/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0013/Pos3/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0013/Pos4/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0013/Pos5/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0013/Pos6/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0013/Pos7/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0013/Pos8/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0013/Pos9/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0013/Pos10/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0013/Pos11/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0013/Pos12/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0013/Pos13/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0013/Pos14/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0014/Pos0/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0014/Pos1/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0014/Pos2/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0014/Pos3/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0014/Pos4/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0014/Pos5/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0014/Pos6/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0014/Pos7/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0014/Pos8/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0014/Pos9/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0014/Pos10/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0014/Pos11/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0014/Pos12/untrans_no_bg_objects_type_1.h5',\n",
       " '/home/nathan/data/kraken/ras/ND0014/Pos13/untrans_no_bg_objects_type_1.h5']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natsorted(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75eb12b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82a87ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('/home/nathan/data/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c5ab22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b243f25d86e6439ca7bdc2e3689fe076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nathan/data/kraken/ras/ND0010/Pos0/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos0\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos0\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos0/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos1/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos1\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos1\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos1/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos2/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos2\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos2\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos2/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos3/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos3\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos3\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos3/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos4/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos4\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos4\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos4/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos5/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos5\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos5/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos6/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos6\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos6\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos6/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos7/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos7\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos7\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos7/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos8/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos8\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos8\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos8/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos9/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos9\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos9\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos9/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos10/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos10\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos10\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos10/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos11/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0010/Pos11\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos11\n",
      "/home/nathan/temp2/data/kraken/ras/ND0010/Pos11/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0012/Pos0/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0012/Pos0\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0012/Pos0\n",
      "/home/nathan/temp2/data/kraken/ras/ND0012/Pos0/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0012/Pos1/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0012/Pos1\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0012/Pos1\n",
      "/home/nathan/temp2/data/kraken/ras/ND0012/Pos1/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0012/Pos2/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0012/Pos2\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0012/Pos2\n",
      "/home/nathan/temp2/data/kraken/ras/ND0012/Pos2/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0012/Pos3/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0012/Pos3\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0012/Pos3\n",
      "/home/nathan/temp2/data/kraken/ras/ND0012/Pos3/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0012/Pos5/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0012/Pos5\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0012/Pos5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0012/Pos5/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0012/Pos8/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0012/Pos8\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0012/Pos8\n",
      "/home/nathan/temp2/data/kraken/ras/ND0012/Pos8/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0012/Pos10/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0012/Pos10\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0012/Pos10\n",
      "/home/nathan/temp2/data/kraken/ras/ND0012/Pos10/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0012/Pos11/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0012/Pos11\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0012/Pos11\n",
      "/home/nathan/temp2/data/kraken/ras/ND0012/Pos11/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos0/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos0\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos0\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos0/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos1/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos1\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos1\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos1/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos2/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos2\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos2\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos2/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos3/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos3\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos3\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos3/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos4/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos4\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos4\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos4/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos5/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos5\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos5/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos6/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos6\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos6\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos6/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos7/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos7\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos7\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos7/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos8/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos8\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos8\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos8/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos9/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos9\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos9\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos9/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos10/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos10\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos10\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos10/untrans_no_bg_objects_type_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nathan/data/kraken/ras/ND0013/Pos11/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos11\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos11\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos11/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos12/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos12\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos12\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos12/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos13/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos13\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos13\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos13/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos14/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0013/Pos14\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos14\n",
      "/home/nathan/temp2/data/kraken/ras/ND0013/Pos14/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos0/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos0\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos0\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos0/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos1/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos1\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos1\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos1/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos2/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos2\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos2\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos2/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos3/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos3\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos3\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos3/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos4/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos4\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos4\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos4/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos5/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos5\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos5/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos6/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos6\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos6\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos6/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos7/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos7\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos7\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos7/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos8/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos8\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos8\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos8/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos9/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos9\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos9\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos9/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos10/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos10\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos10\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos10/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos11/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos11\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos11\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos11/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos12/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos12\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos12\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos12/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos13/untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/data/kraken/ras/ND0014/Pos13\n",
      "untrans_no_bg_objects_type_1.h5\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos13\n",
      "/home/nathan/temp2/data/kraken/ras/ND0014/Pos13/untrans_no_bg_objects_type_1.h5\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(natsorted(file_list)):\n",
    "    ##get path\n",
    "    path = os.path.split(file)[0]\n",
    "    filename = os.path.split(file)[-1]\n",
    "    ## new path\n",
    "    new_path = path.replace('/home/nathan/', '/home/nathan/temp2/')\n",
    "    ## create new directory structure\n",
    "    os.makedirs(new_path)\n",
    "    new_file = os.path.join(new_path, filename)\n",
    "    ## copy file to new location\n",
    "    print(file)\n",
    "    print(path)\n",
    "    print(filename)\n",
    "    print(new_path)\n",
    "    print(new_file)\n",
    "    shutil.copyfile(file, new_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4448da0",
   "metadata": {},
   "source": [
    "# need to do other set of files (with bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10a2bb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nathan/data/kraken/ras/*untrans_objects_type_2.h5'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for file in file_list:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e99e9a",
   "metadata": {},
   "source": [
    "# Parallel batch process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eb3bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(pos):\n",
    "    ### check if overwrite param is false check if raw directory already created and if type of transform file already exists and decide whether to skip pos\n",
    "    \n",
    "\n",
    "    print(f'Starting {expt}/{pos}')\n",
    "    # load segmentation images and apply necessary transforms and crops\n",
    "    image_path = f'{root_dir}/{expt}/{pos}/{pos}_images'\n",
    "    #transform_path = f'{root_dir}/{expt}/{pos}/gfp_transform_tensor.npy'\n",
    "    images = DaskOctopusLiteLoader(image_path, \n",
    "                       #transforms=transform_path,\n",
    "                       #crop=(1200,1600), \n",
    "                       remove_background=False)\n",
    "\n",
    "    # ID the objects in each segmentation image and assign option properties to them\n",
    "    objects = btrack.utils.segmentation_to_objects(\n",
    "        images['mask'], images['mask'],\n",
    "        properties = ('area', 'max_intensity', ),\n",
    "    )\n",
    "\n",
    "    # differentiate the objects based on class ID\n",
    "    objects_gfp = [obj for obj in objects if obj.properties['max_intensity'] == 1]\n",
    "    objects_rfp = [obj for obj in objects if obj.properties['max_intensity'] == 2]\n",
    "\n",
    "    # load classifcation model and define labels\n",
    "    model = load_model('../models/cellx_classifier_stardist.h5')\n",
    "    LABELS = [\"interphase\", \"prometaphase\", \"metaphase\", \"anaphase\", \"apoptosis\"]\n",
    "\n",
    "    # load images for classifcation\n",
    "    bf = images['brightfield']\n",
    "    gfp = images['gfp']\n",
    "    rfp = images['rfp']\n",
    "\n",
    "    # classify objects\n",
    "    print(\"Classifying objects\")\n",
    "    objects_gfp = classify_objects(bf, objects_gfp, obj_type = 1)\n",
    "    objects_rfp = classify_objects(bf, objects_rfp, obj_type = 2)\n",
    "\n",
    "    # save out classified objects as segmentation h5 file\n",
    "    with btrack.dataio.HDF5FileHandler(\n",
    "        f'{root_dir}/{expt}/{pos}/objects_type_1_untrans.h5', 'w', obj_type='obj_type_1',\n",
    "    ) as hdf:\n",
    "        #hdf.write_segmentation(masks['mask'])\n",
    "        hdf.write_objects(objects_gfp)\n",
    "    with btrack.dataio.HDF5FileHandler(\n",
    "        f'{root_dir}/{expt}/{pos}/objects_type_2_untrans.h5', 'w', obj_type='obj_type_2',\n",
    "    ) as hdf:\n",
    "        #hdf.write_segmentation(masks['mask'])\n",
    "        hdf.write_objects(objects_rfp)     \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bc24d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "cpus = os.cpu_count()\n",
    "cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e276356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pos5',\n",
       " 'Pos11',\n",
       " 'Pos3',\n",
       " 'Pos1',\n",
       " 'Pos8',\n",
       " 'Pos10',\n",
       " 'Pos0',\n",
       " 'Pos2',\n",
       " 'Pos6',\n",
       " 'Pos7',\n",
       " 'Pos9',\n",
       " 'Pos4']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_list = [pos for pos in os.listdir(f'{root_dir}/{expt}') \n",
    "                    if 'Pos' in pos \n",
    "                    and os.path.isdir(f'{root_dir}/{expt}/{pos}')]\n",
    "pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74aeb131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ND0013/Pos13Starting ND0013/Pos11Starting ND0013/Pos8Starting ND0013/Pos1Starting ND0013/Pos10\n",
      "Starting ND0013/Pos0\n",
      "Starting ND0013/Pos2\n",
      "\n",
      "Starting ND0013/Pos5\n",
      "Starting ND0013/Pos3\n",
      "\n",
      "\n",
      "\n",
      "Starting ND0013/Pos7\n",
      "Starting ND0013/Pos6Starting ND0013/Pos14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/02/12 02:53:37 PM] Localizing objects from segmentation...\n",
      "[INFO][2022/02/12 02:53:37 PM] Found intensity_image data\n",
      "[INFO][2022/02/12 02:53:37 PM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2022/02/12 02:53:38 PM] Objects are of type: <class 'dict'>\n",
      "[INFO][2022/02/12 02:53:38 PM] ...Found 46 objects in 2 frames.\n",
      "[INFO][2022/02/12 02:53:39 PM] Localizing objects from segmentation...\n",
      "[INFO][2022/02/12 02:53:39 PM] Found intensity_image data\n",
      "[INFO][2022/02/12 02:53:39 PM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2022/02/12 02:53:40 PM] Localizing objects from segmentation...\n",
      "[INFO][2022/02/12 02:53:40 PM] Found intensity_image data\n",
      "[INFO][2022/02/12 02:53:40 PM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2022/02/12 02:53:41 PM] Localizing objects from segmentation...\n",
      "[INFO][2022/02/12 02:53:41 PM] Found intensity_image data\n",
      "[INFO][2022/02/12 02:53:41 PM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2022/02/12 02:53:41 PM] Localizing objects from segmentation...\n",
      "[INFO][2022/02/12 02:53:42 PM] Found intensity_image data\n",
      "[INFO][2022/02/12 02:53:42 PM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2022/02/12 02:53:42 PM] Localizing objects from segmentation...\n",
      "[INFO][2022/02/12 02:53:42 PM] Found intensity_image data\n",
      "[INFO][2022/02/12 02:53:42 PM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2022/02/12 02:53:42 PM] Localizing objects from segmentation...\n",
      "[INFO][2022/02/12 02:53:42 PM] Found intensity_image data\n",
      "[INFO][2022/02/12 02:53:42 PM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2022/02/12 02:53:42 PM] Localizing objects from segmentation...\n",
      "[INFO][2022/02/12 02:53:42 PM] Found intensity_image data\n",
      "[INFO][2022/02/12 02:53:42 PM] Calculating weighted centroids using intensity_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ND0013/Pos9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/02/12 02:53:42 PM] Localizing objects from segmentation...\n",
      "[INFO][2022/02/12 02:53:42 PM] Found intensity_image data\n",
      "[INFO][2022/02/12 02:53:42 PM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2022/02/12 02:53:43 PM] Localizing objects from segmentation...\n",
      "[INFO][2022/02/12 02:53:43 PM] Found intensity_image data\n",
      "[INFO][2022/02/12 02:53:43 PM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2022/02/12 02:53:43 PM] Localizing objects from segmentation...\n",
      "[INFO][2022/02/12 02:53:43 PM] Found intensity_image data\n",
      "[INFO][2022/02/12 02:53:43 PM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2022/02/12 02:53:56 PM] Localizing objects from segmentation...\n",
      "[INFO][2022/02/12 02:53:56 PM] Found intensity_image data\n",
      "[INFO][2022/02/12 02:53:56 PM] Calculating weighted centroids using intensity_image\n",
      "Process ForkPoolWorker-10:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-23492c392ce4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpus\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-23492c392ce4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpus\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_terminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/multiprocessing/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wr, _finalizer_registry, sub_debug, getpid)\u001b[0m\n\u001b[1;32m    223\u001b[0m                           self._callback, self._args, self._kwargs)\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weakref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_terminate_pool\u001b[0;34m(cls, taskqueue, inqueue, outqueue, pool, change_notifier, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mworker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m         \u001b[0mchange_notifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/multiprocessing/queues.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;31m# serialize the data before acquiring the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[1;32m   3458\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3460\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3461\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/threading.py\", line 312, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/queue.py\", line 171, in get\n",
      "    self.not_empty.wait()\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/threading.py\", line 312, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-5-b55b09ea950c>\", line 15, in classify\n",
      "    objects = btrack.utils.segmentation_to_objects(\n",
      "  File \"/home/nathan/analysis/BayesianTracker/btrack/_localization.py\", line 258, in segmentation_to_objects\n",
      "    seg = segmentation[frame, ...].compute()\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/dask/base.py\", line 288, in compute\n",
      "    (result,) = compute(self, traverse=False, **kwargs)\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/dask/base.py\", line 570, in compute\n",
      "    results = schedule(dsk, keys, **kwargs)\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/dask/threaded.py\", line 79, in get\n",
      "    results = get_async(\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/dask/local.py\", line 496, in get_async\n",
      "    for key, res_info, failed in queue_get(queue).result():\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/dask/local.py\", line 134, in queue_get\n",
      "    return q.get()\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/queue.py\", line 183, in get\n",
      "    return item\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/threading.py\", line 260, in __exit__\n",
      "    return self._lock.__exit__(*args)\n",
      "RuntimeError: release unlocked lock\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/multiprocessing/pool.py\", line 128, in worker\n",
      "    e = ExceptionWithTraceback(e, e.__traceback__)\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/multiprocessing/pool.py\", line 65, in __init__\n",
      "    tb = traceback.format_exception(type(exc), exc, tb)\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/traceback.py\", line 120, in format_exception\n",
      "    return list(TracebackException(\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/traceback.py\", line 468, in __init__\n",
      "    def __init__(self, exc_type, exc_value, exc_traceback, *, limit=None,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/home/nathan/data/kraken/ras'\n",
    "expt_list = [expt for expt in os.listdir(root_dir) if len(expt) == 6]\n",
    "\n",
    "for expt in expt_list:\n",
    "    pos_list = [pos for pos in os.listdir(f'{root_dir}/{expt}') \n",
    "                    if 'Pos' in pos \n",
    "                    and os.path.isdir(f'{root_dir}/{expt}/{pos}')]\n",
    "    if __name__ == '__main__':\n",
    "        with Pool(cpus) as p:\n",
    "            p.map(classify, pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad500c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
