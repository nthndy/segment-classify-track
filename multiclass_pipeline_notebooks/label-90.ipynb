{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a18649de",
   "metadata": {},
   "source": [
    "# Complete pre-analysis cell labelling pipeline\n",
    "\n",
    "1. Alignment\n",
    "2. Segmentation\n",
    "3. Object localisation\n",
    "4. Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca1b454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import enum\n",
    "import re\n",
    "import numpy as np\n",
    "import btrack\n",
    "import pandas as pd\n",
    "from pystackreg import StackReg\n",
    "from skimage.io import imsave, imread\n",
    "from tqdm.auto import tqdm\n",
    "from octopuslite import DaskOctopusLiteLoader\n",
    "from skimage import transform as tf\n",
    "from skimage.transform import resize ### tidy up these dependencies\n",
    "from stardist.models import StarDist2D \n",
    "from stardist.plot import render_label\n",
    "from csbdeep.utils import normalize\n",
    "from scipy import ndimage as nd\n",
    "from scipy.special import softmax\n",
    "from cellx import load_model\n",
    "from cellx.tools.image import InfinitePaddedImage\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import binary_erosion, remove_small_objects\n",
    "from natsort import natsorted\n",
    "\n",
    "seg_model = StarDist2D.from_pretrained('2D_versatile_fluo')\n",
    "\n",
    "def image_generator(files, crop = None):\n",
    "    \n",
    "    if crop is None:\n",
    "        for filename in files:\n",
    "            img = imread(filename)\n",
    "            yield img\n",
    "    else:\n",
    "        for filename in files:\n",
    "            img = imread(filename)\n",
    "            img = crop_image(img, crop)\n",
    "            yield img\n",
    "\n",
    "def normalize_channels(x):\n",
    "\n",
    "    for dim in range(x.shape[-1]):\n",
    "        x[..., dim] = normalize(x[..., dim])\n",
    "        \n",
    "    return x\n",
    "\n",
    "def normalize(x):\n",
    "\n",
    "    xf = x.astype(np.float32)\n",
    "    mx = np.mean(xf)\n",
    "    sd = np.max([np.std(xf), 1./np.prod(x.shape)])\n",
    "\n",
    "    return (xf - mx) / sd\n",
    "\n",
    "def classify_objects(image,  gfp, rfp, objects, obj_type):\n",
    "    \n",
    "    # define stages of cell cycle to classify (dependent on model type)\n",
    "    LABELS = [\"interphase\", \"prometaphase\", \"metaphase\", \"anaphase\", \"apoptosis\"]\n",
    "    \n",
    "    # iterate over frames\n",
    "    for n in tqdm(range(image.shape[0])):\n",
    "        \n",
    "        # only select objects if in frame\n",
    "        _objects = [o for o in objects if o.t == n]\n",
    "        \n",
    "        # empty placeholder arrays\n",
    "        crops = []\n",
    "        to_update = []\n",
    "        \n",
    "        # select h2b channel to aid in classification\n",
    "        fp = gfp if obj_type == 1 else rfp\n",
    "        \n",
    "        # create stack by computing each frame of dask array input\n",
    "        frame = np.stack(\n",
    "            [image[n, ...].compute(), fp[n, ...].compute()], \n",
    "            axis=-1,) \n",
    "        \n",
    "        # create padded image for network\n",
    "        vol = InfinitePaddedImage(frame, mode = 'reflect')\n",
    "        \n",
    "        # iterate over objects \n",
    "        for obj in _objects:\n",
    "            \n",
    "            # create coords for image slice\n",
    "            xs = slice(int(obj.x-40), int(obj.x+40), 1)\n",
    "            ys = slice(int(obj.y-40), int(obj.y+40), 1)\n",
    "            \n",
    "            # crop image\n",
    "            crop = vol[ys, xs, :]\n",
    "            crop = resize(crop, (64, 64), preserve_range=True).astype(np.float32)\n",
    "            \n",
    "            # normalise image\n",
    "            if crop.shape == (64 ,64, 2):\n",
    "                crops.append(normalize_channels(crop))\n",
    "                to_update.append(obj)\n",
    "            else:\n",
    "                print(crop.shape)\n",
    "                \n",
    "        if not crops:\n",
    "            continue\n",
    "            \n",
    "        # use classifcation model to predict\n",
    "        pred = model.predict(np.stack(crops, axis=0))\n",
    "        \n",
    "        # check correct number of predictions\n",
    "        assert pred.shape[0] == len(_objects)\n",
    "        \n",
    "        # assign labels to objects\n",
    "        for idx in range(pred.shape[0]):\n",
    "            obj = _objects[idx]\n",
    "            \n",
    "            # assigning details of prediction\n",
    "            pred_label = np.argmax(pred[idx, ...])\n",
    "            pred_softmax = softmax(pred[idx, ...])\n",
    "            logits = {f\"prob_{k}\": pred_softmax[ki] for ki, k in enumerate(LABELS)}\n",
    "            \n",
    "            # write out\n",
    "            obj.label = pred_label\n",
    "            obj.properties = logits\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c293c3cb",
   "metadata": {},
   "source": [
    "# Experiment info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa7aedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_info = pd.read_csv('/home/nathan/data/kraken/ras/experiment_info_final.csv', header = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ab57a28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expt_info = expt_info.rename(columns = {'EXP n˚':'Experiments', 'POSITION':'Positions', 'CELL TYPE':'Condition', 'Useable (in radial analysis)':'Valid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0ec314e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiments</th>\n",
       "      <th>Positions</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Well</th>\n",
       "      <th>EXPT NOTES</th>\n",
       "      <th>POS NOTES</th>\n",
       "      <th>Valid</th>\n",
       "      <th>BF CHANNEL</th>\n",
       "      <th>GFP CHANNEL</th>\n",
       "      <th>RFP CHANNEL</th>\n",
       "      <th>...</th>\n",
       "      <th>Focus?</th>\n",
       "      <th>ALIGNED?</th>\n",
       "      <th>SEGMENTED?</th>\n",
       "      <th>Localised?</th>\n",
       "      <th>TRACKED?</th>\n",
       "      <th>segmentation notes</th>\n",
       "      <th>SEG Model</th>\n",
       "      <th>TRACK MODEL</th>\n",
       "      <th>BLISTERING?</th>\n",
       "      <th>COMPETITION?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08.11.2021</td>\n",
       "      <td>stopped due to focus issue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ND0000</td>\n",
       "      <td>Pos0</td>\n",
       "      <td>MDCK Rasv12 -</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stopped due to focus issue</td>\n",
       "      <td>uninduced</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ras</td>\n",
       "      <td>mutant(ras)-h2b</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ND0000</td>\n",
       "      <td>Pos1</td>\n",
       "      <td>50:50 wt:ras+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stopped due to focus issue</td>\n",
       "      <td>induced</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ras + wt-h2b</td>\n",
       "      <td>mutant(ras)-h2b</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ND0000</td>\n",
       "      <td>Pos2</td>\n",
       "      <td>MDCK Rasv12 +</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stopped due to focus issue</td>\n",
       "      <td>induced</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ras</td>\n",
       "      <td>mutant(ras)-h2b</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ND0000</td>\n",
       "      <td>Pos3</td>\n",
       "      <td>50:50 wt:ras+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stopped due to focus issue</td>\n",
       "      <td>induced</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ras + wt-h2b</td>\n",
       "      <td>mutant(ras)-h2b</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>ND0025</td>\n",
       "      <td>Pos9</td>\n",
       "      <td>97.5:2.5 wt:ras+</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ras + wt-h2b</td>\n",
       "      <td>mutant(ras)-h2b</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>ND0025</td>\n",
       "      <td>Pos10</td>\n",
       "      <td>97.5:2.5 wt:ras+</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ras + wt-h2b</td>\n",
       "      <td>mutant(ras)-h2b</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>ND0025</td>\n",
       "      <td>Pos11</td>\n",
       "      <td>97.5:2.5 wt:ras+</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ras + wt-h2b</td>\n",
       "      <td>mutant(ras)-h2b</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>ND0025</td>\n",
       "      <td>Pos12</td>\n",
       "      <td>97.5:2.5 wt:ras+</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ras + wt-h2b</td>\n",
       "      <td>mutant(ras)-h2b</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>ND0025</td>\n",
       "      <td>Pos13</td>\n",
       "      <td>97.5:2.5 wt:ras+</td>\n",
       "      <td>6.0</td>\n",
       "      <td>.</td>\n",
       "      <td>induced 3x seed dens</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ras + wt-h2b</td>\n",
       "      <td>mutant(ras)-h2b</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>368 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Experiments                   Positions         Condition  Well  \\\n",
       "0    08.11.2021  stopped due to focus issue               NaN   NaN   \n",
       "1        ND0000                        Pos0     MDCK Rasv12 -   NaN   \n",
       "2        ND0000                        Pos1     50:50 wt:ras+   NaN   \n",
       "3        ND0000                        Pos2     MDCK Rasv12 +   NaN   \n",
       "4        ND0000                        Pos3     50:50 wt:ras+   NaN   \n",
       "..          ...                         ...               ...   ...   \n",
       "363      ND0025                        Pos9  97.5:2.5 wt:ras+   6.0   \n",
       "364      ND0025                       Pos10  97.5:2.5 wt:ras+   6.0   \n",
       "365      ND0025                       Pos11  97.5:2.5 wt:ras+   6.0   \n",
       "366      ND0025                       Pos12  97.5:2.5 wt:ras+   6.0   \n",
       "367      ND0025                       Pos13  97.5:2.5 wt:ras+   6.0   \n",
       "\n",
       "                     EXPT NOTES             POS NOTES  Valid  BF CHANNEL  \\\n",
       "0                           NaN                   NaN    NaN         NaN   \n",
       "1    stopped due to focus issue             uninduced  False         NaN   \n",
       "2    stopped due to focus issue               induced  False         NaN   \n",
       "3    stopped due to focus issue               induced  False         NaN   \n",
       "4    stopped due to focus issue               induced  False         NaN   \n",
       "..                          ...                   ...    ...         ...   \n",
       "363                         NaN  induced 3x seed dens   True         NaN   \n",
       "364                         NaN  induced 3x seed dens   True         NaN   \n",
       "365                         NaN  induced 3x seed dens   True         NaN   \n",
       "366                         NaN  induced 3x seed dens   True         NaN   \n",
       "367                           .  induced 3x seed dens   True         NaN   \n",
       "\n",
       "       GFP CHANNEL      RFP CHANNEL  ... Focus? ALIGNED? SEGMENTED?  \\\n",
       "0              NaN              NaN  ...    NaN    FALSE      FALSE   \n",
       "1              Ras  mutant(ras)-h2b  ...    NaN    FALSE      FALSE   \n",
       "2    Ras + wt-h2b   mutant(ras)-h2b  ...    NaN    FALSE      FALSE   \n",
       "3              Ras  mutant(ras)-h2b  ...    NaN    FALSE      FALSE   \n",
       "4    Ras + wt-h2b   mutant(ras)-h2b  ...    NaN    FALSE      FALSE   \n",
       "..             ...              ...  ...    ...      ...        ...   \n",
       "363  Ras + wt-h2b   mutant(ras)-h2b  ...    NaN      NaN        NaN   \n",
       "364  Ras + wt-h2b   mutant(ras)-h2b  ...    NaN      NaN        NaN   \n",
       "365  Ras + wt-h2b   mutant(ras)-h2b  ...    NaN      NaN        NaN   \n",
       "366  Ras + wt-h2b   mutant(ras)-h2b  ...    NaN      NaN        NaN   \n",
       "367  Ras + wt-h2b   mutant(ras)-h2b  ...    NaN      NaN        NaN   \n",
       "\n",
       "    Localised? TRACKED? segmentation notes SEG Model TRACK MODEL BLISTERING?  \\\n",
       "0        False    False                NaN       NaN         NaN         NaN   \n",
       "1        False    False                NaN       NaN         NaN         NaN   \n",
       "2        False    False                NaN       NaN         NaN         NaN   \n",
       "3        False    False                NaN       NaN         NaN         NaN   \n",
       "4        False    False                NaN       NaN         NaN         NaN   \n",
       "..         ...      ...                ...       ...         ...         ...   \n",
       "363        NaN      NaN                NaN       NaN         NaN         NaN   \n",
       "364        NaN      NaN                NaN       NaN         NaN         NaN   \n",
       "365        NaN      NaN                NaN       NaN         NaN         NaN   \n",
       "366        NaN      NaN                NaN       NaN         NaN         NaN   \n",
       "367        NaN      NaN                NaN       NaN         NaN         NaN   \n",
       "\n",
       "    COMPETITION?  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "..           ...  \n",
       "363          NaN  \n",
       "364          NaN  \n",
       "365          NaN  \n",
       "366          NaN  \n",
       "367          NaN  \n",
       "\n",
       "[368 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expt_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf62abb2",
   "metadata": {},
   "source": [
    "##### Just 90:10 expts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b61491aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiments</th>\n",
       "      <th>Positions</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>ND0013</td>\n",
       "      <td>Pos3</td>\n",
       "      <td>90:10 wt:ras+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>ND0013</td>\n",
       "      <td>Pos4</td>\n",
       "      <td>90:10 wt:ras+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>ND0013</td>\n",
       "      <td>Pos5</td>\n",
       "      <td>90:10 wt:ras+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>ND0013</td>\n",
       "      <td>Pos6</td>\n",
       "      <td>90:10 wt:ras+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>ND0013</td>\n",
       "      <td>Pos7</td>\n",
       "      <td>90:10 wt:ras+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>ND0013</td>\n",
       "      <td>Pos8</td>\n",
       "      <td>90:10 wt:ras+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>ND0013</td>\n",
       "      <td>Pos9</td>\n",
       "      <td>90:10 wt:ras+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>ND0013</td>\n",
       "      <td>Pos10</td>\n",
       "      <td>90:10 wt:ras+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>ND0014</td>\n",
       "      <td>Pos0</td>\n",
       "      <td>90:10 wt:ras+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>ND0014</td>\n",
       "      <td>Pos1</td>\n",
       "      <td>90:10 wt:ras+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>ND0014</td>\n",
       "      <td>Pos2</td>\n",
       "      <td>90:10 wt:ras+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>ND0014</td>\n",
       "      <td>Pos3</td>\n",
       "      <td>90:10 wt:ras+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>ND0014</td>\n",
       "      <td>Pos4</td>\n",
       "      <td>90:10 wt:ras+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Experiments Positions      Condition\n",
       "176      ND0013      Pos3  90:10 wt:ras+\n",
       "177      ND0013      Pos4  90:10 wt:ras+\n",
       "178      ND0013      Pos5  90:10 wt:ras+\n",
       "179      ND0013      Pos6  90:10 wt:ras+\n",
       "180      ND0013      Pos7  90:10 wt:ras+\n",
       "181      ND0013      Pos8  90:10 wt:ras+\n",
       "182      ND0013      Pos9  90:10 wt:ras+\n",
       "183      ND0013     Pos10  90:10 wt:ras+\n",
       "188      ND0014      Pos0  90:10 wt:ras+\n",
       "189      ND0014      Pos1  90:10 wt:ras+\n",
       "190      ND0014      Pos2  90:10 wt:ras+\n",
       "191      ND0014      Pos3  90:10 wt:ras+\n",
       "192      ND0014      Pos4  90:10 wt:ras+"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expt_pos_list = expt_info.loc[(expt_info['Valid'] == True) & (expt_info['Condition'] == \"90:10 wt:ras+\" )][['Experiments','Positions', 'Condition']]\n",
    "expt_pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2625540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a618578118450c940f249ad0c02361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress of experiment annotation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting alignment for ND0013/Pos6\n",
      "Starting segmentation for ND0013 Pos6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f81dd1882d4f929071bcb2b5caa51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2787 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete for ND0013 Pos6\n",
      "Starting object localisation for ND0013 Pos6\n",
      "Using cropping: (1200, 1600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/05/15 06:34:01 AM] Localizing objects from segmentation...\n",
      "[INFO][2022/05/15 06:34:01 AM] Found intensity_image data\n",
      "[INFO][2022/05/15 06:34:01 AM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2022/05/15 07:09:53 AM] Objects are of type: <class 'dict'>\n",
      "[INFO][2022/05/15 07:10:03 AM] ...Found 1329084 objects in 2787 frames.\n",
      "[INFO][2022/05/15 07:10:03 AM] Localizing objects from segmentation...\n",
      "[INFO][2022/05/15 07:10:03 AM] Found intensity_image data\n",
      "[INFO][2022/05/15 07:10:03 AM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2022/05/15 07:41:37 AM] Objects are of type: <class 'dict'>\n",
      "[INFO][2022/05/15 07:41:38 AM] ...Found 202177 objects in 2787 frames.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying objects in ND0013 Pos6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753804a0539f47198e73626bec62e6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2787 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4614dd6ee33c4f91a3830a21f33f897e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2787 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/05/15 10:30:09 AM] Opening HDF file: /home/nathan/data/kraken/ras/ND0013/Pos6/objects_type_1.h5...\n",
      "[INFO][2022/05/15 10:30:19 AM] Writing objects/obj_type_1\n",
      "[INFO][2022/05/15 10:30:19 AM] Writing labels/obj_type_1\n",
      "[INFO][2022/05/15 10:30:19 AM] Loading objects/obj_type_1 (1329084, 5) (1329084 filtered: None)\n",
      "[INFO][2022/05/15 10:30:34 AM] Writing properties/obj_type_1/area (1329084,)\n",
      "[INFO][2022/05/15 10:30:34 AM] Writing properties/obj_type_1/eccentricity (1329084,)\n",
      "[INFO][2022/05/15 10:30:34 AM] Writing properties/obj_type_1/mean_intensity (1329084,)\n",
      "[INFO][2022/05/15 10:30:35 AM] Writing properties/obj_type_1/class id (1329084,)\n",
      "[INFO][2022/05/15 10:30:35 AM] Writing properties/obj_type_1/prob_interphase (1329084,)\n",
      "[INFO][2022/05/15 10:30:35 AM] Writing properties/obj_type_1/prob_prometaphase (1329084,)\n",
      "[INFO][2022/05/15 10:30:35 AM] Writing properties/obj_type_1/prob_metaphase (1329084,)\n",
      "[INFO][2022/05/15 10:30:35 AM] Writing properties/obj_type_1/prob_anaphase (1329084,)\n",
      "[INFO][2022/05/15 10:30:35 AM] Writing properties/obj_type_1/prob_apoptosis (1329084,)\n",
      "[INFO][2022/05/15 10:30:36 AM] Closing HDF file: /home/nathan/data/kraken/ras/ND0013/Pos6/objects_type_1.h5\n",
      "[INFO][2022/05/15 10:30:36 AM] Opening HDF file: /home/nathan/data/kraken/ras/ND0013/Pos6/objects_type_2.h5...\n",
      "[INFO][2022/05/15 10:30:37 AM] Writing objects/obj_type_2\n",
      "[INFO][2022/05/15 10:30:37 AM] Writing labels/obj_type_2\n",
      "[INFO][2022/05/15 10:30:37 AM] Loading objects/obj_type_2 (202177, 5) (202177 filtered: None)\n",
      "[INFO][2022/05/15 10:30:40 AM] Writing properties/obj_type_2/area (202177,)\n",
      "[INFO][2022/05/15 10:30:40 AM] Writing properties/obj_type_2/eccentricity (202177,)\n",
      "[INFO][2022/05/15 10:30:40 AM] Writing properties/obj_type_2/mean_intensity (202177,)\n",
      "[INFO][2022/05/15 10:30:40 AM] Writing properties/obj_type_2/class id (202177,)\n",
      "[INFO][2022/05/15 10:30:40 AM] Writing properties/obj_type_2/prob_interphase (202177,)\n",
      "[INFO][2022/05/15 10:30:40 AM] Writing properties/obj_type_2/prob_prometaphase (202177,)\n",
      "[INFO][2022/05/15 10:30:40 AM] Writing properties/obj_type_2/prob_metaphase (202177,)\n",
      "[INFO][2022/05/15 10:30:40 AM] Writing properties/obj_type_2/prob_anaphase (202177,)\n",
      "[INFO][2022/05/15 10:30:40 AM] Writing properties/obj_type_2/prob_apoptosis (202177,)\n",
      "[INFO][2022/05/15 10:30:40 AM] Closing HDF file: /home/nathan/data/kraken/ras/ND0013/Pos6/objects_type_2.h5\n",
      "[INFO][2022/05/15 10:30:40 AM] Opening HDF file: /home/nathan/data/kraken/ras/ND0013/Pos6/objects.h5...\n",
      "[INFO][2022/05/15 10:30:51 AM] Writing objects/obj_type_1\n",
      "[INFO][2022/05/15 10:30:51 AM] Writing labels/obj_type_1\n",
      "[INFO][2022/05/15 10:30:51 AM] Loading objects/obj_type_1 (1329084, 5) (1329084 filtered: None)\n",
      "[INFO][2022/05/15 10:31:05 AM] Writing properties/obj_type_1/area (1329084,)\n",
      "[INFO][2022/05/15 10:31:06 AM] Writing properties/obj_type_1/eccentricity (1329084,)\n",
      "[INFO][2022/05/15 10:31:06 AM] Writing properties/obj_type_1/mean_intensity (1329084,)\n",
      "[INFO][2022/05/15 10:31:06 AM] Writing properties/obj_type_1/class id (1329084,)\n",
      "[INFO][2022/05/15 10:31:06 AM] Writing properties/obj_type_1/prob_interphase (1329084,)\n",
      "[INFO][2022/05/15 10:31:06 AM] Writing properties/obj_type_1/prob_prometaphase (1329084,)\n",
      "[INFO][2022/05/15 10:31:06 AM] Writing properties/obj_type_1/prob_metaphase (1329084,)\n",
      "[INFO][2022/05/15 10:31:07 AM] Writing properties/obj_type_1/prob_anaphase (1329084,)\n",
      "[INFO][2022/05/15 10:31:07 AM] Writing properties/obj_type_1/prob_apoptosis (1329084,)\n",
      "[INFO][2022/05/15 10:31:07 AM] Closing HDF file: /home/nathan/data/kraken/ras/ND0013/Pos6/objects.h5\n",
      "[INFO][2022/05/15 10:31:07 AM] Opening HDF file: /home/nathan/data/kraken/ras/ND0013/Pos6/objects.h5...\n",
      "[INFO][2022/05/15 10:31:09 AM] Writing objects/obj_type_2\n",
      "[INFO][2022/05/15 10:31:09 AM] Writing labels/obj_type_2\n",
      "[INFO][2022/05/15 10:31:09 AM] Loading objects/obj_type_2 (202177, 5) (202177 filtered: None)\n",
      "[INFO][2022/05/15 10:31:10 AM] Writing properties/obj_type_2/area (202177,)\n",
      "[INFO][2022/05/15 10:31:10 AM] Writing properties/obj_type_2/eccentricity (202177,)\n",
      "[INFO][2022/05/15 10:31:10 AM] Writing properties/obj_type_2/mean_intensity (202177,)\n",
      "[INFO][2022/05/15 10:31:11 AM] Writing properties/obj_type_2/class id (202177,)\n",
      "[INFO][2022/05/15 10:31:11 AM] Writing properties/obj_type_2/prob_interphase (202177,)\n",
      "[INFO][2022/05/15 10:31:11 AM] Writing properties/obj_type_2/prob_prometaphase (202177,)\n",
      "[INFO][2022/05/15 10:31:11 AM] Writing properties/obj_type_2/prob_metaphase (202177,)\n",
      "[INFO][2022/05/15 10:31:11 AM] Writing properties/obj_type_2/prob_anaphase (202177,)\n",
      "[INFO][2022/05/15 10:31:11 AM] Writing properties/obj_type_2/prob_apoptosis (202177,)\n",
      "[INFO][2022/05/15 10:31:11 AM] Closing HDF file: /home/nathan/data/kraken/ras/ND0013/Pos6/objects.h5\n",
      "[INFO][2022/05/15 10:31:12 AM] Loaded btrack: /home/nathan/analysis/BayesianTracker/btrack/libs/libtracker.so\n",
      "[INFO][2022/05/15 10:31:12 AM] btrack (v0.4.3) library imported\n",
      "[INFO][2022/05/15 10:31:12 AM] Setting max XYZ search radius to: 100\n",
      "[INFO][2022/05/15 10:31:12 AM] Starting BayesianTracker session\n",
      "[INFO][2022/05/15 10:31:12 AM] Loading configuration file: ../models/MDCK_config_wildtype.json\n",
      "[INFO][2022/05/15 10:31:12 AM] Loading motion model: MDCK_motion\n",
      "[INFO][2022/05/15 10:31:12 AM] Setting max XYZ search radius to: 40\n",
      "[INFO][2022/05/15 10:31:12 AM] Objects are of type: <class 'list'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object localisation complete for ND0013 Pos6\n",
      "Starting tracking for ND0013 Pos6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/05/15 10:31:13 AM] Set volume to ((0, 1600), (0, 1200), (-100000.0, 100000.0))\n",
      "[INFO][2022/05/15 10:31:13 AM] Starting tracking... \n",
      "[INFO][2022/05/15 10:31:14 AM] Tracking objects in frames 0 to 99 (of 2787)...\n",
      "[INFO][2022/05/15 10:31:14 AM]  - Timing (Bayesian updates: 0.66ms, Linking: 0.17ms)\n",
      "[INFO][2022/05/15 10:31:14 AM]  - Probabilities (Link: 1.00000, Lost: 0.80191)\n",
      "[INFO][2022/05/15 10:31:14 AM]  - Stats (Active: 70, Lost: 1122, Conflicts resolved: 156)\n",
      "[INFO][2022/05/15 10:31:14 AM] Tracking objects in frames 100 to 199 (of 2787)...\n",
      "[INFO][2022/05/15 10:31:14 AM]  - Timing (Bayesian updates: 0.66ms, Linking: 0.16ms)\n",
      "[INFO][2022/05/15 10:31:14 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:31:14 AM]  - Stats (Active: 69, Lost: 2114, Conflicts resolved: 352)\n",
      "[INFO][2022/05/15 10:31:14 AM] Tracking objects in frames 200 to 299 (of 2787)...\n",
      "[INFO][2022/05/15 10:31:14 AM]  - Timing (Bayesian updates: 1.09ms, Linking: 0.22ms)\n",
      "[INFO][2022/05/15 10:31:14 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:31:14 AM]  - Stats (Active: 90, Lost: 3427, Conflicts resolved: 581)\n",
      "[INFO][2022/05/15 10:31:14 AM] Tracking objects in frames 300 to 399 (of 2787)...\n",
      "[INFO][2022/05/15 10:31:14 AM]  - Timing (Bayesian updates: 1.84ms, Linking: 0.28ms)\n",
      "[INFO][2022/05/15 10:31:14 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:31:14 AM]  - Stats (Active: 109, Lost: 5425, Conflicts resolved: 946)\n",
      "[INFO][2022/05/15 10:31:14 AM] Tracking objects in frames 400 to 499 (of 2787)...\n",
      "[INFO][2022/05/15 10:31:14 AM]  - Timing (Bayesian updates: 2.18ms, Linking: 0.31ms)\n",
      "[INFO][2022/05/15 10:31:14 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:31:14 AM]  - Stats (Active: 118, Lost: 6972, Conflicts resolved: 1282)\n",
      "[INFO][2022/05/15 10:31:14 AM] Tracking objects in frames 500 to 599 (of 2787)...\n",
      "[INFO][2022/05/15 10:31:15 AM]  - Timing (Bayesian updates: 6.25ms, Linking: 0.50ms)\n",
      "[INFO][2022/05/15 10:31:15 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:31:15 AM]  - Stats (Active: 189, Lost: 9551, Conflicts resolved: 1782)\n",
      "[INFO][2022/05/15 10:31:15 AM] Tracking objects in frames 600 to 699 (of 2787)...\n",
      "[INFO][2022/05/15 10:31:16 AM]  - Timing (Bayesian updates: 11.55ms, Linking: 0.77ms)\n",
      "[INFO][2022/05/15 10:31:16 AM]  - Probabilities (Link: 0.99996, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:31:16 AM]  - Stats (Active: 252, Lost: 13782, Conflicts resolved: 2709)\n",
      "[INFO][2022/05/15 10:31:16 AM] Tracking objects in frames 700 to 799 (of 2787)...\n",
      "[INFO][2022/05/15 10:31:17 AM]  - Timing (Bayesian updates: 23.05ms, Linking: 1.04ms)\n",
      "[INFO][2022/05/15 10:31:17 AM]  - Probabilities (Link: 1.00000, Lost: 0.99514)\n",
      "[INFO][2022/05/15 10:31:17 AM]  - Stats (Active: 345, Lost: 20519, Conflicts resolved: 4275)\n",
      "[INFO][2022/05/15 10:31:17 AM] Tracking objects in frames 800 to 899 (of 2787)...\n",
      "[INFO][2022/05/15 10:31:20 AM]  - Timing (Bayesian updates: 52.16ms, Linking: 1.83ms)\n",
      "[INFO][2022/05/15 10:31:20 AM]  - Probabilities (Link: 0.99996, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:31:20 AM]  - Stats (Active: 565, Lost: 28235, Conflicts resolved: 6645)\n",
      "[INFO][2022/05/15 10:31:20 AM] Tracking objects in frames 900 to 999 (of 2787)...\n",
      "[INFO][2022/05/15 10:31:25 AM]  - Timing (Bayesian updates: 46.18ms, Linking: 1.77ms)\n",
      "[INFO][2022/05/15 10:31:25 AM]  - Probabilities (Link: 1.00000, Lost: 0.88751)\n",
      "[INFO][2022/05/15 10:31:25 AM]  - Stats (Active: 460, Lost: 37028, Conflicts resolved: 8631)\n",
      "[INFO][2022/05/15 10:31:25 AM] Tracking objects in frames 1000 to 1099 (of 2787)...\n",
      "[INFO][2022/05/15 10:31:31 AM]  - Timing (Bayesian updates: 86.17ms, Linking: 2.54ms)\n",
      "[INFO][2022/05/15 10:31:31 AM]  - Probabilities (Link: 1.00000, Lost: 0.99840)\n",
      "[INFO][2022/05/15 10:31:31 AM]  - Stats (Active: 577, Lost: 45088, Conflicts resolved: 10667)\n",
      "[INFO][2022/05/15 10:31:31 AM] Tracking objects in frames 1100 to 1199 (of 2787)...\n",
      "[INFO][2022/05/15 10:31:41 AM]  - Timing (Bayesian updates: 104.49ms, Linking: 2.54ms)\n",
      "[INFO][2022/05/15 10:31:41 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:31:41 AM]  - Stats (Active: 624, Lost: 56060, Conflicts resolved: 13993)\n",
      "[INFO][2022/05/15 10:31:41 AM] Tracking objects in frames 1200 to 1299 (of 2787)...\n",
      "[INFO][2022/05/15 10:31:55 AM]  - Timing (Bayesian updates: 160.31ms, Linking: 3.76ms)\n",
      "[INFO][2022/05/15 10:31:55 AM]  - Probabilities (Link: 0.99832, Lost: 0.87514)\n",
      "[INFO][2022/05/15 10:31:55 AM]  - Stats (Active: 724, Lost: 65745, Conflicts resolved: 17169)\n",
      "[INFO][2022/05/15 10:31:55 AM] Tracking objects in frames 1300 to 1399 (of 2787)...\n",
      "[INFO][2022/05/15 10:32:13 AM]  - Timing (Bayesian updates: 169.07ms, Linking: 3.50ms)\n",
      "[INFO][2022/05/15 10:32:13 AM]  - Probabilities (Link: 0.99158, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:32:13 AM]  - Stats (Active: 712, Lost: 75381, Conflicts resolved: 20363)\n",
      "[INFO][2022/05/15 10:32:13 AM] Tracking objects in frames 1400 to 1499 (of 2787)...\n",
      "[INFO][2022/05/15 10:32:32 AM]  - Timing (Bayesian updates: 194.77ms, Linking: 3.70ms)\n",
      "[INFO][2022/05/15 10:32:32 AM]  - Probabilities (Link: 0.99970, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:32:32 AM]  - Stats (Active: 752, Lost: 85067, Conflicts resolved: 24529)\n",
      "[INFO][2022/05/15 10:32:32 AM] Tracking objects in frames 1500 to 1599 (of 2787)...\n",
      "[INFO][2022/05/15 10:32:53 AM]  - Timing (Bayesian updates: 206.07ms, Linking: 3.98ms)\n",
      "[INFO][2022/05/15 10:32:53 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:32:53 AM]  - Stats (Active: 769, Lost: 93353, Conflicts resolved: 28168)\n",
      "[INFO][2022/05/15 10:32:53 AM] Tracking objects in frames 1600 to 1699 (of 2787)...\n",
      "[INFO][2022/05/15 10:33:13 AM]  - Timing (Bayesian updates: 212.01ms, Linking: 3.74ms)\n",
      "[INFO][2022/05/15 10:33:13 AM]  - Probabilities (Link: 1.00000, Lost: 0.61771)\n",
      "[INFO][2022/05/15 10:33:13 AM]  - Stats (Active: 787, Lost: 99949, Conflicts resolved: 30852)\n",
      "[INFO][2022/05/15 10:33:13 AM] Tracking objects in frames 1700 to 1799 (of 2787)...\n",
      "[INFO][2022/05/15 10:33:35 AM]  - Timing (Bayesian updates: 207.91ms, Linking: 3.84ms)\n",
      "[INFO][2022/05/15 10:33:35 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:33:35 AM]  - Stats (Active: 770, Lost: 106424, Conflicts resolved: 33552)\n",
      "[INFO][2022/05/15 10:33:35 AM] Tracking objects in frames 1800 to 1899 (of 2787)...\n",
      "[INFO][2022/05/15 10:33:58 AM]  - Timing (Bayesian updates: 227.48ms, Linking: 4.03ms)\n",
      "[INFO][2022/05/15 10:33:58 AM]  - Probabilities (Link: 0.99981, Lost: 0.77607)\n",
      "[INFO][2022/05/15 10:33:58 AM]  - Stats (Active: 800, Lost: 113553, Conflicts resolved: 37273)\n",
      "[INFO][2022/05/15 10:33:58 AM] Tracking objects in frames 1900 to 1999 (of 2787)...\n",
      "[INFO][2022/05/15 10:34:21 AM]  - Timing (Bayesian updates: 215.08ms, Linking: 4.13ms)\n",
      "[INFO][2022/05/15 10:34:21 AM]  - Probabilities (Link: 0.99948, Lost: 0.92636)\n",
      "[INFO][2022/05/15 10:34:21 AM]  - Stats (Active: 761, Lost: 117823, Conflicts resolved: 39237)\n",
      "[INFO][2022/05/15 10:34:21 AM] Tracking objects in frames 2000 to 2099 (of 2787)...\n",
      "[INFO][2022/05/15 10:34:44 AM]  - Timing (Bayesian updates: 218.32ms, Linking: 3.91ms)\n",
      "[INFO][2022/05/15 10:34:44 AM]  - Probabilities (Link: 0.99721, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:34:44 AM]  - Stats (Active: 767, Lost: 123232, Conflicts resolved: 41441)\n",
      "[INFO][2022/05/15 10:34:44 AM] Tracking objects in frames 2100 to 2199 (of 2787)...\n",
      "[INFO][2022/05/15 10:35:06 AM]  - Timing (Bayesian updates: 302.52ms, Linking: 5.09ms)\n",
      "[INFO][2022/05/15 10:35:06 AM]  - Probabilities (Link: 0.99799, Lost: 0.99964)\n",
      "[INFO][2022/05/15 10:35:06 AM]  - Stats (Active: 1034, Lost: 128677, Conflicts resolved: 44058)\n",
      "[INFO][2022/05/15 10:35:06 AM] Tracking objects in frames 2200 to 2299 (of 2787)...\n",
      "[INFO][2022/05/15 10:35:30 AM]  - Timing (Bayesian updates: 233.10ms, Linking: 4.23ms)\n",
      "[INFO][2022/05/15 10:35:30 AM]  - Probabilities (Link: 0.99979, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:35:30 AM]  - Stats (Active: 783, Lost: 133374, Conflicts resolved: 46223)\n",
      "[INFO][2022/05/15 10:35:30 AM] Tracking objects in frames 2300 to 2399 (of 2787)...\n",
      "[INFO][2022/05/15 10:35:54 AM]  - Timing (Bayesian updates: 235.82ms, Linking: 4.71ms)\n",
      "[INFO][2022/05/15 10:35:54 AM]  - Probabilities (Link: 1.00000, Lost: 0.94502)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/05/15 10:35:54 AM]  - Stats (Active: 820, Lost: 138707, Conflicts resolved: 48752)\n",
      "[INFO][2022/05/15 10:35:54 AM] Tracking objects in frames 2400 to 2499 (of 2787)...\n",
      "[INFO][2022/05/15 10:36:18 AM]  - Timing (Bayesian updates: 221.47ms, Linking: 4.32ms)\n",
      "[INFO][2022/05/15 10:36:18 AM]  - Probabilities (Link: 0.99998, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:36:18 AM]  - Stats (Active: 782, Lost: 146017, Conflicts resolved: 52117)\n",
      "[INFO][2022/05/15 10:36:18 AM] Tracking objects in frames 2500 to 2599 (of 2787)...\n",
      "[INFO][2022/05/15 10:36:42 AM]  - Timing (Bayesian updates: 222.36ms, Linking: 4.32ms)\n",
      "[INFO][2022/05/15 10:36:42 AM]  - Probabilities (Link: 1.00000, Lost: 0.99746)\n",
      "[INFO][2022/05/15 10:36:42 AM]  - Stats (Active: 791, Lost: 151878, Conflicts resolved: 55047)\n",
      "[INFO][2022/05/15 10:36:42 AM] Tracking objects in frames 2600 to 2699 (of 2787)...\n",
      "[INFO][2022/05/15 10:37:05 AM]  - Timing (Bayesian updates: 223.41ms, Linking: 4.17ms)\n",
      "[INFO][2022/05/15 10:37:05 AM]  - Probabilities (Link: 1.00000, Lost: 0.99771)\n",
      "[INFO][2022/05/15 10:37:05 AM]  - Stats (Active: 791, Lost: 157862, Conflicts resolved: 57863)\n",
      "[INFO][2022/05/15 10:37:05 AM] Tracking objects in frames 2700 to 2787 (of 2787)...\n",
      "[INFO][2022/05/15 10:37:24 AM]  - Timing (Bayesian updates: 202.33ms, Linking: 4.54ms)\n",
      "[INFO][2022/05/15 10:37:24 AM]  - Probabilities (Link: 1.00000, Lost: 0.98680)\n",
      "[INFO][2022/05/15 10:37:24 AM] SUCCESS.\n",
      "[INFO][2022/05/15 10:37:24 AM]  - Found 34183 tracks in 2787 frames (in 0.0s)\n",
      "[INFO][2022/05/15 10:37:25 AM]  - Inserted 38998 dummy objects to fill tracking gaps\n",
      "[INFO][2022/05/15 10:37:25 AM] Loading hypothesis model: MDCK_hypothesis_wildtype\n",
      "[INFO][2022/05/15 10:37:25 AM] Calculating hypotheses (relax: True)...\n",
      "[INFO][2022/05/15 10:37:25 AM] Setting up constraints matrix for global optimisation...\n",
      "[INFO][2022/05/15 10:37:26 AM] Optimizing...\n",
      "[INFO][2022/05/15 10:37:26 AM] Optimization complete. (Solution: optimal)\n",
      "[INFO][2022/05/15 10:37:26 AM]  - Fates.FALSE_POSITIVE: 34183 (of 34183)\n",
      "[INFO][2022/05/15 10:37:26 AM]  - TOTAL: 34183 hypotheses\n",
      "[INFO][2022/05/15 10:37:26 AM] Completed optimization with 34183 tracks\n",
      "[INFO][2022/05/15 10:37:26 AM] Opening HDF file: /home/nathan/data/kraken/ras/ND0013/Pos6/tracks.h5...\n",
      "[INFO][2022/05/15 10:37:37 AM] Writing objects/obj_type_1\n",
      "[INFO][2022/05/15 10:37:37 AM] Writing labels/obj_type_1\n",
      "[INFO][2022/05/15 10:37:37 AM] Loading objects/obj_type_1 (1329084, 5) (1329084 filtered: None)\n",
      "[INFO][2022/05/15 10:37:53 AM] Writing properties/obj_type_1/area (1329084,)\n",
      "[INFO][2022/05/15 10:37:53 AM] Writing properties/obj_type_1/eccentricity (1329084,)\n",
      "[INFO][2022/05/15 10:37:53 AM] Writing properties/obj_type_1/mean_intensity (1329084,)\n",
      "[INFO][2022/05/15 10:37:53 AM] Writing properties/obj_type_1/class id (1329084,)\n",
      "[INFO][2022/05/15 10:37:53 AM] Writing properties/obj_type_1/prob_interphase (1329084,)\n",
      "[INFO][2022/05/15 10:37:54 AM] Writing properties/obj_type_1/prob_prometaphase (1329084,)\n",
      "[INFO][2022/05/15 10:37:54 AM] Writing properties/obj_type_1/prob_metaphase (1329084,)\n",
      "[INFO][2022/05/15 10:37:54 AM] Writing properties/obj_type_1/prob_anaphase (1329084,)\n",
      "[INFO][2022/05/15 10:37:54 AM] Writing properties/obj_type_1/prob_apoptosis (1329084,)\n",
      "[INFO][2022/05/15 10:37:58 AM] Writing tracks/obj_type_1\n",
      "[INFO][2022/05/15 10:37:58 AM] Writing dummies/obj_type_1\n",
      "[INFO][2022/05/15 10:37:58 AM] Writing LBEP/obj_type_1\n",
      "[INFO][2022/05/15 10:37:58 AM] Writing fates/obj_type_1\n",
      "[INFO][2022/05/15 10:37:59 AM] Closing HDF file: /home/nathan/data/kraken/ras/ND0013/Pos6/tracks.h5\n",
      "[INFO][2022/05/15 10:37:59 AM] Ending BayesianTracker session\n",
      "[INFO][2022/05/15 10:38:01 AM] Loaded btrack: /home/nathan/analysis/BayesianTracker/btrack/libs/libtracker.so\n",
      "[INFO][2022/05/15 10:38:01 AM] btrack (v0.4.3) library imported\n",
      "[INFO][2022/05/15 10:38:01 AM] Setting max XYZ search radius to: 100\n",
      "[INFO][2022/05/15 10:38:01 AM] Starting BayesianTracker session\n",
      "[INFO][2022/05/15 10:38:01 AM] Loading configuration file: ../models/MDCK_config_scribble_sparse.json\n",
      "[INFO][2022/05/15 10:38:01 AM] Loading motion model: MDCK_motion\n",
      "[INFO][2022/05/15 10:38:01 AM] Setting max XYZ search radius to: 40\n",
      "[INFO][2022/05/15 10:38:01 AM] Objects are of type: <class 'list'>\n",
      "[INFO][2022/05/15 10:38:01 AM] Set volume to ((0, 1600), (0, 1200), (-100000.0, 100000.0))\n",
      "[INFO][2022/05/15 10:38:01 AM] Starting tracking... \n",
      "[INFO][2022/05/15 10:38:01 AM] Tracking objects in frames 0 to 99 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Timing (Bayesian updates: 0.01ms, Linking: 0.02ms)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Stats (Active: 10, Lost: 398, Conflicts resolved: 22)\n",
      "[INFO][2022/05/15 10:38:01 AM] Tracking objects in frames 100 to 199 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Timing (Bayesian updates: 0.03ms, Linking: 0.04ms)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Probabilities (Link: 0.99914, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Stats (Active: 14, Lost: 1034, Conflicts resolved: 32)\n",
      "[INFO][2022/05/15 10:38:01 AM] Tracking objects in frames 200 to 299 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Timing (Bayesian updates: 0.02ms, Linking: 0.02ms)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Stats (Active: 12, Lost: 1941, Conflicts resolved: 68)\n",
      "[INFO][2022/05/15 10:38:01 AM] Tracking objects in frames 300 to 399 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Timing (Bayesian updates: 0.02ms, Linking: 0.03ms)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Probabilities (Link: 0.99999, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Stats (Active: 12, Lost: 3305, Conflicts resolved: 96)\n",
      "[INFO][2022/05/15 10:38:01 AM] Tracking objects in frames 400 to 499 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Timing (Bayesian updates: 0.03ms, Linking: 0.03ms)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Probabilities (Link: 0.99992, Lost: 0.99968)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Stats (Active: 13, Lost: 4086, Conflicts resolved: 136)\n",
      "[INFO][2022/05/15 10:38:01 AM] Tracking objects in frames 500 to 599 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Timing (Bayesian updates: 0.04ms, Linking: 0.04ms)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Stats (Active: 18, Lost: 4727, Conflicts resolved: 169)\n",
      "[INFO][2022/05/15 10:38:01 AM] Tracking objects in frames 600 to 699 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Timing (Bayesian updates: 0.06ms, Linking: 0.05ms)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Probabilities (Link: 0.99151, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Stats (Active: 19, Lost: 5499, Conflicts resolved: 215)\n",
      "[INFO][2022/05/15 10:38:01 AM] Tracking objects in frames 700 to 799 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Timing (Bayesian updates: 0.10ms, Linking: 0.06ms)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Probabilities (Link: 0.99999, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Stats (Active: 29, Lost: 6445, Conflicts resolved: 265)\n",
      "[INFO][2022/05/15 10:38:01 AM] Tracking objects in frames 800 to 899 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Timing (Bayesian updates: 0.22ms, Linking: 0.10ms)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Probabilities (Link: 0.99998, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Stats (Active: 47, Lost: 7491, Conflicts resolved: 371)\n",
      "[INFO][2022/05/15 10:38:01 AM] Tracking objects in frames 900 to 999 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Timing (Bayesian updates: 0.18ms, Linking: 0.11ms)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Stats (Active: 40, Lost: 8493, Conflicts resolved: 453)\n",
      "[INFO][2022/05/15 10:38:01 AM] Tracking objects in frames 1000 to 1099 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Timing (Bayesian updates: 0.28ms, Linking: 0.11ms)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Stats (Active: 49, Lost: 9440, Conflicts resolved: 554)\n",
      "[INFO][2022/05/15 10:38:01 AM] Tracking objects in frames 1100 to 1199 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Timing (Bayesian updates: 0.76ms, Linking: 0.19ms)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/05/15 10:38:01 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Stats (Active: 76, Lost: 14455, Conflicts resolved: 769)\n",
      "[INFO][2022/05/15 10:38:01 AM] Tracking objects in frames 1200 to 1299 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Timing (Bayesian updates: 0.92ms, Linking: 0.20ms)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Probabilities (Link: 0.99945, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:01 AM]  - Stats (Active: 81, Lost: 15776, Conflicts resolved: 887)\n",
      "[INFO][2022/05/15 10:38:01 AM] Tracking objects in frames 1300 to 1399 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:02 AM]  - Timing (Bayesian updates: 1.38ms, Linking: 0.25ms)\n",
      "[INFO][2022/05/15 10:38:02 AM]  - Probabilities (Link: 0.97856, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:02 AM]  - Stats (Active: 95, Lost: 17205, Conflicts resolved: 1043)\n",
      "[INFO][2022/05/15 10:38:02 AM] Tracking objects in frames 1400 to 1499 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:02 AM]  - Timing (Bayesian updates: 1.65ms, Linking: 0.26ms)\n",
      "[INFO][2022/05/15 10:38:02 AM]  - Probabilities (Link: 0.99895, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:02 AM]  - Stats (Active: 102, Lost: 18835, Conflicts resolved: 1217)\n",
      "[INFO][2022/05/15 10:38:02 AM] Tracking objects in frames 1500 to 1599 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:02 AM]  - Timing (Bayesian updates: 1.82ms, Linking: 0.27ms)\n",
      "[INFO][2022/05/15 10:38:02 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:02 AM]  - Stats (Active: 103, Lost: 20187, Conflicts resolved: 1383)\n",
      "[INFO][2022/05/15 10:38:02 AM] Tracking objects in frames 1600 to 1699 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:02 AM]  - Timing (Bayesian updates: 2.19ms, Linking: 0.32ms)\n",
      "[INFO][2022/05/15 10:38:02 AM]  - Probabilities (Link: 1.00000, Lost: 0.99971)\n",
      "[INFO][2022/05/15 10:38:02 AM]  - Stats (Active: 115, Lost: 21331, Conflicts resolved: 1465)\n",
      "[INFO][2022/05/15 10:38:02 AM] Tracking objects in frames 1700 to 1799 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:03 AM]  - Timing (Bayesian updates: 2.51ms, Linking: 0.33ms)\n",
      "[INFO][2022/05/15 10:38:03 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:03 AM]  - Stats (Active: 121, Lost: 22271, Conflicts resolved: 1550)\n",
      "[INFO][2022/05/15 10:38:03 AM] Tracking objects in frames 1800 to 1899 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:03 AM]  - Timing (Bayesian updates: 2.51ms, Linking: 0.34ms)\n",
      "[INFO][2022/05/15 10:38:03 AM]  - Probabilities (Link: 0.99994, Lost: 0.63950)\n",
      "[INFO][2022/05/15 10:38:03 AM]  - Stats (Active: 125, Lost: 23521, Conflicts resolved: 1691)\n",
      "[INFO][2022/05/15 10:38:03 AM] Tracking objects in frames 1900 to 1999 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:03 AM]  - Timing (Bayesian updates: 2.60ms, Linking: 0.33ms)\n",
      "[INFO][2022/05/15 10:38:03 AM]  - Probabilities (Link: 0.99797, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:03 AM]  - Stats (Active: 123, Lost: 24711, Conflicts resolved: 1809)\n",
      "[INFO][2022/05/15 10:38:03 AM] Tracking objects in frames 2000 to 2099 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:04 AM]  - Timing (Bayesian updates: 3.02ms, Linking: 0.37ms)\n",
      "[INFO][2022/05/15 10:38:04 AM]  - Probabilities (Link: 0.98266, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:04 AM]  - Stats (Active: 136, Lost: 30698, Conflicts resolved: 2079)\n",
      "[INFO][2022/05/15 10:38:04 AM] Tracking objects in frames 2100 to 2199 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:04 AM]  - Timing (Bayesian updates: 4.19ms, Linking: 0.45ms)\n",
      "[INFO][2022/05/15 10:38:04 AM]  - Probabilities (Link: 0.98689, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:04 AM]  - Stats (Active: 187, Lost: 32263, Conflicts resolved: 2246)\n",
      "[INFO][2022/05/15 10:38:04 AM] Tracking objects in frames 2200 to 2299 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:05 AM]  - Timing (Bayesian updates: 3.49ms, Linking: 0.39ms)\n",
      "[INFO][2022/05/15 10:38:05 AM]  - Probabilities (Link: 0.99997, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:05 AM]  - Stats (Active: 145, Lost: 34029, Conflicts resolved: 2417)\n",
      "[INFO][2022/05/15 10:38:05 AM] Tracking objects in frames 2300 to 2399 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:05 AM]  - Timing (Bayesian updates: 4.34ms, Linking: 0.46ms)\n",
      "[INFO][2022/05/15 10:38:05 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:05 AM]  - Stats (Active: 159, Lost: 36302, Conflicts resolved: 2697)\n",
      "[INFO][2022/05/15 10:38:05 AM] Tracking objects in frames 2400 to 2499 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:06 AM]  - Timing (Bayesian updates: 3.96ms, Linking: 0.43ms)\n",
      "[INFO][2022/05/15 10:38:06 AM]  - Probabilities (Link: 0.99998, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:06 AM]  - Stats (Active: 150, Lost: 43211, Conflicts resolved: 3104)\n",
      "[INFO][2022/05/15 10:38:06 AM] Tracking objects in frames 2500 to 2599 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:06 AM]  - Timing (Bayesian updates: 4.23ms, Linking: 0.47ms)\n",
      "[INFO][2022/05/15 10:38:06 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:06 AM]  - Stats (Active: 163, Lost: 45607, Conflicts resolved: 3439)\n",
      "[INFO][2022/05/15 10:38:06 AM] Tracking objects in frames 2600 to 2699 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:07 AM]  - Timing (Bayesian updates: 4.59ms, Linking: 0.49ms)\n",
      "[INFO][2022/05/15 10:38:07 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:07 AM]  - Stats (Active: 167, Lost: 48112, Conflicts resolved: 3798)\n",
      "[INFO][2022/05/15 10:38:07 AM] Tracking objects in frames 2700 to 2787 (of 2787)...\n",
      "[INFO][2022/05/15 10:38:07 AM]  - Timing (Bayesian updates: 4.17ms, Linking: 0.44ms)\n",
      "[INFO][2022/05/15 10:38:07 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2022/05/15 10:38:07 AM] SUCCESS.\n",
      "[INFO][2022/05/15 10:38:07 AM]  - Found 8994 tracks in 2787 frames (in 0.0s)\n",
      "[INFO][2022/05/15 10:38:08 AM]  - Inserted 2526 dummy objects to fill tracking gaps\n",
      "[INFO][2022/05/15 10:38:08 AM] Loading hypothesis model: MDCK_hypothesis_scribble_sparse\n",
      "[INFO][2022/05/15 10:38:08 AM] Calculating hypotheses (relax: True)...\n",
      "[INFO][2022/05/15 10:38:08 AM] Setting up constraints matrix for global optimisation...\n",
      "[INFO][2022/05/15 10:38:08 AM] Optimizing...\n",
      "[INFO][2022/05/15 10:38:08 AM] Optimization complete. (Solution: optimal)\n",
      "[INFO][2022/05/15 10:38:08 AM]  - Fates.FALSE_POSITIVE: 8994 (of 8994)\n",
      "[INFO][2022/05/15 10:38:08 AM]  - TOTAL: 8994 hypotheses\n",
      "[INFO][2022/05/15 10:38:08 AM] Completed optimization with 8994 tracks\n",
      "[INFO][2022/05/15 10:38:08 AM] Opening HDF file: /home/nathan/data/kraken/ras/ND0013/Pos6/tracks.h5...\n",
      "[INFO][2022/05/15 10:38:09 AM] Writing objects/obj_type_2\n",
      "[INFO][2022/05/15 10:38:09 AM] Writing labels/obj_type_2\n",
      "[INFO][2022/05/15 10:38:09 AM] Loading objects/obj_type_2 (202177, 5) (202177 filtered: None)\n",
      "[INFO][2022/05/15 10:38:11 AM] Writing properties/obj_type_2/area (202177,)\n",
      "[INFO][2022/05/15 10:38:11 AM] Writing properties/obj_type_2/eccentricity (202177,)\n",
      "[INFO][2022/05/15 10:38:11 AM] Writing properties/obj_type_2/mean_intensity (202177,)\n",
      "[INFO][2022/05/15 10:38:11 AM] Writing properties/obj_type_2/class id (202177,)\n",
      "[INFO][2022/05/15 10:38:11 AM] Writing properties/obj_type_2/prob_interphase (202177,)\n",
      "[INFO][2022/05/15 10:38:11 AM] Writing properties/obj_type_2/prob_prometaphase (202177,)\n",
      "[INFO][2022/05/15 10:38:11 AM] Writing properties/obj_type_2/prob_metaphase (202177,)\n",
      "[INFO][2022/05/15 10:38:11 AM] Writing properties/obj_type_2/prob_anaphase (202177,)\n",
      "[INFO][2022/05/15 10:38:12 AM] Writing properties/obj_type_2/prob_apoptosis (202177,)\n",
      "[INFO][2022/05/15 10:38:12 AM] Writing tracks/obj_type_2\n",
      "[INFO][2022/05/15 10:38:12 AM] Writing dummies/obj_type_2\n",
      "[INFO][2022/05/15 10:38:12 AM] Writing LBEP/obj_type_2\n",
      "[INFO][2022/05/15 10:38:12 AM] Writing fates/obj_type_2\n",
      "[INFO][2022/05/15 10:38:12 AM] Closing HDF file: /home/nathan/data/kraken/ras/ND0013/Pos6/tracks.h5\n",
      "[INFO][2022/05/15 10:38:12 AM] Ending BayesianTracker session\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/home/nathan/data/kraken/ras'\n",
    "\n",
    "for i, expt_pos in tqdm(expt_pos_list.iterrows(), desc = 'Progress of experiment annotation', total = len(expt_pos_list)):    \n",
    "    expt = expt_pos['Experiments']\n",
    "    pos = expt_pos['Positions']\n",
    "    if pos != 'Pos6':\n",
    "        continue\n",
    "    print(f'Starting alignment for {expt}/{pos}')\n",
    "\n",
    "    ### create new subdir of for raw files and move them all there\n",
    "    image_path = f'{root_dir}/{expt}/{pos}/{pos}_images'\n",
    "    if not os.path.exists(image_path):\n",
    "        os.mkdir(image_path)\n",
    "        files = sorted(glob.glob(f'{root_dir}/{expt}/{pos}/*.tif'))\n",
    "        for file in files:\n",
    "            os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_images'))\n",
    "\n",
    "    # check if blanks dir exists and make if not and move\n",
    "    if not os.path.exists(f'{root_dir}/{expt}/{pos}/{pos}_blanks'):\n",
    "        os.mkdir(f'{root_dir}/{expt}/{pos}/{pos}_blanks')\n",
    "        ### pre load files from raw file dir \n",
    "        images = DaskOctopusLiteLoader(image_path, remove_background= False)\n",
    "\n",
    "        ### measure mean pixel value arrays and use to find under/over-exposed frames\n",
    "        max_pixel = 200\n",
    "        min_pixel = 2\n",
    "        # set empty dict arrays for mean values \n",
    "        mean_arrays = {}\n",
    "        # set for dodgy frames (only unique entries)\n",
    "        dodgy_frame_list = set([])\n",
    "        #iterate over channels\n",
    "        for channel in tqdm(images.channels, desc = f'Finding mean values of image channels'):\n",
    "            if 'MASK' in channel.name:\n",
    "                continue\n",
    "            # find mean value of each frame in each channel\n",
    "            mean_arrays[channel.name] = [np.mean(img) for img in image_generator(images.files(channel.name))]\n",
    "            # iterate over frames\n",
    "            for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "                # check to see if mean frame pixel value meets criteria\n",
    "                if max_pixel < mean_value or mean_value < min_pixel:\n",
    "                    # if so add to delete list\n",
    "                    dodgy_frame_list.add(frame)\n",
    "        # format delete list to only include single values\n",
    "        dodgy_frame_list = list(dodgy_frame_list)\n",
    "        print('Number of under/over-exposed frames:', len(dodgy_frame_list))\n",
    "\n",
    "        # move blank images into this directory\n",
    "        for channel in images.channels:\n",
    "            for f in images.files(channel.name):\n",
    "                for i in dodgy_frame_list:\n",
    "                    if str(i).zfill(9) in f:\n",
    "                        os.rename(f, f.replace('_images', '_blanks'))\n",
    "\n",
    "    if not os.path.exists(f'{root_dir}/{expt}/{pos}/transform_tensor.npy'):\n",
    "        # crop central window out of reference image with blanks removed\n",
    "        reference_image = DaskOctopusLiteLoader(image_path, \n",
    "                                                crop = (500, 500)\n",
    "                                               )['gfp'].compute() \n",
    "\n",
    "\n",
    "        ### Register alignment\n",
    "        print('Registering alignment for', pos, expt)\n",
    "        # create operator using transformation type (translation)\n",
    "        sr = StackReg(StackReg.TRANSLATION) \n",
    "        # register each frame to the previous as transformation matrices/tensor\n",
    "        transform_tensor = sr.register_stack(reference_image, reference = 'previous', )\n",
    "\n",
    "        ### clip transformation tensor to eliminate any rare jumps, (1688-1600)/2=44\n",
    "        transform_tensor = np.clip(transform_tensor, a_max= 44, a_min = -44)\n",
    "\n",
    "        # save out transform tensor\n",
    "        np.save(f'{root_dir}/{expt}/{pos}/transform_tensor.npy', transform_tensor)\n",
    "\n",
    "        print('Alignment complete for', expt, pos)\n",
    "\n",
    "\n",
    "\n",
    "    print('Starting segmentation for', expt, pos)\n",
    "    # load images\n",
    "    images = DaskOctopusLiteLoader(image_path, \n",
    "                                   remove_background = True)\n",
    "    \n",
    "    \n",
    "    if 'MASK_GFP' in [channel.name for channel in images.channels]:\n",
    "        print('Masks already preprocessing, skipping to next experiment')\n",
    "        continue\n",
    "    # iterate over images filenames \n",
    "    for frame, fn in tqdm(enumerate(images.files('gfp')),total = len(images.files('gfp'))):\n",
    "        # load two seperate images\n",
    "        if os.path.exists(fn.replace('channel001', 'channel099')):\n",
    "            continue\n",
    "        gfp = imread(fn)\n",
    "        # predict gfp labels with a higher threshold as the fl. signal is strong\n",
    "        labels, details = seg_model.predict_instances(normalize(gfp), prob_thresh=0.75)\n",
    "        # create empty mask image\n",
    "        mask = np.zeros(labels.shape, dtype = np.uint8)\n",
    "        # remove any small, unrealistically nuclear objects from seg output\n",
    "        labels = remove_small_objects(labels, min_size = 200)\n",
    "        ### image post processing, start at 1 to skip background label\n",
    "        for i in range(1, np.amax(labels)):\n",
    "            #needs erosion step to stop merging of labels\n",
    "            segment = labels == i\n",
    "            seg_props = regionprops(label(segment), cache = False)\n",
    "            ### if segment exists, subject to exclusion criteria\n",
    "            if seg_props:\n",
    "                ### if segment area is large and elliptical it is probably a missclassified ras cyto (keeping for future use)\n",
    "                if 2000 <= seg_props[0].area or seg_props[0].eccentricity > 0.95:\n",
    "                    ### dont bother eroding the large ras cyto masks as will add time\n",
    "                    #segment = binary_erosion(segment)\n",
    "                    mask[segment] = 3\n",
    "                else:\n",
    "                    segment = binary_erosion(segment)\n",
    "                    mask[segment] = 1\n",
    "\n",
    "        # now do the same for the rfp channel\n",
    "        rfp = imread(fn.replace('channel001', 'channel002'))   \n",
    "        # predict labels a much lower threshold as rfp signal is dim\n",
    "        labels, details = seg_model.predict_instances(normalize(rfp), prob_thresh=0.2)\n",
    "\n",
    "        ### remove small objects (low thresh picks up hot pixels) also reduce number of iterations needed for individual binary erosion\n",
    "        labels = remove_small_objects(labels, min_size = 200)\n",
    "\n",
    "        ### iterate over individual segments, eroding and reassigning label to not merge\n",
    "        for i in range(1, np.amax(labels)):\n",
    "            #needs erosion step to stop merging of labels\n",
    "            segment = labels == i\n",
    "            segment = binary_erosion(segment)\n",
    "            ## add to main mask\n",
    "            mask[segment] = 2\n",
    "\n",
    "        # set filename as mask format (channel099)\n",
    "        fn = ((images.files('gfp')[frame])).replace('channel001', 'channel099')\n",
    "        #save out labelled image\n",
    "        imsave(fn, mask.astype(np.uint8), check_contrast=False)\n",
    "        \n",
    "    print('Segmentation complete for', expt, pos)\n",
    "\n",
    "    \n",
    "    print('Starting object localisation for', expt, pos)\n",
    "    \n",
    "    #if not os.path.exists(f'{root_dir}/{expt}/{pos}/objects.h5'):\n",
    "    transform_path = f'{root_dir}/{expt}/{pos}/transform_tensor.npy'\n",
    "    images = DaskOctopusLiteLoader(image_path, \n",
    "                                   transforms=transform_path,\n",
    "                                   crop=(1200,1600), \n",
    "                                   remove_background=True)\n",
    "\n",
    "    ## loading seperate instances of objects so that fl. intensities can be measured\n",
    "    objects_gfp = btrack.utils.segmentation_to_objects(\n",
    "        images['mask']==1,\n",
    "        images['gfp'],\n",
    "        properties = ('area', 'eccentricity', 'mean_intensity'),\n",
    "        assign_class_ID = True,\n",
    "    )\n",
    "    objects_rfp = btrack.utils.segmentation_to_objects(\n",
    "        (images['mask']==2)*2,\n",
    "        images['rfp'],\n",
    "        properties = ('area', 'eccentricity', 'mean_intensity'),\n",
    "        assign_class_ID = True,\n",
    "    )\n",
    "    ### filter for size\n",
    "    ### probably redundant two lines but just keeping as insurance\n",
    "#         objects_gfp = [o for o in objects_gfp if 4000.>o.properties['area']>100.]\n",
    "#         objects_rfp = [o for o in objects_rfp if 4000.>o.properties['area']>100.]\n",
    "#         objects_gfp = [obj for obj in objects_gfp if obj.properties['class id'] == 1]\n",
    "#         objects_rfp = [obj for obj in objects_rfp if obj.properties['class id'] == 2]\n",
    "\n",
    "    model = load_model('../models/cellx_classifier_stardist.h5')\n",
    "\n",
    "    bf = images['brightfield']\n",
    "    gfp = images['gfp']\n",
    "    rfp = images['rfp']\n",
    "\n",
    "    print('Classifying objects in', expt, pos)\n",
    "    objects_gfp = classify_objects(bf, gfp, rfp, objects_gfp, obj_type = 1)\n",
    "    objects_rfp = classify_objects(bf, gfp, rfp, objects_rfp, obj_type = 2)\n",
    "\n",
    "    with btrack.dataio.HDF5FileHandler(\n",
    "        f'{root_dir}/{expt}/{pos}/objects_type_1.h5', 'w', obj_type='obj_type_1',\n",
    "    ) as hdf:\n",
    "        #hdf.write_segmentation(masks['mask'])\n",
    "        hdf.write_objects(objects_gfp)    \n",
    "\n",
    "    with btrack.dataio.HDF5FileHandler(\n",
    "        f'{root_dir}/{expt}/{pos}/objects_type_2.h5', 'w', obj_type='obj_type_2',\n",
    "    ) as hdf:\n",
    "        #hdf.write_segmentation(masks['mask'])\n",
    "        hdf.write_objects(objects_rfp)\n",
    "\n",
    "    with btrack.dataio.HDF5FileHandler(\n",
    "        f'{root_dir}/{expt}/{pos}/objects.h5', 'w', obj_type='obj_type_1',\n",
    "    ) as hdf:\n",
    "        #hdf.write_segmentation(masks['mask'])\n",
    "        hdf.write_objects(objects_gfp)\n",
    "\n",
    "    with btrack.dataio.HDF5FileHandler(\n",
    "        f'{root_dir}/{expt}/{pos}/objects.h5', 'a', obj_type='obj_type_2',\n",
    "    ) as hdf:\n",
    "        #hdf.write_segmentation(masks['mask'])\n",
    "        hdf.write_objects(objects_rfp)\n",
    "\n",
    "    print('Object localisation complete for', expt, pos)\n",
    "\n",
    "    print('Starting tracking for', expt, pos)\n",
    "    \n",
    "    #if not os.path.exists(f'{root_dir}/{expt}/{pos}/tracks.h5'):\n",
    "    # initialise a tracker session using a context manager\n",
    "    with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "        # configure the tracker using a config file\n",
    "        tracker.configure_from_file(\n",
    "            '../models/MDCK_config_wildtype.json'\n",
    "        )\n",
    "        tracker.max_search_radius = 40\n",
    "\n",
    "        # append the objects to be tracked\n",
    "        tracker.append(objects_gfp)\n",
    "\n",
    "        # set the volume\n",
    "        tracker.volume=((0, 1600), (0, 1200), (-1e5, 1e5))\n",
    "\n",
    "        # track them (in interactive mode)\n",
    "        tracker.track_interactive(step_size=100)\n",
    "\n",
    "        # generate hypotheses and run the global optimizer\n",
    "        tracker.optimize()\n",
    "\n",
    "        tracker.export(f'{root_dir}/{expt}/{pos}/tracks.h5', obj_type='obj_type_1')\n",
    "\n",
    "        # get the tracks in a format for napari visualization (optional)\n",
    "#         visaulise_tracks, properties, graph = tracker.to_napari(ndim=2)\n",
    "\n",
    "#         gfp_tracks = tracker.tracks\n",
    "\n",
    "    # initialise a tracker session using a context manager\n",
    "    with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "        # configure the tracker using a config file\n",
    "        tracker.configure_from_file(\n",
    "            '../models/MDCK_config_scribble_sparse.json'\n",
    "        )\n",
    "        tracker.max_search_radius = 40\n",
    "\n",
    "        # append the objects to be tracked\n",
    "        tracker.append(objects_rfp)\n",
    "\n",
    "        # set the volume\n",
    "        tracker.volume=((0, 1600), (0, 1200), (-1e5, 1e5))\n",
    "\n",
    "        # track them (in interactive mode)\n",
    "        tracker.track_interactive(step_size=100)\n",
    "\n",
    "        # generate hypotheses and run the global optimizer\n",
    "        tracker.optimize()\n",
    "\n",
    "        tracker.export(f'{root_dir}/{expt}/{pos}/tracks.h5', obj_type='obj_type_2')\n",
    "\n",
    "#         # get the tracks in a format for napari visualization (optional)\n",
    "#         visaulise_tracks, properties, graph = tracker.to_napari(ndim=2)\n",
    "\n",
    "#         rfp_tracks = tracker.tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3f9a1c",
   "metadata": {},
   "source": [
    "# Finishing nd0013"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
