{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4802d903",
   "metadata": {},
   "source": [
    "# Using multiprocessing to batch compute a multipositioned experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa73e0",
   "metadata": {},
   "source": [
    "Am yet to run time tests on this to see if it works quantitatively better but seems like it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23aae283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import tqdm.auto as tqdm\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy import ndimage as nd\n",
    "from skimage.io import imsave\n",
    "from octopuslite import DaskOctopusLiteLoader\n",
    "from stardist.models import StarDist2D \n",
    "from stardist.plot import render_label\n",
    "from csbdeep.utils import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5820aa",
   "metadata": {},
   "source": [
    "# CPU count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "725dff18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpus = os.cpu_count()\n",
    "cpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9a1668",
   "metadata": {},
   "source": [
    "# Define segment function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1be8718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(pos):\n",
    "    if not overwrite and glob.glob(f'{root_dir}/{expt}/{pos}/{pos}_images/*channel099*.tif'):\n",
    "        print(f'{root_dir}/{expt}/{pos}/{pos}_images/ mask files found, skipping {expt}/{pos}')\n",
    "        return\n",
    "    print('Starting experiment position:', expt, pos)\n",
    "    # load images\n",
    "    image_path = f'{root_dir}/{expt}/{pos}/{pos}_images'\n",
    "    images = DaskOctopusLiteLoader(image_path, \n",
    "                                   remove_background = False)\n",
    "    # iterate over images filenames \n",
    "    for frame, fn in tqdm(enumerate(images.files(reference_channel))):\n",
    "        # compile 2-channels into XYC array\n",
    "        img = np.zeros((images[reference_channel][frame].shape[0], \n",
    "                        images[reference_channel][frame].shape[1], 2)) \n",
    "        img[:,:,0] = images['irfp'][frame]\n",
    "        img[:,:,1] = images['rfp'][frame]\n",
    "        # predict labels using 2ch image\n",
    "        labels, details = model.predict_instances(normalize(img))\n",
    "        # format 2channel mask image \n",
    "        mask = np.zeros(labels.shape)\n",
    "        # make multiclass mask from details dict\n",
    "        for cell_ID, class_label in enumerate(details['class_id'], 1):\n",
    "            #needs erosion step to stop merging of labels\n",
    "            segment = nd.binary_erosion(labels==cell_ID)\n",
    "            mask[segment] = class_label\n",
    "            # set background to zero\n",
    "            mask[labels == 0] = 0\n",
    "        # set filename as mask format (channel099)\n",
    "        fn = ((images.files('irfp')[frame])).replace('channel003', 'channel099')\n",
    "        # save out labelled image\n",
    "        imsave(fn, mask.astype(np.uint8), check_contrast=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d320cee",
   "metadata": {},
   "source": [
    "# Define necessary parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0950e6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.552369, nms_thresh=0.3.\n",
      "Positions to iterate over: ['Pos5', 'Pos6', 'Pos4']\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/home/nathan/data/kraken/ras'\n",
    "expt_list = ['ND0010_test']\n",
    "pos_list = 'all'\n",
    "reference_channel = 'irfp'\n",
    "overwrite = False\n",
    "expt = 'ND0010_test'\n",
    "model = StarDist2D(None, name='stardist_multiclass_MDCK', basedir='../models')\n",
    "pos_list = [pos for pos in os.listdir(f'{root_dir}/{expt}') \n",
    "               if 'Pos' in pos \n",
    "               and os.path.isdir(f'{root_dir}/{expt}/{pos}')]  \n",
    "print('Positions to iterate over:', pos_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3143093e",
   "metadata": {},
   "source": [
    "# Start parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "689b400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3342d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    with Pool(cpus) as p:\n",
    "        p.map(segment, pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00b112dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main line\n",
      "module name: __main__\n",
      "parent process: 3621\n",
      "process id: 4365\n",
      "/home/nathan/data/kraken/ras/ND0010_test/Pos5/Pos5_images/ mask files found, skipping ND0010_test/Pos5\n",
      "/home/nathan/data/kraken/ras/ND0010_test/Pos4/Pos4_images/ mask files found, skipping ND0010_test/Pos4\n",
      "/home/nathan/data/kraken/ras/ND0010_test/Pos6/Pos6_images/ mask files found, skipping ND0010_test/Pos6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def info(title):\n",
    "    print(title)\n",
    "    print('module name:', __name__)\n",
    "    print('parent process:', os.getppid())\n",
    "    print('process id:', os.getpid())\n",
    "\n",
    "# def f(name):\n",
    "#     info('function f')\n",
    "#     print('hello', name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    info('main line')\n",
    "    with Pool(cpus) as p:\n",
    "        p.map(segment, pos_list)\n",
    "#     p.start()\n",
    "#     p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6adb2e29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nathan/data/kraken/ras/ND0010_test/Pos5/Pos5_images/ mask files found, skipping ND0010_test/Pos5\n",
      "/home/nathan/data/kraken/ras/ND0010_test/Pos6/Pos6_images/ mask files found, skipping ND0010_test/Pos6\n",
      "/home/nathan/data/kraken/ras/ND0010_test/Pos4/Pos4_images/ mask files found, skipping ND0010_test/Pos4\n"
     ]
    }
   ],
   "source": [
    "with Pool(cpus) as p:\n",
    "        p.map(segment, pos_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1b8bbb",
   "metadata": {},
   "source": [
    "Source: https://towardsdatascience.com/parallelize-your-python-code-to-save-time-on-data-processing-805934b826e2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
